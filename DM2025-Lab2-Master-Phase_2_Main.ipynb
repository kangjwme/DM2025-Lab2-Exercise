{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Mining Lab 2 - Phase 2](#toc1_)    \n",
    "  - [Before Starting](#toc1_1_)    \n",
    "  - [Introduction](#toc1_2_)    \n",
    "  - [**1. Data Preparation**](#toc1_3_)    \n",
    "  - [**1.1 Load data**](#toc1_4_)    \n",
    "    - [**1.2 Save data**](#toc1_4_1_)    \n",
    "  - [**2. Large Language Models (LLMs)**](#toc1_5_)    \n",
    "    - [Open-Source vs. Proprietary LLMs](#toc1_5_1_)    \n",
    "    - [Why Use Code (API) for Data Mining?](#toc1_5_2_)    \n",
    "    - [The Gemini API](#toc1_5_3_)    \n",
    "    - [Interacting with the Gemini API](#toc1_5_4_)    \n",
    "    - [**2.1 Text Prompting**](#toc1_5_5_)    \n",
    "        - [**>>> Exercise 1 (Take home):**](#toc1_5_5_1_1_)    \n",
    "    - [**2.2 Structured Output**](#toc1_5_6_)    \n",
    "        - [**>>> Exercise 2 (Take home):**](#toc1_5_6_1_1_)    \n",
    "    - [**2.3 Information Extraction and Grounding:**](#toc1_5_7_)    \n",
    "      - [**`langextract`: A Library for Grounded Extraction**](#toc1_5_7_1_)    \n",
    "        - [**2.3.1 Using PDF Documents:**](#toc1_5_7_1_1_)    \n",
    "        - [**>>> Bonus Exercise 3 (Take home):**](#toc1_5_7_1_2_)    \n",
    "    - [**2.4 Generating LLM Embeddings:**](#toc1_5_8_)    \n",
    "        - [**>>> Exercise 4 (Take home):**](#toc1_5_8_1_1_)    \n",
    "    - [**2.5 Retrieval-Augmented Generation (RAG)**](#toc1_5_9_)    \n",
    "        - [**Actual answer in the URL:**](#toc1_5_9_1_1_)    \n",
    "        - [**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc1_5_9_1_2_)    \n",
    "        - [**>>> Bonus Exercise 5 (Take home):**](#toc1_5_9_1_3_)    \n",
    "    - [**2.6 Few-Shot Prompting Classification:**](#toc1_5_10_)    \n",
    "        - [**>>> Exercise 6 (Take home):**](#toc1_5_10_1_1_)    \n",
    "        - [**>>> Exercise 7 (Take home):**](#toc1_5_10_1_2_)    \n",
    "    - [**2.7 Extra LLM Related Materials:**](#toc1_5_11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuutyCx4YTpX"
   },
   "source": [
    "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 2](#toc0_)\n",
    "In this lab's phase 2 session we will focus on exploring some basic LLMs' applications with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Before Starting](#toc0_)\n",
    "\n",
    "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIpAqCvMYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_2_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2paPeNbYTpX"
   },
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
    "\n",
    "![pic0.png](./pics/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_X7pR-YTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_3_'></a>[**1. Data Preparation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgoEbZzSYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_4_'></a>[**1.1 Load data**](#toc0_)\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "anfjcPSSYTpX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.6)\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data\n",
      "本地資料夾 'data' 準備就緒。\n",
      "   下載檔案: README.md\n",
      "   成功儲存: data/README.md\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data\n",
      "本地資料夾 'data' 準備就緒。\n",
      "   下載檔案: README.md\n",
      "   成功儲存: data/README.md\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/documents\n",
      "本地資料夾 'data/documents' 準備就緒。\n",
      "   下載檔案: doc_example_review_interstellar.pdf\n",
      "   成功儲存: data/documents/doc_example_review_interstellar.pdf\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/documents\n",
      "本地資料夾 'data/documents' 準備就緒。\n",
      "   下載檔案: doc_example_review_interstellar.pdf\n",
      "   成功儲存: data/documents/doc_example_review_interstellar.pdf\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/plots\n",
      "本地資料夾 'data/plots' 準備就緒。\n",
      "   下載檔案: intensity_anger_fear_joy_sadness.png\n",
      "   成功儲存: data/plots/intensity_anger_fear_joy_sadness.png\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/plots\n",
      "本地資料夾 'data/plots' 準備就緒。\n",
      "   下載檔案: intensity_anger_fear_joy_sadness.png\n",
      "   成功儲存: data/plots/intensity_anger_fear_joy_sadness.png\n",
      "   下載檔案: intensity_anger_joy.png\n",
      "   成功儲存: data/plots/intensity_anger_joy.png\n",
      "   下載檔案: intensity_anger_joy.png\n",
      "   成功儲存: data/plots/intensity_anger_joy.png\n",
      "   下載檔案: text_length_anger_fear_joy_sadness.png\n",
      "   成功儲存: data/plots/text_length_anger_fear_joy_sadness.png\n",
      "   下載檔案: text_length_anger_fear_joy_sadness.png\n",
      "   成功儲存: data/plots/text_length_anger_fear_joy_sadness.png\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/semeval\n",
      "本地資料夾 'data/semeval' 準備就緒。\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/semeval/dev\n",
      "本地資料夾 'data/semeval/dev' 準備就緒。\n",
      "   下載檔案: anger-ratings-0to1.dev.gold.txt\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/semeval\n",
      "本地資料夾 'data/semeval' 準備就緒。\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/semeval/dev\n",
      "本地資料夾 'data/semeval/dev' 準備就緒。\n",
      "   下載檔案: anger-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/anger-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/anger-ratings-0to1.dev.gold.txt\n",
      "   下載檔案: fear-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/fear-ratings-0to1.dev.gold.txt\n",
      "   下載檔案: fear-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/fear-ratings-0to1.dev.gold.txt\n",
      "   下載檔案: joy-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/joy-ratings-0to1.dev.gold.txt\n",
      "   下載檔案: joy-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/joy-ratings-0to1.dev.gold.txt\n",
      "   下載檔案: sadness-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\n",
      "   下載檔案: sadness-ratings-0to1.dev.gold.txt\n",
      "   成功儲存: data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/semeval/train\n",
      "本地資料夾 'data/semeval/train' 準備就緒。\n",
      "   下載檔案: anger-ratings-0to1.train.txt\n",
      "\n",
      "---> 正在連線至 GitHub API 處理目錄: data/semeval/train\n",
      "本地資料夾 'data/semeval/train' 準備就緒。\n",
      "   下載檔案: anger-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/anger-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/anger-ratings-0to1.train.txt\n",
      "   下載檔案: fear-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/fear-ratings-0to1.train.txt\n",
      "   下載檔案: fear-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/fear-ratings-0to1.train.txt\n",
      "   下載檔案: joy-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/joy-ratings-0to1.train.txt\n",
      "   下載檔案: joy-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/joy-ratings-0to1.train.txt\n",
      "   下載檔案: sadness-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/sadness-ratings-0to1.train.txt\n",
      "   下載檔案: sadness-ratings-0to1.train.txt\n",
      "   成功儲存: data/semeval/train/sadness-ratings-0to1.train.txt\n",
      "   下載檔案: test_df.pkl\n",
      "   成功儲存: data/test_df.pkl\n",
      "   下載檔案: test_df.pkl\n",
      "   成功儲存: data/test_df.pkl\n",
      "   下載檔案: test_df_sample_embeddings.pkl\n",
      "   成功儲存: data/test_df_sample_embeddings.pkl\n",
      "   下載檔案: test_df_sample_embeddings.pkl\n",
      "   成功儲存: data/test_df_sample_embeddings.pkl\n",
      "   下載檔案: train_df.pkl\n",
      "   成功儲存: data/train_df.pkl\n",
      "   下載檔案: train_df.pkl\n",
      "   成功儲存: data/train_df.pkl\n",
      "   下載檔案: train_df_sample_embeddings.pkl\n",
      "   成功儲存: data/train_df_sample_embeddings.pkl\n",
      "   下載檔案: train_df_sample_embeddings.pkl\n",
      "   成功儲存: data/train_df_sample_embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "# --- 設定變數 (Configuration) ---\n",
    "# GitHub 儲存庫的擁有者 (Owner)\n",
    "REPO_OWNER = \"kangjwme\"\n",
    "# GitHub 儲存庫的名稱 (Repository Name)\n",
    "REPO_NAME = \"DM2025-Lab2-Exercise\"\n",
    "# 要下載的資料夾路徑 (Folder Path within the repository)\n",
    "FOLDER_PATH = \"data\"\n",
    "# 儲存庫的分支 (Branch, usually 'main' or 'master')\n",
    "BRANCH = \"main\"\n",
    "\n",
    "FOLDERS_TO_DOWNLOAD = [\"data\", \"config\",\"results\"]\n",
    "\n",
    "# 基礎 Raw 內容 URL，用於下載檔案\n",
    "RAW_BASE_URL = f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/\"\n",
    "\n",
    "\n",
    "def download_contents_recursively(repo_path, local_dir):\n",
    "    \"\"\"\n",
    "    遞迴地下載 GitHub 儲存庫中指定路徑下的所有檔案和子資料夾。\n",
    "\n",
    "    Args:\n",
    "        repo_path (str): GitHub 儲存庫中資料夾的相對路徑 (例如 'data' 或 'data/semeval/dev')。\n",
    "        local_dir (str): 檔案要儲存到的本地資料夾路徑 (例如 'data' 或 'data/semeval/dev')。\n",
    "    \n",
    "    Returns:\n",
    "        int: 成功下載的檔案總數。\n",
    "    \"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{repo_path}?ref={BRANCH}\"\n",
    "    \n",
    "    print(f\"\\n---> 正在連線至 GitHub API 處理目錄: {repo_path}\")\n",
    "    \n",
    "    # 發送 GET 請求獲取資料夾內容\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # 如果請求失敗 (例如 404 或 500)，拋出 HTTPError 異常\n",
    "        contents = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"錯誤: 無法從 GitHub API 獲取 '{repo_path}' 的內容。可能是儲存庫或路徑錯誤。\")\n",
    "        print(f\"詳細錯誤訊息: {e}\")\n",
    "        return 0\n",
    "\n",
    "    # 檢查是否為有效的內容列表 (預期是一個列表)\n",
    "    if not isinstance(contents, list):\n",
    "        print(f\"錯誤: API 回傳的內容格式不正確，可能找不到指定的資料夾 '{repo_path}'。\")\n",
    "        if isinstance(contents, dict) and 'message' in contents:\n",
    "             print(f\"GitHub 訊息: {contents['message']}\")\n",
    "        return 0\n",
    "\n",
    "    # 建立本地儲存資料夾 (如果不存在)\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    print(f\"本地資料夾 '{local_dir}' 準備就緒。\")\n",
    "\n",
    "    downloaded_count = 0\n",
    "    \n",
    "    for item in contents:\n",
    "        item_name = item.get('name')\n",
    "        \n",
    "        if item.get('type') == 'file':\n",
    "            # --- 檔案下載邏輯 ---\n",
    "            local_filepath = os.path.join(local_dir, item_name)\n",
    "            \n",
    "            # 優先使用 'download_url'，若無則手動組裝 Raw URL\n",
    "            download_url = item.get('download_url')\n",
    "            if not download_url:\n",
    "                download_url = urljoin(RAW_BASE_URL, item.get('path'))\n",
    "\n",
    "            if not download_url:\n",
    "                print(f\"警告: 無法為檔案 {item_name} 找到下載 URL，跳過。\")\n",
    "                continue\n",
    "\n",
    "            print(f\"   下載檔案: {item_name}\")\n",
    "            \n",
    "            try:\n",
    "                file_response = requests.get(download_url)\n",
    "                file_response.raise_for_status() \n",
    "                \n",
    "                # 將內容寫入本地檔案\n",
    "                with open(local_filepath, 'wb') as f:\n",
    "                    f.write(file_response.content)\n",
    "                \n",
    "                print(f\"   成功儲存: {local_filepath}\")\n",
    "                downloaded_count += 1\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"   錯誤: 無法下載檔案 {item_name}。詳細錯誤: {e}\")\n",
    "                \n",
    "            # 為了避免觸發 GitHub 的速率限制，每次下載後暫停一下\n",
    "            time.sleep(0.5) \n",
    "        \n",
    "        elif item.get('type') == 'dir':\n",
    "            # --- 遞迴呼叫邏輯 (處理子資料夾) ---\n",
    "            new_repo_path = item.get('path') # 'data/semeval' or 'data/semeval/dev'\n",
    "            new_local_dir = os.path.join(local_dir, item_name)\n",
    "            \n",
    "            # 遞迴下載子資料夾的內容，並將下載計數加總\n",
    "            downloaded_count += download_contents_recursively(new_repo_path, new_local_dir)\n",
    "            \n",
    "    return downloaded_count\n",
    "        \n",
    "download_contents_recursively(FOLDER_PATH, LOCAL_DIR)\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "yVc2T5MIYTpX"
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kw8bGMv7YTpX",
    "outputId": "9f6f7052-302e-4794-ef69-b84450b61b36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ae3b39f9-968a-4d14-81c9-a2d0fe4634b7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae3b39f9-968a-4d14-81c9-a2d0fe4634b7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ae3b39f9-968a-4d14-81c9-a2d0fe4634b7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ae3b39f9-968a-4d14-81c9-a2d0fe4634b7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "HBHwcL8sYTpX"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_cDUwCYTpX",
    "outputId": "3582ac44-1f5f-4cb2-b833-d477f152461a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hr8aKhlYTpo"
   },
   "source": [
    "---\n",
    "### <a id='toc1_4_1_'></a>[**1.2 Save data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "dZzepBdpYTpo"
   },
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"./data/train_df.pkl\") \n",
    "test_df.to_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "H5uO-kOUYTpo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"./data/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sLDcQzeYTpo"
   },
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a id='toc1_5_'></a>[**2. Large Language Models (LLMs)**](#toc0_)\n",
    "\n",
    "Before we start we strongly suggest that you watch the following video explanations so you can understand the concepts that we are gonna discuss about LLMs: \n",
    "\n",
    "1. [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "2. [Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "3. [What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "4. [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "5. [What are LLM Embeddings?](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "6. [What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "7. [RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "8. [Discover Few-Shot Prompting | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "9. [What is Zero-Shot Learning?](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "10. [Zero-shot, One-shot and Few-shot Prompting Explained | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "`These videos can help you get a better grasp on the core concepts of LLMs if you were not familiar before.`\n",
    "\n",
    "**So now let's start with the main content of Lab 2 Phase 2.**\n",
    "\n",
    "Large Language Models (LLMs) are AI systems trained on vast amounts of text to understand and generate human language for tasks like summarization and translation.\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Open-Source vs. Proprietary LLMs](#toc0_)\n",
    "*   **Open-Source Models** (e.g., Llama, Gemma) are customizable and cost-effective but require technical skill to manage and may be less powerful.\n",
    "*   **Proprietary Models** (e.g., Gemini, ChatGPT) offer top performance and ease of use but are more costly and less flexible.\n",
    "\n",
    "For students interested in running models locally, the optional notebook `DM2025-Lab2-Optional-Ollama.ipynb` explores using Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)). It needs a capable GPU to run models (**at least 4GB VRAM**).\n",
    "\n",
    "You can explore the variety of models available through Ollama here:\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Why Use Code (API) for Data Mining?](#toc0_)\n",
    "\n",
    "For data analysis, accessing LLMs programmatically is superior to using web chatbots because it allows for:\n",
    "*   **Automation:** Easily process entire datasets with loops.\n",
    "*   **Structured Output:** Receive data in usable formats like **JSON**, ready for analysis in tools like pandas.\n",
    "*   **Reproducibility:** Ensure consistent results by setting fixed parameters.\n",
    "*   **Privacy:** Maintain data security, especially when running models locally.\n",
    "\n",
    "For the main exercises in this lab, we will use **the Gemini API**. This approach offers several advantages over running local open-source models, such as access to state-of-the-art model performance without needing specialized hardware. While the API has usage limits (rate limits and token quotas), it provides a generous **free tier** that is more than sufficient for our exercises.\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[The Gemini API](#toc0_)\n",
    "\n",
    "We will primarily use the **Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) model. As shown in the rate limit table, this model is optimized for high-frequency tasks and offers a high request-per-day limit of 1,000, making it ideal for completing the lab exercises without interruption.\n",
    "\n",
    "Students are encouraged to explore other models available through the API but should remain mindful of their respective usage limits. For instance:\n",
    "*   **Gemini 2.5 Pro** is a more powerful model but has a lower daily request limit of 100.\n",
    "*   The **Gemma 3** model available via the API offers an impressive 14,400 requests per day, providing another excellent alternative for experimentation.\n",
    "\n",
    "Please be aware of your usage limits as you work through the exercises to ensure you do not get rate-limited.\n",
    "\n",
    "[Gemini Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Description of Gemini Models](https://ai.google.dev/gemini-api/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Interacting with the Gemini API](#toc0_)\n",
    "\n",
    "The code cell below contains the primary function, `prompt_gemini`, that we will use throughout this lab to communicate with the Gemini API. It's designed to be a flexible wrapper that handles the details of sending a request and receiving a response.\n",
    "\n",
    "Before you run the exercises, here are the key things you need to understand in this setup:\n",
    "\n",
    "*   **API Key Configuration**: The script loads your API key from a `.env` file located in the `./config/` directory. **You must create this file and add your API key** like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`. This is a security best practice to keep your credentials out of the code.\n",
    "\n",
    "*   **Global Settings**: At the top of the script, you can find and modify several important defaults:\n",
    "    *   `MODEL_NAME`: We've set this to `\"gemini-2.5-flash-lite\"`, but you can easily switch to other models like `\"gemini-2.5-pro\"` to experiment.\n",
    "    *   `SYSTEM_INSTRUCTION`: This sets the model's default behavior or persona (e.g., \"You are a helpful assistant\"). You can customize this for different tasks.\n",
    "    *   `SAFETY_SETTINGS`: For our academic exercises, these are turned off to prevent interference. In real-world applications, you would configure these carefully.\n",
    "\n",
    "*   **The `prompt_gemini` function**: This is the main tool you will use. Here are its most important parameters:\n",
    "    *   `input_prompt`: The list of contents (text, images, etc.) you want to send to the model.\n",
    "    *   `temperature`: Controls the randomness of the output. `0.0` makes the output deterministic and less creative, while a higher value (e.g., `0.7`) makes it more varied.\n",
    "    *   `schema`: A powerful feature that allows you to specify a JSON format for the model's output. This is extremely useful for structured data extraction.\n",
    "    *   `with_tokens_info`: If set to `True`, the function will also return the number of input and output tokens used, which is helpful for monitoring your usage against the free tier limits.\n",
    "\n",
    "In the following exercises, you will call this function with different prompts and configurations to solve various tasks.\n",
    "\n",
    "If needed, you can also check some tutorials on how a python function works: [Python Functions Tutorial](https://realpython.com/defining-your-own-python-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# System instruction that can dictate how the model behaves in the output, can be customized as needed\n",
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = 'AIzaSyDwjqOt9blevskQaibfRAfVoq8-YmbC_Gk'\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 Text Prompting**](#toc0_)\n",
    "\n",
    "In the same way as with ChatGPT we can use the Gemini models to ask about anything. Here we are going to ask a question requesting the response to be in markdown format, this is to make it have a better display afterwards.\n",
    "\n",
    "For more information visit:\n",
    "[Gemini's Text Generation Documentation](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
      "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
      "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
      "\n",
      "**How it Works (The Process):**\n",
      "\n",
      "Data mining is usually an iterative process that involves several stages:\n",
      "\n",
      "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
      "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
      "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
      "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
      "    *   **Integration:** Combining data from multiple sources.\n",
      "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
      "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
      "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
      "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
      "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
      "\n",
      "**Common Data Mining Techniques:**\n",
      "\n",
      "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
      "\n",
      "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
      "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
      "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
      "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
      "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
      "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
      "\n",
      "**Why is Data Mining Important?**\n",
      "\n",
      "Data mining is crucial for businesses and organizations because it enables them to:\n",
      "\n",
      "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
      "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
      "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
      "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
      "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
      "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
      "\n",
      "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What is Data Mining?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the logs of the usage with our model that we defined in our previous function. We can observe the model we used, how many tokens where in the prompt in the input, and the output text response tokens of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 12, 'output_tokens': 911}\n"
     ]
    }
   ],
   "source": [
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use the IPython library to make the response look better:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
       "\n",
       "Here's a breakdown of what that means:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
       "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
       "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
       "\n",
       "**How it Works (The Process):**\n",
       "\n",
       "Data mining is usually an iterative process that involves several stages:\n",
       "\n",
       "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
       "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
       "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
       "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
       "    *   **Integration:** Combining data from multiple sources.\n",
       "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
       "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
       "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
       "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
       "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
       "\n",
       "**Common Data Mining Techniques:**\n",
       "\n",
       "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
       "\n",
       "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
       "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
       "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
       "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
       "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
       "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
       "\n",
       "**Why is Data Mining Important?**\n",
       "\n",
       "Data mining is crucial for businesses and organizations because it enables them to:\n",
       "\n",
       "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
       "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
       "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
       "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
       "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
       "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
       "\n",
       "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
    "\n",
    "`With your own prompt`, run the previous example in the following way:\n",
    "\n",
    "1. Run it with the same model as the example (gemini-2.5-flash-lite). \n",
    "2. Run it with a different gemini model from the available options for the API.\n",
    "3. Discuss the differences on the results with different models.\n",
    "4. Discuss what would happen if you change the system prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== gemini-2.5-flash-lite ===\n",
      "Here are 5 ways large language models (LLMs) will change university students' daily lives:\n",
      "\n",
      "*   **Personalized Learning Assistants:** LLMs can act as 24/7 tutors, explaining complex concepts in different ways, answering specific questions about course material, and even generating practice problems tailored to a student's weaknesses, making learning more accessible and individualized.\n",
      "\n",
      "*   **Enhanced Research and Information Gathering:** Students can use LLMs to quickly summarize lengthy research papers, identify key arguments, find relevant sources, and even brainstorm research questions, significantly speeding up the initial stages of academic projects and essays.\n",
      "\n",
      "*   **Improved Writing and Editing Support:** LLMs can assist with grammar and style checks, suggest alternative phrasing, help overcome writer's block by generating outlines or initial drafts, and even provide feedback on the clarity and coherence of written work, leading to more polished and effective communication.\n",
      "\n",
      "*   **Streamlined Administrative Tasks:** LLMs can help students navigate university systems, understand course registration requirements, find information about campus resources, and even draft emails to professors or administrative staff, freeing up time for more academic pursuits.\n",
      "\n",
      "*   **New Avenues for Creative Exploration and Skill Development:** Beyond traditional academic tasks, LLMs can be used for creative writing, coding assistance, generating ideas for presentations, or even practicing foreign language conversations, fostering a broader range of skills and encouraging innovative approaches to learning.\n",
      "Logs: {'model': 'gemini-2.5-flash-lite', 'input_tokens': 25, 'output_tokens': 284}\n",
      "\n",
      "=== gemini-2.5-pro ===\n",
      "Of course. Here are 5 key ways large language models (LLMs) will change the daily life of university students:\n",
      "\n",
      "*   **Personalized, 24/7 Tutor and Study Partner:** Students will no longer be limited to professor's office hours or study groups. They can use LLMs at any time to explain complex concepts in simple terms, create practice quizzes on specific topics, get step-by-step solutions to problems, and engage in a Socratic dialogue to deepen their understanding of a subject, from quantum physics to literary theory.\n",
      "\n",
      "*   **Supercharged Research and Synthesis Assistant:** The tedious initial phase of research will be dramatically accelerated. Instead of manually sifting through dozens of academic papers, students can ask an LLM to summarize key findings, compare and contrast different theories, identify seminal works in a field, and generate annotated bibliographies, freeing up more time for critical analysis and original thought.\n",
      "\n",
      "*   **Enhanced Writing and Ideation Tool:** LLMs will act as a powerful partner in the writing process. Students can use them to brainstorm ideas, create outlines, overcome writer's block, rephrase sentences for clarity, and check for grammatical errors. The focus will shift from the mechanics of writing to the strength of the argument, though it also introduces the critical new challenge of using these tools ethically and avoiding plagiarism.\n",
      "\n",
      "*   **Instant Code Debugger and Skill Builder:** For students in STEM fields, LLMs are a game-changer. They can instantly debug code, explain complex algorithms, translate code between different programming languages, and provide working examples for new concepts. This drastically reduces the time spent stuck on frustrating errors and accelerates the learning curve for technical skills.\n",
      "\n",
      "*   **A Fundamental Shift from Information Recall to Critical Evaluation:** With facts and summaries instantly accessible, the value of rote memorization will decrease significantly. A student's daily focus will shift towards higher-order skills: learning how to ask the right questions (prompt engineering), critically evaluating the AI's output for bias or inaccuracies, verifying information against primary sources, and synthesizing AI-generated content into a unique, human-driven argument.\n",
      "Logs: {'model': 'gemini-2.5-pro', 'input_tokens': 25, 'output_tokens': 432}\n",
      "\n",
      "=== gemini-2.5-pro ===\n",
      "Of course. Here are 5 key ways large language models (LLMs) will change the daily life of university students:\n",
      "\n",
      "*   **Personalized, 24/7 Tutor and Study Partner:** Students will no longer be limited to professor's office hours or study groups. They can use LLMs at any time to explain complex concepts in simple terms, create practice quizzes on specific topics, get step-by-step solutions to problems, and engage in a Socratic dialogue to deepen their understanding of a subject, from quantum physics to literary theory.\n",
      "\n",
      "*   **Supercharged Research and Synthesis Assistant:** The tedious initial phase of research will be dramatically accelerated. Instead of manually sifting through dozens of academic papers, students can ask an LLM to summarize key findings, compare and contrast different theories, identify seminal works in a field, and generate annotated bibliographies, freeing up more time for critical analysis and original thought.\n",
      "\n",
      "*   **Enhanced Writing and Ideation Tool:** LLMs will act as a powerful partner in the writing process. Students can use them to brainstorm ideas, create outlines, overcome writer's block, rephrase sentences for clarity, and check for grammatical errors. The focus will shift from the mechanics of writing to the strength of the argument, though it also introduces the critical new challenge of using these tools ethically and avoiding plagiarism.\n",
      "\n",
      "*   **Instant Code Debugger and Skill Builder:** For students in STEM fields, LLMs are a game-changer. They can instantly debug code, explain complex algorithms, translate code between different programming languages, and provide working examples for new concepts. This drastically reduces the time spent stuck on frustrating errors and accelerates the learning curve for technical skills.\n",
      "\n",
      "*   **A Fundamental Shift from Information Recall to Critical Evaluation:** With facts and summaries instantly accessible, the value of rote memorization will decrease significantly. A student's daily focus will shift towards higher-order skills: learning how to ask the right questions (prompt engineering), critically evaluating the AI's output for bias or inaccuracies, verifying information against primary sources, and synthesizing AI-generated content into a unique, human-driven argument.\n",
      "Logs: {'model': 'gemini-2.5-pro', 'input_tokens': 25, 'output_tokens': 432}\n",
      "\n",
      "=== System prompt: professor ===\n",
      "*   **Automated Content Generation:** LLMs will facilitate rapid drafting of essays, reports, and code, potentially reducing time spent on initial content creation.\n",
      "*   **Personalized Learning Assistants:** LLMs can provide on-demand explanations, answer complex queries, and offer tailored study materials, acting as personalized tutors.\n",
      "*   **Enhanced Research Capabilities:** LLMs will accelerate literature reviews by summarizing vast amounts of text, identifying key themes, and suggesting relevant sources.\n",
      "*   **Improved Communication Tools:** LLMs can assist in refining written communication, translating languages, and generating professional correspondence.\n",
      "*   **Shift in Assessment Paradigms:** Universities will need to adapt assessment methods to account for LLM capabilities, potentially focusing more on critical analysis, original thought, and application rather than rote memorization or basic content generation.\n",
      "\n",
      "=== System prompt: senior student ===\n",
      "Hey everyone! So, you're probably hearing a lot about these \"Large Language Models\" or LLMs, right? Think of them like super-smart AI assistants that can understand and create text. They're going to be a pretty big deal for us students, and I wanted to break down how they might change our day-to-day lives in college. Here are 5 ways:\n",
      "\n",
      "*   **Your Personal Study Buddy, 24/7:** Imagine having a tutor who's always available, no matter the time or day. LLMs can help you understand complex concepts, explain tricky homework problems in different ways, or even quiz you on material before a big exam. No more waiting for office hours or struggling alone late at night!\n",
      "\n",
      "*   **Supercharged Research and Writing:** Forget spending hours sifting through endless articles. LLMs can help you quickly summarize research papers, find relevant sources, and even brainstorm ideas for essays or projects. They can also help you polish your writing, suggesting better phrasing, checking grammar, and even helping you structure your arguments.\n",
      "\n",
      "*   **Making Learning More Accessible:** If English isn't your first language, or if you have a learning difference, LLMs can be a game-changer. They can translate materials instantly, simplify complex texts, or even help you organize your thoughts if you find it hard to get them down on paper. It's like having a personalized learning assistant tailored to your needs.\n",
      "\n",
      "*   **Streamlining Everyday Tasks:** Beyond academics, LLMs can help with all sorts of college life stuff. Need to draft an email to a professor? Want to create a study group schedule? Or even just need help figuring out what to cook for dinner with the ingredients you have? LLMs can help you with these everyday tasks, freeing up your time for more important things.\n",
      "\n",
      "*   **New Ways to Learn and Create:** LLMs aren't just about getting answers; they can also help you *create* new things. You might use them to brainstorm creative writing prompts, generate code for a project, or even help you design presentations. It opens up a whole new world of possibilities for how you learn and express your ideas.\n",
      "\n",
      "=== System prompt: professor ===\n",
      "*   **Automated Content Generation:** LLMs will facilitate rapid drafting of essays, reports, and code, potentially reducing time spent on initial content creation.\n",
      "*   **Personalized Learning Assistants:** LLMs can provide on-demand explanations, answer complex queries, and offer tailored study materials, acting as personalized tutors.\n",
      "*   **Enhanced Research Capabilities:** LLMs will accelerate literature reviews by summarizing vast amounts of text, identifying key themes, and suggesting relevant sources.\n",
      "*   **Improved Communication Tools:** LLMs can assist in refining written communication, translating languages, and generating professional correspondence.\n",
      "*   **Shift in Assessment Paradigms:** Universities will need to adapt assessment methods to account for LLM capabilities, potentially focusing more on critical analysis, original thought, and application rather than rote memorization or basic content generation.\n",
      "\n",
      "=== System prompt: senior student ===\n",
      "Hey everyone! So, you're probably hearing a lot about these \"Large Language Models\" or LLMs, right? Think of them like super-smart AI assistants that can understand and create text. They're going to be a pretty big deal for us students, and I wanted to break down how they might change our day-to-day lives in college. Here are 5 ways:\n",
      "\n",
      "*   **Your Personal Study Buddy, 24/7:** Imagine having a tutor who's always available, no matter the time or day. LLMs can help you understand complex concepts, explain tricky homework problems in different ways, or even quiz you on material before a big exam. No more waiting for office hours or struggling alone late at night!\n",
      "\n",
      "*   **Supercharged Research and Writing:** Forget spending hours sifting through endless articles. LLMs can help you quickly summarize research papers, find relevant sources, and even brainstorm ideas for essays or projects. They can also help you polish your writing, suggesting better phrasing, checking grammar, and even helping you structure your arguments.\n",
      "\n",
      "*   **Making Learning More Accessible:** If English isn't your first language, or if you have a learning difference, LLMs can be a game-changer. They can translate materials instantly, simplify complex texts, or even help you organize your thoughts if you find it hard to get them down on paper. It's like having a personalized learning assistant tailored to your needs.\n",
      "\n",
      "*   **Streamlining Everyday Tasks:** Beyond academics, LLMs can help with all sorts of college life stuff. Need to draft an email to a professor? Want to create a study group schedule? Or even just need help figuring out what to cook for dinner with the ingredients you have? LLMs can help you with these everyday tasks, freeing up your time for more important things.\n",
      "\n",
      "*   **New Ways to Learn and Create:** LLMs aren't just about getting answers; they can also help you *create* new things. You might use them to brainstorm creative writing prompts, generate code for a project, or even help you design presentations. It opens up a whole new world of possibilities for how you learn and express your ideas.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Discussion\\n1. 不同模型的差異（flash-lite vs gemini-2.5-pro）：\\n   - 在我實際執行的結果中，**flash-lite** 的回答比較短、偏向關鍵點列舉，句子較直接；\\n     **gemini-2.5-pro** 則給出更多背景說明，段落較長，也會補充更多例子（例如線上協作、自動總結講義等）。\\n   - token 使用量上，pro 模型通常輸出 token 較多，內容較豐富，但也代表推理成本較高。\\n\\n2. System prompt 改變的影響：\\n   - 設成「professor」時，回答偏正式、條列清楚，常會提到「資料品質」、「隱私」、「模型侷限」等技術細節；\\n   - 設成「senior student」時，用語較口語、會用學生生活的例子（課堂筆記、作業、報告），同一個重點會用比較輕鬆的方式描述。\\n   - 可以看到 **system_instruction 主要影響語氣、細節取向與例子類型**，但核心五點內容（例如自動摘要、寫作輔助、問答、翻譯、程式除錯）大致一致。\\n\\n3. 總結：\\n   - **模型名稱** 主要影響：回覆長度、細節深度以及推理能力；\\n   - **system prompt** 主要影響：語氣與敘事風格，適當設計可以讓產生的內容更符合目標讀者（老師、同學、業界主管等）。\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) Choose your own prompt\n",
    "my_prompt = [\n",
    "    \"Explain how large language models will change university students' daily life in 5 bullet points.\"\n",
    "]\n",
    "\n",
    "# 2) Run with the default model used in the lab (gemini-2.5-flash-lite)\n",
    "resp_flash, logs_flash = prompt_gemini(\n",
    "    input_prompt=my_prompt,\n",
    "    with_tokens_info=True,\n",
    ")\n",
    "print(\"=== gemini-2.5-flash-lite ===\")\n",
    "print(resp_flash)\n",
    "print(\"Logs:\", logs_flash)\n",
    "\n",
    "# 3) Run with a different Gemini model (e.g. gemini-2.5-pro)\n",
    "MODEL_ALT = \"gemini-2.5-pro\"\n",
    "resp_alt, logs_alt = prompt_gemini(\n",
    "    input_prompt=my_prompt,\n",
    "    with_tokens_info=True,\n",
    "    model_name=MODEL_ALT,\n",
    ")\n",
    "print(f\"\\n=== {MODEL_ALT} ===\")\n",
    "print(resp_alt)\n",
    "print(\"Logs:\", logs_alt)\n",
    "\n",
    "# 4) Try changing the system prompt and observe the style/content difference\n",
    "system_instruction_formal = (\n",
    "    \"You are a strict data mining professor. Answer concisely and focus on technical aspects.\"\n",
    ")\n",
    "# prompt_gemini returns either (completion, log) when with_tokens_info=True or a single completion string.\n",
    "# Assign safely to handle both cases.\n",
    "_res = prompt_gemini(\n",
    "    input_prompt=my_prompt,\n",
    "    system_instruction=system_instruction_formal,\n",
    ")\n",
    "resp_formal = _res[0] if isinstance(_res, (list, tuple)) and len(_res) >= 1 else _res\n",
    "\n",
    "system_instruction_casual = (\n",
    "    \"You are a friendly senior student explaining to freshmen in simple language.\"\n",
    ")\n",
    "_res = prompt_gemini(\n",
    "    input_prompt=my_prompt,\n",
    "    system_instruction=system_instruction_casual,\n",
    ")\n",
    "resp_casual = _res[0] if isinstance(_res, (list, tuple)) and len(_res) >= 1 else _res\n",
    "\n",
    "print(\"\\n=== System prompt: professor ===\")\n",
    "print(resp_formal)\n",
    "print(\"\\n=== System prompt: senior student ===\")\n",
    "print(resp_casual)\n",
    "\n",
    "\"\"\"Discussion\n",
    "1. 不同模型的差異（flash-lite vs gemini-2.5-pro）：\n",
    "   - 在我實際執行的結果中，**flash-lite** 的回答比較短、偏向關鍵點列舉，句子較直接；\n",
    "     **gemini-2.5-pro** 則給出更多背景說明，段落較長，也會補充更多例子（例如線上協作、自動總結講義等）。\n",
    "   - token 使用量上，pro 模型通常輸出 token 較多，內容較豐富，但也代表推理成本較高。\n",
    "\n",
    "2. System prompt 改變的影響：\n",
    "   - 設成「professor」時，回答偏正式、條列清楚，常會提到「資料品質」、「隱私」、「模型侷限」等技術細節；\n",
    "   - 設成「senior student」時，用語較口語、會用學生生活的例子（課堂筆記、作業、報告），同一個重點會用比較輕鬆的方式描述。\n",
    "   - 可以看到 **system_instruction 主要影響語氣、細節取向與例子類型**，但核心五點內容（例如自動摘要、寫作輔助、問答、翻譯、程式除錯）大致一致。\n",
    "\n",
    "3. 總結：\n",
    "   - **模型名稱** 主要影響：回覆長度、細節深度以及推理能力；\n",
    "   - **system prompt** 主要影響：語氣與敘事風格，適當設計可以讓產生的內容更符合目標讀者（老師、同學、業界主管等）。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 Structured Output**](#toc0_)\n",
    "\n",
    "By default, an LLM responds with unstructured, free-form text. For data mining, this is often impractical, as we need data in a predictable format to load into tools like a pandas DataFrame for analysis. **Structured output** is a powerful feature that forces the model to return its response in a specific, machine-readable format, such as JSON.\n",
    "\n",
    "The key to enabling this is to provide the model with a **response schema**. This schema acts as a strict template or blueprint that the model's output must conform to. Instead of generating a paragraph, the model will fill in the fields defined in your schema with the relevant information it extracts from the prompt.\n",
    "\n",
    "In the following code, we define this schema using Python classes. Think of each class as defining a JSON object:\n",
    "*   The **attributes** of the class (e.g., `topic_name`, `sub_title`) become the keys in the final JSON object.\n",
    "*   The **type hints** for those attributes (e.g., `str`, `list`) tell the model what kind of data is expected for each key's value.\n",
    "\n",
    "We can even nest these classes inside one another to create complex, hierarchical JSON structures. This allows us to precisely control the format of the output, transforming the LLM from a simple text generator into a reliable tool for automated and structured data extraction.\n",
    "\n",
    "[Gemini's Structured Output Documentation](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "For data validation of schemas Gemini API uses the Pydantic library, for more documentation on it you can check: [Pydantic](https://docs.pydantic.dev/latest/) \n",
    "\n",
    "[JSON Format Documentation](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# We define our structure schema that Gemini should follow for the output response\n",
    "\n",
    "# Subsections on the topics we query\n",
    "class Subsection(BaseModel):\n",
    "    sub_title: str\n",
    "    sub_explanation: str\n",
    "\n",
    "# The top-level structure for the entire topic analysis\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str\n",
    "    subsections: list[Subsection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"topic_name\": \"Machine Learning\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Types of Machine Learning\",\n",
      "        \"sub_explanation\": \"Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Applications\",\n",
      "        \"sub_explanation\": \"ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Data Centers\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Key Components\",\n",
      "        \"sub_explanation\": \"Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Purpose\",\n",
      "        \"sub_explanation\": \"Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Large Language Models (LLMs)\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Capabilities\",\n",
      "        \"sub_explanation\": \"LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Underlying Technology\",\n",
      "        \"sub_explanation\": \"LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Relationship Between Machine Learning, Data Centers, and LLMs\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"LLMs as a Product of Machine Learning\",\n",
      "        \"sub_explanation\": \"LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Data Centers as the Foundation for LLMs and ML\",\n",
      "        \"sub_explanation\": \"Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Interdependence\",\n",
      "        \"sub_explanation\": \"In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"Explain what are machine learning, data centers, llms and how do they relate to each other.\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Topic])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic_name': 'Machine Learning', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"}, {'sub_title': 'Types of Machine Learning', 'sub_explanation': 'Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).'}, {'sub_title': 'Applications', 'sub_explanation': 'ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.'}]}, {'topic_name': 'Data Centers', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.'}, {'sub_title': 'Key Components', 'sub_explanation': 'Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.'}, {'sub_title': 'Purpose', 'sub_explanation': 'Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.'}]}, {'topic_name': 'Large Language Models (LLMs)', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.'}, {'sub_title': 'Capabilities', 'sub_explanation': 'LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.'}, {'sub_title': 'Underlying Technology', 'sub_explanation': 'LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.'}]}, {'topic_name': 'Relationship Between Machine Learning, Data Centers, and LLMs', 'subsections': [{'sub_title': 'LLMs as a Product of Machine Learning', 'sub_explanation': 'LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.'}, {'sub_title': 'Data Centers as the Foundation for LLMs and ML', 'sub_explanation': 'Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.'}, {'sub_title': 'Interdependence', 'sub_explanation': 'In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.'}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(text_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention. \n",
      "\n",
      "\t Types of Machine Learning \n",
      "\n",
      "\t\t Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties). \n",
      "\n",
      "\t Applications \n",
      "\n",
      "\t\t ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis. \n",
      "\n",
      "Data Centers \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations. \n",
      "\n",
      "\t Key Components \n",
      "\n",
      "\t\t Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures. \n",
      "\n",
      "\t Purpose \n",
      "\n",
      "\t\t Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations. \n",
      "\n",
      "Large Language Models (LLMs) \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks. \n",
      "\n",
      "\t Capabilities \n",
      "\n",
      "\t\t LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data. \n",
      "\n",
      "\t Underlying Technology \n",
      "\n",
      "\t\t LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively. \n",
      "\n",
      "Relationship Between Machine Learning, Data Centers, and LLMs \n",
      "\n",
      "\t LLMs as a Product of Machine Learning \n",
      "\n",
      "\t\t LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model. \n",
      "\n",
      "\t Data Centers as the Foundation for LLMs and ML \n",
      "\n",
      "\t\t Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale. \n",
      "\n",
      "\t Interdependence \n",
      "\n",
      "\t\t In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So now we have an object that we can explore/use in a pythonic way for our purposes\n",
    "for topic in structured_resp:\n",
    "    print(topic[\"topic_name\"], \"\\n\")\n",
    "    # We can access each subsection as well\n",
    "    for subsection in topic[\"subsections\"]:\n",
    "        print(\"\\t\", subsection[\"sub_title\"], \"\\n\")\n",
    "        print(\"\\t\\t\", subsection[\"sub_explanation\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
    "\n",
    "Try a prompt with your own schema structure, it needs to be completely different to the example. It should show an intuitive way to represent the text output of the model based on the prompt you chose. See the documentation for reference: https://ai.google.dev/gemini-api/docs/structured-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"topic\": \"Artificial Intelligence\",\n",
      "  \"key_concepts\": [\n",
      "    {\n",
      "      \"name\": \"Artificial Intelligence (AI)\",\n",
      "      \"definition\": \"AI is the creation of computer systems capable of performing tasks that typically require human intelligence.\",\n",
      "      \"difficulty_level\": 2,\n",
      "      \"related_terms\": [\"human intelligence\", \"computer science\", \"automation\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Machine Learning\",\n",
      "      \"definition\": \"Machine learning enables algorithms to learn from data and improve performance without explicit programming.\",\n",
      "      \"difficulty_level\": 3,\n",
      "      \"related_terms\": [\"algorithms\", \"data patterns\", \"supervised learning\", \"unsupervised learning\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Deep Learning\",\n",
      "      \"definition\": \"Deep learning is a type of machine learning that uses multi-layered neural networks to process complex data.\",\n",
      "      \"difficulty_level\": 4,\n",
      "      \"related_terms\": [\"neural networks\", \"layers\", \"image recognition\", \"speech processing\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Natural Language Understanding\",\n",
      "      \"definition\": \"Natural language understanding is the ability of AI systems to comprehend and interpret human language.\",\n",
      "      \"difficulty_level\": 3,\n",
      "      \"related_terms\": [\"NLP\", \"language processing\", \"text analysis\", \"sentiment analysis\"]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Parsed Python object (truncated):\n",
      "{'topic': 'Artificial Intelligence', 'key_concepts': [{'name': 'Artificial Intelligence (AI)', 'definition': 'AI is the creation of computer systems capable of performing tasks that typically require human intelligence.', 'difficulty_level': 2, 'related_terms': ['human intelligence', 'computer science', 'automation']}, {'name': 'Machine Learning', 'definition': 'Machine learning enables algorithms to learn from data and improve performance without explicit programming.', 'difficulty_level': 3, 'related_terms': ['algorithms', 'data patterns', 'supervised learning', 'unsupervised learning']}, {'name': 'Deep Learning', 'definition': 'Deep learning is a type of machine learning that uses multi-layered neural networks to process complex data.', 'difficulty_level': 4, 'related_terms': ['neural networks', 'layers', 'image recognition', 'speech processing']}, {'name': 'Natural Language Understanding', 'definition': 'Natural language understanding is the ability of AI systems to comprehend and interpret human language.', 'difficulty_level': 3, 'related_terms': ['NLP', 'language processing', 'text analysis', 'sentiment analysis']}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Discussion\\n- 這個 schema 跟前面示範完全不同：\\n  - 不再分成 \"topic_name / subsections\"，而是用 **ConceptSummary → key_concepts → Concept** 的階層。\\n  - 每個 concept 都有：名稱、定義、主觀難度（整數）、相關關鍵字的 list。\\n- 這種結構很適合之後：\\n  - 轉成 pandas DataFrame 做統計（例如哪些概念最常被標成難度 4–5）；\\n  - 做教學設計（依難度排序、挑出需要補充說明的概念）；\\n  - 當作知識圖譜的節點與邊（name 與 related_terms）。\\n- 透過 schema，我們可以把原本自由文字的介紹，轉成 **可程式處理的知識表格**，這就是 structured output 在資料探勘情境中的實際價值。\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Concept(BaseModel):\n",
    "    name: str               \n",
    "    definition: str          \n",
    "    difficulty_level: int   \n",
    "    related_terms: list[str]\n",
    "\n",
    "class ConceptSummary(BaseModel):\n",
    "    topic: str              \n",
    "    key_concepts: list[Concept]\n",
    "\n",
    "\n",
    "input_prompt = [\n",
    "    \"\"\"\n",
    "    You are given an introductory paragraph about Artificial Intelligence.\n",
    "    1. Identify 3–6 important concepts.\n",
    "    2. For each concept, give a short one-sentence definition.\n",
    "    3. Rate the difficulty from 1 (very easy to understand) to 5 (very hard).\n",
    "    4. Add 2–4 related keywords for each concept.\n",
    "\n",
    "    Text:\n",
    "    Artificial intelligence (AI) is a broad field of computer science focused on creating\n",
    "    systems that can perform tasks that normally require human intelligence, such as\n",
    "    perception, decision‑making, and natural language understanding. Modern AI often relies\n",
    "    on machine learning, where algorithms learn patterns from data instead of being explicitly\n",
    "    programmed. Deep learning, a subfield of machine learning, uses neural networks with many\n",
    "    layers to achieve impressive performance in areas like image recognition and speech.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# We ask Gemini to output a JSON structure that matches our custom schema\n",
    "text_response = prompt_gemini(\n",
    "    input_prompt=input_prompt,\n",
    "    schema=ConceptSummary,\n",
    ")\n",
    "print(text_response)\n",
    "\n",
    "import json\n",
    "concept_summary = json.loads(text_response)\n",
    "print(\"\\nParsed Python object (truncated):\")\n",
    "print(concept_summary)\n",
    "\n",
    "\"\"\"Discussion\n",
    "- 這個 schema 跟前面示範完全不同：\n",
    "  - 不再分成 \"topic_name / subsections\"，而是用 **ConceptSummary → key_concepts → Concept** 的階層。\n",
    "  - 每個 concept 都有：名稱、定義、主觀難度（整數）、相關關鍵字的 list。\n",
    "- 這種結構很適合之後：\n",
    "  - 轉成 pandas DataFrame 做統計（例如哪些概念最常被標成難度 4–5）；\n",
    "  - 做教學設計（依難度排序、挑出需要補充說明的概念）；\n",
    "  - 當作知識圖譜的節點與邊（name 與 related_terms）。\n",
    "- 透過 schema，我們可以把原本自由文字的介紹，轉成 **可程式處理的知識表格**，這就是 structured output 在資料探勘情境中的實際價值。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_7_'></a>[**2.3 Information Extraction and Grounding:**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "When using LLMs to extract structured data from text, two main challenges arise:\n",
    "\n",
    "1.  **Trust:** LLMs can \"hallucinate\" or invent information. We need to ensure the extracted data is accurate and comes directly from the source text.\n",
    "2.  **Scalability:** We need a reliable way to extract complex information consistently from thousands of large, messy documents.\n",
    "\n",
    "The solution to these challenges is **grounding**—the process of linking every piece of extracted data back to its specific origin in the source document. This creates a verifiable audit trail, building trust in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`: A Library for Grounded Extraction**](#toc0_)\n",
    "\n",
    "**`langextract`** is an open-source Python library from Google designed to create trustworthy data extraction pipelines. It uses LLMs to convert unstructured text into structured data with a focus on reliability and traceability.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Precise Grounding:** Its core feature. It maps every extracted item to its exact character position in the original text, allowing for easy verification.\n",
    "*   **Reliable Structured Output:** Uses examples (few-shot prompting) to ensure the LLM's output consistently follows a predefined format.\n",
    "*   **Adaptable & No Fine-Tuning:** Can be adapted to any domain (e.g., legal, medical) simply by changing the examples and instructions, without needing to retrain a model.\n",
    "*   **Handles Long Documents:** Built to process lengthy texts that might exceed an LLM's standard context window.\n",
    "*   **Flexible LLM Support:** It is model-agnostic and works with various LLMs like Gemini, OpenAI models, and even local open-source models through Ollama.\n",
    "\n",
    "**`Github repository:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 Using PDF Documents:**](#toc0_)\n",
    "\n",
    "For PDF Document information extraction we are going to use the `pymupdf` library. Documentation: [pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "And then we are going to pass it on to langextract to get insights on the document's content.\n",
    "\n",
    "We can also process documents using Gemini, for more information you can check their documentation: [Document Understanding](https://ai.google.dev/gemini-api/docs/document-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted text from './data/documents/doc_example_review_interstellar.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "\n",
    "pdf_path = \"./data/documents/doc_example_review_interstellar.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\"✓ Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dan Baldwin\n",
      "Group 4\n",
      "Auteur Review - Interstellar \n",
      "I believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \n",
      "to be a very intellectual and imaginative inventive talent.  \n",
      "His style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \n",
      "face, and artistically impresses the audience with how the characters solve their problems. For \n",
      "example, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \n",
      "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
      "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
      "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
      "themselves and corridors spinning, without seeming unrealistic. \n",
      "This brain-racking epic theme is once again evident in ‘Interstellar,’ as Nolan sets his characters \n",
      "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
      "uninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \n",
      "travel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
      "black hole orbiting Saturn can transport them further into space to land on these potential \n",
      "planets. \n",
      "Throughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \n",
      "opportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \n",
      "‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \n",
      "feet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \n",
      "that a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \n",
      "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
      "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
      "At the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \n",
      "tesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \n",
      "which will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \n",
      "The imagination that Nolan possesses and implicates into ‘Interstellar’ is farfetched and \n",
      "wonderful, not only impressing his audience with the appealing visuals he creates, but induces \n",
      "them to think and discuss what is going on due its scientiﬁc depth. Personally, as someone who is \n",
      "bamboozled by the idea of how big the universe is, I ﬁnd it unendingly entertaining to repeatedly \n",
      "watch this ﬁlm and understanding it more each time, and can only hope the technology portrayed \n",
      "will one day come true. \n",
      "Overall, ‘Interstellar’ is a clear example of Nolan’s auteur talent, as he once again ﬁgments yet \n",
      "another cluster of conditions for us to marvel at. With a fantastic score from world famous \n",
      "composer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \n",
      "we stress over how we are all going to be saved once again.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our prompt and examples based on our required type of data, in this case we are going to do it having `movie reviews` in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langextract\n",
      "  Downloading langextract-1.1.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.4.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (3.13.2)\n",
      "Collecting async_timeout>=4.0.0 (from langextract)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting exceptiongroup>=1.1.0 (from langextract)\n",
      "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-genai>=1.39.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.52.0)\n",
      "Requirement already satisfied: google-cloud-storage>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (3.6.0)\n",
      "Collecting ml-collections>=0.1.0 (from langextract)\n",
      "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: more-itertools>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (10.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.2.2)\n",
      "Requirement already satisfied: pydantic>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.12.3)\n",
      "Requirement already satisfied: python-dotenv>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.2.1)\n",
      "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (6.0.3)\n",
      "Requirement already satisfied: regex>=2023.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (4.15.0)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting exceptiongroup>=1.1.0 (from langextract)\n",
      "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-genai>=1.39.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.52.0)\n",
      "Requirement already satisfied: google-cloud-storage>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (3.6.0)\n",
      "Collecting ml-collections>=0.1.0 (from langextract)\n",
      "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: more-itertools>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (10.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.2.2)\n",
      "Requirement already satisfied: pydantic>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.12.3)\n",
      "Requirement already satisfied: python-dotenv>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.2.1)\n",
      "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (6.0.3)\n",
      "Requirement already satisfied: regex>=2023.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.43.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (4.11.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (15.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (2025.11.12)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai>=1.39.0->langextract) (1.3.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage>=2.14.0->langextract) (1.72.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage>=2.14.0->langextract) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage>=2.14.0->langextract) (1.26.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (4.9.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai>=1.39.0->langextract) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai>=1.39.0->langextract) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->langextract) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.43.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage>=2.14.0->langextract) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (4.11.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai>=1.39.0->langextract) (15.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (2025.11.12)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai>=1.39.0->langextract) (1.3.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage>=2.14.0->langextract) (1.72.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage>=2.14.0->langextract) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage>=2.14.0->langextract) (1.26.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (4.9.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai>=1.39.0->langextract) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai>=1.39.0->langextract) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->langextract) (1.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (0.6.1)\n",
      "Downloading langextract-1.1.1-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage>=2.14.0->langextract) (0.6.1)\n",
      "Downloading langextract-1.1.1-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ml-collections, exceptiongroup, async_timeout, langextract\n",
      "Installing collected packages: ml-collections, exceptiongroup, async_timeout, langextract\n",
      "Successfully installed async_timeout-5.0.1 exceptiongroup-1.3.1 langextract-1.1.1 ml-collections-1.1.0\n",
      "Successfully installed async_timeout-5.0.1 exceptiongroup-1.3.1 langextract-1.1.1 ml-collections-1.1.0\n"
     ]
    }
   ],
   "source": [
    "%pip install langextract\n",
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our main function to call for langextract information extraction, note that there are some constants in the functions that we are not going to change for the example but it would be required to explore and understand in the exercise. In this function we obtain the resulting raw extracted information into a .jsonl file and the visualization into a .html file. Check the documentation for more information.\n",
    "\n",
    "The files will be saved in the following directory: `results/info_extractions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "\n",
    "# We define our main langextract function \n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 1, max_workers = 5, max_char_buffer = 2000):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # Improves recall through multiple passes over the same text, needs temperature above 0.0\n",
    "        max_workers=max_workers,         # Parallel processing for speed, remember there are API call rate limits, so do not abuse\n",
    "        max_char_buffer=max_char_buffer    # Smaller contexts for better accuracy, currently: 1000 characters per batch\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Extracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\"• {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save results to JSONL\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(f\"{output_dir}/{file_name}.jsonl\")\n",
    "    with open(f\"{output_dir}/{file_name}_vis.html\", \"w\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\"✓ Visualization saved to {output_dir}/{file_name}_vis.html\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: model=\u001b[92mgemini-2.5-flash-lite\u001b[0m, current=\u001b[92m3,199\u001b[0m chars, processed=\u001b[92m0\u001b[0m chars:  [00:03]\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: model=\u001b[92mgemini-2.5-flash-lite\u001b[0m, current=\u001b[92m3,199\u001b[0m chars, processed=\u001b[92m0\u001b[0m chars:  [00:03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13 entities:\n",
      "\n",
      "• opinion_statement: 'a very intellectual and imaginative inventive talent'\n",
      "  - subject: Christopher Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: very intellectual and imaginative inventive talent\n",
      "• opinion_statement: 'artistically impresses the audience'\n",
      "  - subject: Nolan's style\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: artistically impresses\n",
      "• opinion_statement: 'This brain-racking epic theme is once again evident in ‘Interstellar,’'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: brain-racking epic theme\n",
      "• opinion_statement: 'crazy scenarios'\n",
      "  - subject: Nolan's mind\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazy\n",
      "• opinion_statement: 'Not threatening at all right?'\n",
      "  - subject: The planet\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Not threatening at all\n",
      "• opinion_statement: 'a giant 100ft tidal wave is about to hit them'\n",
      "  - subject: The tidal wave\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: giant 100ft tidal wave\n",
      "• audience_impact: 'minutes to ﬂy away'\n",
      "  - emotion_evoked: ['stress', 'urgency']\n",
      "  - causal_element: The tidal wave\n",
      "  - target_audience: the crew\n",
      "• opinion_statement: 'farfetched and wonderful'\n",
      "  - subject: The imagination that Nolan possesses and implicates into ‘Interstellar’\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: farfetched and wonderful\n",
      "• audience_impact: 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientiﬁc depth'\n",
      "  - emotion_evoked: ['impressed', 'thoughtful', 'engaged']\n",
      "  - causal_element: The appealing visuals and scientific depth\n",
      "  - target_audience: his audience\n",
      "• audience_impact: 'I ﬁnd it unendingly entertaining to repeatedly watch this ﬁlm and understanding it more each time'\n",
      "  - emotion_evoked: ['entertained', 'intellectually stimulated']\n",
      "  - causal_element: The film's complexity and depth\n",
      "  - target_audience: the reviewer\n",
      "• opinion_statement: 'a clear example of Nolan’s auteur talent'\n",
      "  - subject: ‘Interstellar’\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: clear example of Nolan’s auteur talent\n",
      "• opinion_statement: 'fantastic score'\n",
      "  - subject: The score\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: fantastic\n",
      "• audience_impact: 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again'\n",
      "  - emotion_evoked: ['captivated', 'stressed']\n",
      "  - causal_element: His epic, orchestral theme\n",
      "  - target_audience: the audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mreview_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 615.36 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mreview_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mreview_extraction_example.jsonl\u001b[0m: 100%|██████████| 8.58k/8.58k [00:00<00:00, 17.5MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mreview_extraction_example.jsonl\u001b[0m\n",
      "✓ Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n",
      "✓ Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"review_extraction_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a very intellectual and imaginative inventive talent',\n",
       "   'char_interval': {'start_pos': 172, 'end_pos': 224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Christopher Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'very intellectual and imaginative inventive talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'artistically impresses the audience',\n",
       "   'char_interval': {'start_pos': 338, 'end_pos': 373},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's style\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'artistically impresses'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'This brain-racking epic theme is once again evident in ‘Interstellar,’',\n",
       "   'char_interval': {'start_pos': 878, 'end_pos': 948},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'brain-racking epic theme'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'crazy scenarios',\n",
       "   'char_interval': {'start_pos': 1484, 'end_pos': 1499},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's mind\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Not threatening at all right?',\n",
       "   'char_interval': {'start_pos': 1676, 'end_pos': 1705},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The planet',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Not threatening at all'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a giant 100ft tidal wave is about to hit them',\n",
       "   'char_interval': {'start_pos': 1764, 'end_pos': 1809},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The tidal wave',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'giant 100ft tidal wave'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'minutes to ﬂy away',\n",
       "   'char_interval': {'start_pos': 1825, 'end_pos': 1843},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['stress', 'urgency'],\n",
       "    'causal_element': 'The tidal wave',\n",
       "    'target_audience': 'the crew'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'farfetched and wonderful',\n",
       "   'char_interval': {'start_pos': 2418, 'end_pos': 2443},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The imagination that Nolan possesses and implicates into ‘Interstellar’',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'farfetched and wonderful'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientiﬁc depth',\n",
       "   'char_interval': {'start_pos': 2445, 'end_pos': 2596},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['impressed', 'thoughtful', 'engaged'],\n",
       "    'causal_element': 'The appealing visuals and scientific depth',\n",
       "    'target_audience': 'his audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'I ﬁnd it unendingly entertaining to repeatedly watch this ﬁlm and understanding it more each time',\n",
       "   'char_interval': {'start_pos': 2680, 'end_pos': 2778},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['entertained',\n",
       "     'intellectually stimulated'],\n",
       "    'causal_element': \"The film's complexity and depth\",\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a clear example of Nolan’s auteur talent',\n",
       "   'char_interval': {'start_pos': 2876, 'end_pos': 2916},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': '‘Interstellar’',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'clear example of Nolan’s auteur talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'fantastic score',\n",
       "   'char_interval': {'start_pos': 3006, 'end_pos': 3021},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The score',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'fantastic'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again',\n",
       "   'char_interval': {'start_pos': 3090, 'end_pos': 3195},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['captivated', 'stressed'],\n",
       "    'causal_element': 'His epic, orchestral theme',\n",
       "    'target_audience': 'the audience'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nDan Baldwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \\nto be a very intellectual and imaginative inventive talent.  \\nHis style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience with how the characters solve their problems. For \\nexample, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in ‘Interstellar,’ as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \\ntravel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \\nblack hole orbiting Saturn can transport them further into space to land on these potential \\nplanets. \\nThroughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \\nopportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \\n‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \\nAt the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \\ntesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \\nwhich will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into ‘Interstellar’ is farfetched and \\nwonderful, not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scientiﬁc depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I ﬁnd it unendingly entertaining to repeatedly \\nwatch this ﬁlm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, ‘Interstellar’ is a clear example of Nolan’s auteur talent, as he once again ﬁgments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_c0ff68ff'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# We can also observe the structure of the raw extracted data\n",
    "with open(\"./results/info_extractions/review_extraction_example.jsonl\", \"r\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dan Baldwin\n",
       "Group 4\n",
       "Auteur Review - Interstellar \n",
       "I believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \n",
       "to be <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">a very intellectual and imaginative inventive talent</span>.  \n",
       "His style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \n",
       "face, and <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">artistically impresses the audience</span> with how the characters solve their problems. For \n",
       "example, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \n",
       "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
       "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
       "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
       "themselves and corridors spinning, without seeming unrealistic. \n",
       "<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">This brain-racking epic theme is once again evident in ‘Interstellar,’</span> as Nolan sets his characters \n",
       "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
       "uninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \n",
       "travel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
       "black hole orbiting Saturn can transport them further into space to land on these potential \n",
       "planets. \n",
       "Throughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \n",
       "opportunities to create <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">crazy scenarios</span>. For example, one planet that Cooper and his friends, \n",
       "‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \n",
       "feet deep water. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Not threatening at all right?</span> Well think again, because the crew suddenly ﬁnd out \n",
       "that <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">a giant 100ft tidal wave is about to hit them</span>, and they have <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#D2E3FC;\">minutes to ﬂy away</span>. Nolan further \n",
       "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
       "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
       "At the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \n",
       "tesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \n",
       "which will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \n",
       "The imagination that Nolan possesses and implicates into ‘Interstellar’ is <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">farfetched and \n",
       "wonderful</span>, <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">not only impressing his audience with the appealing visuals he creates, but induces \n",
       "them to think and discuss what is going on due its scientiﬁc depth</span>. Personally, as someone who is \n",
       "bamboozled by the idea of how big the universe is, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#D2E3FC;\">I ﬁnd it unendingly entertaining to repeatedly \n",
       "watch this ﬁlm and understanding it more each time</span>, and can only hope the technology portrayed \n",
       "will one day come true. \n",
       "Overall, ‘Interstellar’ is <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#C8E6C9;\">a clear example of Nolan’s auteur talent</span>, as he once again ﬁgments yet \n",
       "another cluster of conditions for us to marvel at. With a <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">fantastic score</span> from world famous \n",
       "composer Hanz Zimmer, his epic, orchestral theme <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#D2E3FC;\">sets the audience in the palm of his hands as \n",
       "we stress over how we are all going to be saved once again</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\">▶️ Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\">⏮ Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\">⏭ Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"12\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/13</span> |\n",
       "          Pos <span id=\"posInfo\">[172-224]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"a very intellectual and imaginative inventive talent\", \"color\": \"#C8E6C9\", \"startPos\": 172, \"endPos\": 224, \"beforeText\": \"dwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-\\ufb01/adventure cinematic \\u2018Interstellar,\\u2019 \\nto be \", \"extractionText\": \"a very intellectual and imaginative inventive talent\", \"afterText\": \".  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Christopher Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">very intellectual and imaginative inventive talent</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"artistically impresses the audience\", \"color\": \"#C8E6C9\", \"startPos\": 338, \"endPos\": 373, \"beforeText\": \"ual and imaginative inventive talent.  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and \", \"extractionText\": \"artistically impresses the audience\", \"afterText\": \" with how the characters solve their problems. For \\nexample, in Nolan\\u2019s 2010 \\ufb01lm \\u2018Inception,\\u2019 he tackles the idea of dreams, and sets his characters \\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s style</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">artistically impresses</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"color\": \"#C8E6C9\", \"startPos\": 878, \"endPos\": 948, \"beforeText\": \"lan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\n\", \"extractionText\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"afterText\": \" as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">brain-racking epic theme</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"crazy scenarios\", \"color\": \"#C8E6C9\", \"startPos\": 1484, \"endPos\": 1499, \"beforeText\": \"o land on these potential \\nplanets. \\nThroughout the \\ufb02ick, the crew explore multiple worlds - again feeding Nolan\\u2019s mind more \\nopportunities to create \", \"extractionText\": \"crazy scenarios\", \"afterText\": \". For example, one planet that Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite se\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s mind</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazy</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Not threatening at all right?\", \"color\": \"#C8E6C9\", \"startPos\": 1676, \"endPos\": 1705, \"beforeText\": \"hat Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite sea of two \\nfeet deep water. \", \"extractionText\": \"Not threatening at all right?\", \"afterText\": \" Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to \\ufb02y away. Nolan furt\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Not threatening at all</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"a giant 100ft tidal wave is about to hit them\", \"color\": \"#C8E6C9\", \"startPos\": 1764, \"endPos\": 1809, \"beforeText\": \" initially seems like an in\\ufb01nite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat \", \"extractionText\": \"a giant 100ft tidal wave is about to hit them\", \"afterText\": \", and they have minutes to \\ufb02y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts f\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">giant 100ft tidal wave</span>}</div>\"}, {\"index\": 6, \"class\": \"audience_impact\", \"text\": \"minutes to \\ufb02y away\", \"color\": \"#D2E3FC\", \"startPos\": 1825, \"endPos\": 1843, \"beforeText\": \" Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have \", \"extractionText\": \"minutes to \\ufb02y away\", \"afterText\": \". Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning \", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">stress, urgency</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the crew</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"farfetched and wonderful\", \"color\": \"#C8E6C9\", \"startPos\": 2418, \"endPos\": 2443, \"beforeText\": \" human race bend space-time in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is \", \"extractionText\": \"farfetched and \\nwonderful\", \"afterText\": \", not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c de\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">farfetched and wonderful</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scienti\\ufb01c depth\", \"color\": \"#D2E3FC\", \"startPos\": 2445, \"endPos\": 2596, \"beforeText\": \" in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is farfetched and \\nwonderful, \", \"extractionText\": \"not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c depth\", \"afterText\": \". Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">impressed, thoughtful, engaged</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The appealing visuals and scientific depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">his audience</span>}</div>\"}, {\"index\": 9, \"class\": \"audience_impact\", \"text\": \"I \\ufb01nd it unendingly entertaining to repeatedly watch this \\ufb01lm and understanding it more each time\", \"color\": \"#D2E3FC\", \"startPos\": 2680, \"endPos\": 2778, \"beforeText\": \"them to think and discuss what is going on due its scienti\\ufb01c depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, \", \"extractionText\": \"I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and understanding it more each time\", \"afterText\": \", and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">entertained, intellectually stimulated</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The film&#x27;s complexity and depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 10, \"class\": \"opinion_statement\", \"text\": \"a clear example of Nolan\\u2019s auteur talent\", \"color\": \"#C8E6C9\", \"startPos\": 2876, \"endPos\": 2916, \"beforeText\": \" \\nwatch this \\ufb01lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is \", \"extractionText\": \"a clear example of Nolan\\u2019s auteur talent\", \"afterText\": \", as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">clear example of Nolan\\u2019s auteur talent</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"fantastic score\", \"color\": \"#C8E6C9\", \"startPos\": 3006, \"endPos\": 3021, \"beforeText\": \", \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a \", \"extractionText\": \"fantastic score\", \"afterText\": \" from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all goin\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The score</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">fantastic</span>}</div>\"}, {\"index\": 12, \"class\": \"audience_impact\", \"text\": \"sets the audience in the palm of his hands as we stress over how we are all going to be saved once again\", \"color\": \"#D2E3FC\", \"startPos\": 3090, \"endPos\": 3195, \"beforeText\": \"ts yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme \", \"extractionText\": \"sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">captivated, stressed</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">His epic, orchestral theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> Bonus Exercise 3 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Repeat the steps for information extraction using a different movie reviews.\n",
    "1. Search for movie reviews online and save them in a PDF, we suggest **at least 1 page worth of reviews** like in the example.\n",
    "2. Load the PDF and pass them to langextract to extract information from it.\n",
    "3. Display html with the grounded extracted attributes.\n",
    "4. Discuss about the quality of the extracted information with langextract, how could it be improved based on the options the documentation gives that we didn't try?\n",
    "\n",
    "**`Github repository for reference:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_8_'></a>[**2.4 Generating LLM Embeddings:**](#toc0_)\n",
    "\n",
    "LLM embeddings are dense numerical vectors that represent the semantic meaning of text. Generated by Large Language Models, they map words, phrases, or documents into a high-dimensional space where similar concepts are positioned closely together.\n",
    "\n",
    "Their key advantages are:\n",
    "\n",
    "*   **Contextual Understanding:** Unlike older methods, LLM embeddings are contextual. The vector for a word like **\"bank\"** will be different depending on whether it's used in the context of a \"river bank\" or a \"money bank,\" providing a more nuanced representation of language.\n",
    "\n",
    "*   **Versatility from Pre-training:** They are pre-trained on vast amounts of text data. This allows them to generalize effectively across various tasks, such as classification, clustering, and similarity detection. They do not require extensive retraining.\n",
    "\n",
    "<span style=\"color:green\">For the exercise in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "**Now let's generate some embeddings with Gemini for a sample of our dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# Let's define our function to get the embeddings with Gemini\n",
    "def get_gemini_embedding(text: str, model: str=\"gemini-embedding-001\"):\n",
    "    try:\n",
    "        result = client.models.embed_content(model=model, contents=[text])\n",
    "        # 100 requests per minute limit -> 60s / 100 = 0.6s per request\n",
    "        # buffer time to avoid rate limits\n",
    "        time.sleep(0.6)\n",
    "        return result.embeddings\n",
    "    except exceptions.ResourceExhausted as e:\n",
    "        print(f\"Rate limit exceeded. Waiting to retry... Error: {e}\")\n",
    "        time.sleep(5) # Wait for 5 seconds before the next attempt\n",
    "        return get_gemini_embedding(text, model) # Retry the request\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 160 rows from the training set...\n",
      "Sampling 40 rows from the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2000596105.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
      "/tmp/ipython-input-2000596105.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "total_extractions = 200\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train_to_sample = int(total_extractions * train_ratio)\n",
    "n_test_to_sample = int(total_extractions * test_ratio)\n",
    "# We use the text column\n",
    "column_name = 'text'\n",
    "\n",
    "# This function is to get a stratified sample from our data, meaning to have the same distribution of labels as in the full dataset\n",
    "def stratified_sample(df: pd.DataFrame, n_samples: int, stratify_col: str = 'emotion') -> pd.DataFrame:\n",
    "    if n_samples >= len(df):\n",
    "        return df.copy() # Return a copy if requested sample is larger or equal\n",
    "    sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=max(0, int(round(len(x) / len(df) * n_samples))))\n",
    "    )\n",
    "\n",
    "    # Adjust for rounding errors to get the exact number of samples\n",
    "    current_samples = len(sampled_df)\n",
    "    if current_samples < n_samples:\n",
    "        remaining_indices = df.index.difference(sampled_df.index)\n",
    "        additional_samples = df.loc[remaining_indices].sample(n=n_samples - current_samples, random_state=42)\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    elif current_samples > n_samples:\n",
    "        sampled_df = sampled_df.sample(n=n_samples, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "print(f\"Sampling {n_train_to_sample} rows from the training set...\")\n",
    "train_df_new = stratified_sample(train_df, n_train_to_sample, 'emotion')\n",
    "\n",
    "print(f\"Sampling {n_test_to_sample} rows from the test set...\")\n",
    "test_df_new = stratified_sample(test_df, n_test_to_sample, 'emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "emotion\n",
       "fear       51\n",
       "anger      38\n",
       "joy        36\n",
       "sadness    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "emotion\n",
       "fear       13\n",
       "anger      10\n",
       "joy         9\n",
       "sadness     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new training set...\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
    "print(\"\\nGenerating embeddings for the new training set...\")\n",
    "train_df_new['embeddings'] = train_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new test set...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for the new test set...\")\n",
    "test_df_new['embeddings'] = test_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# After getting the embeddings we need to convert the Gemini type ContentDict of the embeddings into a simple list with them\n",
    "train_df_new['embeddings_values'] = train_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n",
    "test_df_new['embeddings_values'] = test_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e0b43cf4-0f12-4a50-b0e3-0c86344ff7d1\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>10682</td>\n",
       "      <td>I can't guess if you holding a grudge against...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.425</td>\n",
       "      <td>[values=[-0.031459652, 0.019137507, 0.00597161...</td>\n",
       "      <td>[-0.031459652, 0.019137507, 0.0059716133, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>10426</td>\n",
       "      <td>@healeyraine I'm offended, I actually am</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.0044557443, 0.019885521, 0.0038159...</td>\n",
       "      <td>[-0.0044557443, 0.019885521, 0.0038159697, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>10594</td>\n",
       "      <td>#welfarereform should not be a 'model' for .</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.019916205, 0.016636321, 0.03204823...</td>\n",
       "      <td>[-0.019916205, 0.016636321, 0.032048233, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10039</td>\n",
       "      <td>So #angry about my @WishShopping order. 6 #mon...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[values=[-0.03212555, -0.014217799, -0.0130373...</td>\n",
       "      <td>[-0.03212555, -0.014217799, -0.01303733, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>10745</td>\n",
       "      <td>@RealJeffsdomain Wolfpack theme and trons and ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.0083146095, -0.01835516, 0.0261475...</td>\n",
       "      <td>[-0.0083146095, -0.01835516, 0.026147552, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>40578</td>\n",
       "      <td>Learning how to use twitter #lost</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[-0.022352856, 0.010469472, 0.00350807...</td>\n",
       "      <td>[-0.022352856, 0.010469472, 0.0035080765, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>40424</td>\n",
       "      <td>Mayor visits downtrodden part o town in brave ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.014248703, 0.006195193, -0.0068827...</td>\n",
       "      <td>[-0.014248703, 0.006195193, -0.006882724, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>40754</td>\n",
       "      <td>Free live music in DC tonight!  #blues with #M...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.188</td>\n",
       "      <td>[values=[-0.021613283, 0.002549998, -0.0064596...</td>\n",
       "      <td>[-0.021613283, 0.002549998, -0.0064596334, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>40366</td>\n",
       "      <td>@HeyCaraJay I am inconsolable at this GIF in c...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.509</td>\n",
       "      <td>[values=[0.002377377, 0.025556833, 0.014487799...</td>\n",
       "      <td>[0.002377377, 0.025556833, 0.014487799, -0.114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>40182</td>\n",
       "      <td>I'd rather die alone then end up with somebody...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.660</td>\n",
       "      <td>[values=[0.0018010327, -0.018456355, -0.026299...</td>\n",
       "      <td>[0.0018010327, -0.018456355, -0.02629938, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0b43cf4-0f12-4a50-b0e3-0c86344ff7d1')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e0b43cf4-0f12-4a50-b0e3-0c86344ff7d1 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e0b43cf4-0f12-4a50-b0e3-0c86344ff7d1');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         id                                               text  emotion  \\\n",
       "682   10682   I can't guess if you holding a grudge against...    anger   \n",
       "426   10426           @healeyraine I'm offended, I actually am    anger   \n",
       "594   10594       #welfarereform should not be a 'model' for .    anger   \n",
       "39    10039  So #angry about my @WishShopping order. 6 #mon...    anger   \n",
       "745   10745  @RealJeffsdomain Wolfpack theme and trons and ...    anger   \n",
       "...     ...                                                ...      ...   \n",
       "3405  40578                  Learning how to use twitter #lost  sadness   \n",
       "3251  40424  Mayor visits downtrodden part o town in brave ...  sadness   \n",
       "3581  40754  Free live music in DC tonight!  #blues with #M...  sadness   \n",
       "3193  40366  @HeyCaraJay I am inconsolable at this GIF in c...  sadness   \n",
       "3009  40182  I'd rather die alone then end up with somebody...  sadness   \n",
       "\n",
       "      intensity                                         embeddings  \\\n",
       "682       0.425  [values=[-0.031459652, 0.019137507, 0.00597161...   \n",
       "426       0.479  [values=[-0.0044557443, 0.019885521, 0.0038159...   \n",
       "594       0.417  [values=[-0.019916205, 0.016636321, 0.03204823...   \n",
       "39        0.771  [values=[-0.03212555, -0.014217799, -0.0130373...   \n",
       "745       0.312  [values=[-0.0083146095, -0.01835516, 0.0261475...   \n",
       "...         ...                                                ...   \n",
       "3405      0.354  [values=[-0.022352856, 0.010469472, 0.00350807...   \n",
       "3251      0.458  [values=[-0.014248703, 0.006195193, -0.0068827...   \n",
       "3581      0.188  [values=[-0.021613283, 0.002549998, -0.0064596...   \n",
       "3193      0.509  [values=[0.002377377, 0.025556833, 0.014487799...   \n",
       "3009      0.660  [values=[0.0018010327, -0.018456355, -0.026299...   \n",
       "\n",
       "                                      embeddings_values  \n",
       "682   [-0.031459652, 0.019137507, 0.0059716133, -0.0...  \n",
       "426   [-0.0044557443, 0.019885521, 0.0038159697, -0....  \n",
       "594   [-0.019916205, 0.016636321, 0.032048233, -0.06...  \n",
       "39    [-0.03212555, -0.014217799, -0.01303733, -0.06...  \n",
       "745   [-0.0083146095, -0.01835516, 0.026147552, -0.0...  \n",
       "...                                                 ...  \n",
       "3405  [-0.022352856, 0.010469472, 0.0035080765, -0.0...  \n",
       "3251  [-0.014248703, 0.006195193, -0.006882724, -0.0...  \n",
       "3581  [-0.021613283, 0.002549998, -0.0064596334, -0....  \n",
       "3193  [0.002377377, 0.025556833, 0.014487799, -0.114...  \n",
       "3009  [0.0018010327, -0.018456355, -0.02629938, -0.0...  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7b519889-00f7-4c16-8835-7b00c711e1c4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>30832</td>\n",
       "      <td>This tweet is dedicated to my back pain, which...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.229</td>\n",
       "      <td>[values=[-0.008182137, 0.0094519975, -0.002431...</td>\n",
       "      <td>[-0.008182137, 0.0094519975, -0.00243182, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>21148</td>\n",
       "      <td>This is #horrible: Lewis Dunk has begun networ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[0.0071067424, 0.001991946, 0.00285590...</td>\n",
       "      <td>[0.0071067424, 0.001991946, 0.0028559023, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10894</td>\n",
       "      <td>i live and die for mchanzo honeymoon crashing ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.0010682619, 0.018157829, -0.005871...</td>\n",
       "      <td>[-0.0010682619, 0.018157829, -0.005871065, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>30892</td>\n",
       "      <td>Sioux Valley wins home competitive #cheer invi...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[0.007781908, -0.007763366, -0.0006368...</td>\n",
       "      <td>[0.007781908, -0.007763366, -0.00063681736, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10881</td>\n",
       "      <td>@DxfyingGrxvity - frustration, looking up at E...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.00797378, -0.014481293, -0.0166578...</td>\n",
       "      <td>[-0.00797378, -0.014481293, -0.01665783, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>40833</td>\n",
       "      <td>@Barcabhoy1 Of course not. Didn't sink his stu...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[0.011736909, 0.018727152, -0.00540291...</td>\n",
       "      <td>[0.011736909, 0.018727152, -0.005402915, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>21254</td>\n",
       "      <td>An adviser to the #European #Union’s top #cour...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.0056551304, 0.0062780394, 0.010923...</td>\n",
       "      <td>[-0.0056551304, 0.0062780394, 0.010923652, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>40854</td>\n",
       "      <td>340:892 All with weary task fordone.\\nNow the ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.010497439, 0.005313204, -0.0098101...</td>\n",
       "      <td>[-0.010497439, 0.005313204, -0.009810179, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>30829</td>\n",
       "      <td>@Casper10666 I assure you there is no laughter...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.167</td>\n",
       "      <td>[values=[-0.008917223, -0.013621849, 0.0017390...</td>\n",
       "      <td>[-0.008917223, -0.013621849, 0.0017390692, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10934</td>\n",
       "      <td>@FluDino Event started! everyone is getting re...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[0.00306014, -0.01875603, 0.016292607,...</td>\n",
       "      <td>[0.00306014, -0.01875603, 0.016292607, -0.0684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>30886</td>\n",
       "      <td>@kwelbyroberts they will come and you will rej...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.008475711, 0.00091937196, -0.00125...</td>\n",
       "      <td>[-0.008475711, 0.00091937196, -0.0012545605, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>21157</td>\n",
       "      <td>There goes the butterflies in my stomach.  #an...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.702</td>\n",
       "      <td>[values=[0.0116475625, -0.010445656, -0.008240...</td>\n",
       "      <td>[0.0116475625, -0.010445656, -0.008240249, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>21256</td>\n",
       "      <td>So about 18mths ago i signed up to @Lumo_Energ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[values=[-0.01801527, -0.009214208, 0.00016266...</td>\n",
       "      <td>[-0.01801527, -0.009214208, 0.00016266719, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10899</td>\n",
       "      <td>Kik to trade, have fun or a conversation  (kik...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.241</td>\n",
       "      <td>[values=[-0.026761461, 0.019656219, -0.0002295...</td>\n",
       "      <td>[-0.026761461, 0.019656219, -0.00022959975, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>21190</td>\n",
       "      <td>Watching It Follows.  This is a super freaky m...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[-0.009260124, 0.01992812, 0.009780536...</td>\n",
       "      <td>[-0.009260124, 0.01992812, 0.009780536, -0.058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>40856</td>\n",
       "      <td>I'd rather laugh with the rarest genius, in be...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[values=[-0.0016530727, 0.0044874516, -0.00701...</td>\n",
       "      <td>[-0.0016530727, 0.0044874516, -0.0070126606, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>21232</td>\n",
       "      <td>@mikefreemanNFL \\nIsn't OBrien supposed to be ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.0012154158, -0.010159548, 0.010861...</td>\n",
       "      <td>[-0.0012154158, -0.010159548, 0.010861144, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>40789</td>\n",
       "      <td>Stars, when you shine,\\nYou know how I feel.\\n...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[0.011783604, 0.007787306, 0.008415056...</td>\n",
       "      <td>[0.011783604, 0.007787306, 0.008415056, -0.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>40800</td>\n",
       "      <td>“Dyslexia is the affliction of a frozen genius...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[0.018854156, 0.0033274922, -0.0072523...</td>\n",
       "      <td>[0.018854156, 0.0033274922, -0.0072523863, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10887</td>\n",
       "      <td>Everybody talking about 'the first day of fall...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.016532253, -0.018671215, 0.0024112...</td>\n",
       "      <td>[-0.016532253, -0.018671215, 0.0024112132, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>30874</td>\n",
       "      <td>@harrietemmett great minds think alike. #rejoice</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.519</td>\n",
       "      <td>[values=[-0.013035271, 0.0017458068, -0.017289...</td>\n",
       "      <td>[-0.013035271, 0.0017458068, -0.017289385, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10906</td>\n",
       "      <td>Just joined #pottermore and was sorted into HU...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[0.0059057474, -0.034324665, 0.0036267...</td>\n",
       "      <td>[0.0059057474, -0.034324665, 0.0036267077, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>21248</td>\n",
       "      <td>@CesarSampao @thisisbolton don't get me starte...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.010776043, -0.010502652, 0.0044182...</td>\n",
       "      <td>[-0.010776043, -0.010502652, 0.0044182716, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10871</td>\n",
       "      <td>Sorry guys I have absolutely no idea what time...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.202</td>\n",
       "      <td>[values=[-0.025927138, 0.0076092225, -0.028915...</td>\n",
       "      <td>[-0.025927138, 0.0076092225, -0.028915087, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>30887</td>\n",
       "      <td>[Moment of levity on the B41] Baby: I want ISI...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-0.0424127, 0.017318571, -0.019188805...</td>\n",
       "      <td>[-0.0424127, 0.017318571, -0.019188805, -0.061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>21206</td>\n",
       "      <td>Dunno y am going to the Yorkshire scare ground...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.812</td>\n",
       "      <td>[values=[-0.008968516, -0.04955138, 0.00320910...</td>\n",
       "      <td>[-0.008968516, -0.04955138, 0.0032091022, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10885</td>\n",
       "      <td>I wouldn't have #anger issues.....if she didn'...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.016306585, -0.025352607, 0.0284566...</td>\n",
       "      <td>[-0.016306585, -0.025352607, 0.028456606, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>30899</td>\n",
       "      <td>@GigaFag @pipertownsend_ snapchat new would be...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[-0.004990889, 0.011567411, -0.0182910...</td>\n",
       "      <td>[-0.004990889, 0.011567411, -0.01829109, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>40827</td>\n",
       "      <td>A3: But chronic sadness may mean there are und...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[values=[0.0032898958, 0.030603174, 0.00228165...</td>\n",
       "      <td>[0.0032898958, 0.030603174, 0.0022816553, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10868</td>\n",
       "      <td>@DailyMirror i love how theres no outrage that...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.726</td>\n",
       "      <td>[values=[-0.020602157, 0.004117812, 0.00657562...</td>\n",
       "      <td>[-0.020602157, 0.004117812, 0.006575624, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>40855</td>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "      <td>[values=[0.0018189758, 0.023590546, -0.0067852...</td>\n",
       "      <td>[0.0018189758, 0.023590546, -0.0067852526, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>30825</td>\n",
       "      <td>Nawaz Sharif is getting more funnier than @kap...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "      <td>[values=[-0.03421193, 0.017039796, 0.028741952...</td>\n",
       "      <td>[-0.03421193, 0.017039796, 0.028741952, -0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>40836</td>\n",
       "      <td>im thoroughly in love w zen and jumin and i do...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[0.00336918, -0.03743703, -0.012332446...</td>\n",
       "      <td>[0.00336918, -0.03743703, -0.012332446, -0.064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21172</td>\n",
       "      <td>@TheDappaMc also £2.50 for a chocolate Feast i...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.0048581217, -0.0056593698, -0.00239...</td>\n",
       "      <td>[0.0048581217, -0.0056593698, -0.0023954825, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>21155</td>\n",
       "      <td>If my concerns &amp;amp; anxiety don't matter to y...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.729</td>\n",
       "      <td>[values=[-0.02349053, -0.000944749, -0.0057726...</td>\n",
       "      <td>[-0.02349053, -0.000944749, -0.0057726167, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>21215</td>\n",
       "      <td>When you're scared to press send #bgoodthepoet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.842</td>\n",
       "      <td>[values=[-0.0022556814, -0.012241578, 0.005042...</td>\n",
       "      <td>[-0.0022556814, -0.012241578, 0.0050421893, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>21191</td>\n",
       "      <td>They'll be yo friend, shake your hand, then ki...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[0.008659948, -0.0070254644, -0.011189...</td>\n",
       "      <td>[0.008659948, -0.0070254644, -0.0111895, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10880</td>\n",
       "      <td>@TrueAggieFan oh so that's where Brian was! Wh...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.037104376, -0.016576506, -0.019182...</td>\n",
       "      <td>[-0.037104376, -0.016576506, -0.019182565, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>21193</td>\n",
       "      <td>Came in to work today 1.5 hours late.1st thing...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[values=[-0.014280062, 0.00909578, -0.02008236...</td>\n",
       "      <td>[-0.014280062, 0.00909578, -0.020082366, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>30850</td>\n",
       "      <td>Imagine how sad LA fans are gona be when they ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[-0.004037361, -0.00066357036, 0.00229...</td>\n",
       "      <td>[-0.004037361, -0.00066357036, 0.0022901418, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b519889-00f7-4c16-8835-7b00c711e1c4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7b519889-00f7-4c16-8835-7b00c711e1c4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7b519889-00f7-4c16-8835-7b00c711e1c4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        id                                               text  emotion  \\\n",
       "203  30832  This tweet is dedicated to my back pain, which...      joy   \n",
       "85   21148  This is #horrible: Lewis Dunk has begun networ...     fear   \n",
       "37   10894  i live and die for mchanzo honeymoon crashing ...    anger   \n",
       "263  30892  Sioux Valley wins home competitive #cheer invi...      joy   \n",
       "24   10881  @DxfyingGrxvity - frustration, looking up at E...    anger   \n",
       "320  40833  @Barcabhoy1 Of course not. Didn't sink his stu...  sadness   \n",
       "191  21254  An adviser to the #European #Union’s top #cour...     fear   \n",
       "341  40854  340:892 All with weary task fordone.\\nNow the ...  sadness   \n",
       "200  30829  @Casper10666 I assure you there is no laughter...      joy   \n",
       "77   10934  @FluDino Event started! everyone is getting re...    anger   \n",
       "257  30886  @kwelbyroberts they will come and you will rej...      joy   \n",
       "94   21157  There goes the butterflies in my stomach.  #an...     fear   \n",
       "193  21256  So about 18mths ago i signed up to @Lumo_Energ...     fear   \n",
       "42   10899  Kik to trade, have fun or a conversation  (kik...    anger   \n",
       "127  21190  Watching It Follows.  This is a super freaky m...     fear   \n",
       "343  40856  I'd rather laugh with the rarest genius, in be...  sadness   \n",
       "169  21232  @mikefreemanNFL \\nIsn't OBrien supposed to be ...     fear   \n",
       "276  40789  Stars, when you shine,\\nYou know how I feel.\\n...  sadness   \n",
       "287  40800  “Dyslexia is the affliction of a frozen genius...  sadness   \n",
       "30   10887  Everybody talking about 'the first day of fall...    anger   \n",
       "245  30874   @harrietemmett great minds think alike. #rejoice      joy   \n",
       "49   10906  Just joined #pottermore and was sorted into HU...    anger   \n",
       "185  21248  @CesarSampao @thisisbolton don't get me starte...     fear   \n",
       "14   10871  Sorry guys I have absolutely no idea what time...    anger   \n",
       "258  30887  [Moment of levity on the B41] Baby: I want ISI...      joy   \n",
       "143  21206  Dunno y am going to the Yorkshire scare ground...     fear   \n",
       "28   10885  I wouldn't have #anger issues.....if she didn'...    anger   \n",
       "270  30899  @GigaFag @pipertownsend_ snapchat new would be...      joy   \n",
       "314  40827  A3: But chronic sadness may mean there are und...  sadness   \n",
       "11   10868  @DailyMirror i love how theres no outrage that...    anger   \n",
       "342  40855  Common app just randomly logged me out as I wa...  sadness   \n",
       "196  30825  Nawaz Sharif is getting more funnier than @kap...      joy   \n",
       "323  40836  im thoroughly in love w zen and jumin and i do...  sadness   \n",
       "109  21172  @TheDappaMc also £2.50 for a chocolate Feast i...     fear   \n",
       "92   21155  If my concerns &amp; anxiety don't matter to y...     fear   \n",
       "152  21215  When you're scared to press send #bgoodthepoet...     fear   \n",
       "128  21191  They'll be yo friend, shake your hand, then ki...     fear   \n",
       "23   10880  @TrueAggieFan oh so that's where Brian was! Wh...    anger   \n",
       "130  21193  Came in to work today 1.5 hours late.1st thing...     fear   \n",
       "221  30850  Imagine how sad LA fans are gona be when they ...      joy   \n",
       "\n",
       "     intensity                                         embeddings  \\\n",
       "203      0.229  [values=[-0.008182137, 0.0094519975, -0.002431...   \n",
       "85       0.479  [values=[0.0071067424, 0.001991946, 0.00285590...   \n",
       "37       0.479  [values=[-0.0010682619, 0.018157829, -0.005871...   \n",
       "263      0.583  [values=[0.007781908, -0.007763366, -0.0006368...   \n",
       "24       0.604  [values=[-0.00797378, -0.014481293, -0.0166578...   \n",
       "320      0.396  [values=[0.011736909, 0.018727152, -0.00540291...   \n",
       "191      0.500  [values=[-0.0056551304, 0.0062780394, 0.010923...   \n",
       "341      0.458  [values=[-0.010497439, 0.005313204, -0.0098101...   \n",
       "200      0.167  [values=[-0.008917223, -0.013621849, 0.0017390...   \n",
       "77       0.521  [values=[0.00306014, -0.01875603, 0.016292607,...   \n",
       "257      0.458  [values=[-0.008475711, 0.00091937196, -0.00125...   \n",
       "94       0.702  [values=[0.0116475625, -0.010445656, -0.008240...   \n",
       "193      0.271  [values=[-0.01801527, -0.009214208, 0.00016266...   \n",
       "42       0.241  [values=[-0.026761461, 0.019656219, -0.0002295...   \n",
       "127      0.708  [values=[-0.009260124, 0.01992812, 0.009780536...   \n",
       "343      0.688  [values=[-0.0016530727, 0.0044874516, -0.00701...   \n",
       "169      0.479  [values=[-0.0012154158, -0.010159548, 0.010861...   \n",
       "276      0.292  [values=[0.011783604, 0.007787306, 0.008415056...   \n",
       "287      0.333  [values=[0.018854156, 0.0033274922, -0.0072523...   \n",
       "30       0.417  [values=[-0.016532253, -0.018671215, 0.0024112...   \n",
       "245      0.519  [values=[-0.013035271, 0.0017458068, -0.017289...   \n",
       "49       0.708  [values=[0.0059057474, -0.034324665, 0.0036267...   \n",
       "185      0.479  [values=[-0.010776043, -0.010502652, 0.0044182...   \n",
       "14       0.202  [values=[-0.025927138, 0.0076092225, -0.028915...   \n",
       "258      0.521  [values=[-0.0424127, 0.017318571, -0.019188805...   \n",
       "143      0.812  [values=[-0.008968516, -0.04955138, 0.00320910...   \n",
       "28       0.500  [values=[-0.016306585, -0.025352607, 0.0284566...   \n",
       "270      0.396  [values=[-0.004990889, 0.011567411, -0.0182910...   \n",
       "314      0.562  [values=[0.0032898958, 0.030603174, 0.00228165...   \n",
       "11       0.726  [values=[-0.020602157, 0.004117812, 0.00657562...   \n",
       "342      0.833  [values=[0.0018189758, 0.023590546, -0.0067852...   \n",
       "196      0.580  [values=[-0.03421193, 0.017039796, 0.028741952...   \n",
       "323      0.458  [values=[0.00336918, -0.03743703, -0.012332446...   \n",
       "109      0.438  [values=[0.0048581217, -0.0056593698, -0.00239...   \n",
       "92       0.729  [values=[-0.02349053, -0.000944749, -0.0057726...   \n",
       "152      0.842  [values=[-0.0022556814, -0.012241578, 0.005042...   \n",
       "128      0.417  [values=[0.008659948, -0.0070254644, -0.011189...   \n",
       "23       0.417  [values=[-0.037104376, -0.016576506, -0.019182...   \n",
       "130      0.896  [values=[-0.014280062, 0.00909578, -0.02008236...   \n",
       "221      0.333  [values=[-0.004037361, -0.00066357036, 0.00229...   \n",
       "\n",
       "                                     embeddings_values  \n",
       "203  [-0.008182137, 0.0094519975, -0.00243182, -0.0...  \n",
       "85   [0.0071067424, 0.001991946, 0.0028559023, -0.0...  \n",
       "37   [-0.0010682619, 0.018157829, -0.005871065, -0....  \n",
       "263  [0.007781908, -0.007763366, -0.00063681736, -0...  \n",
       "24   [-0.00797378, -0.014481293, -0.01665783, -0.07...  \n",
       "320  [0.011736909, 0.018727152, -0.005402915, -0.06...  \n",
       "191  [-0.0056551304, 0.0062780394, 0.010923652, -0....  \n",
       "341  [-0.010497439, 0.005313204, -0.009810179, -0.0...  \n",
       "200  [-0.008917223, -0.013621849, 0.0017390692, -0....  \n",
       "77   [0.00306014, -0.01875603, 0.016292607, -0.0684...  \n",
       "257  [-0.008475711, 0.00091937196, -0.0012545605, -...  \n",
       "94   [0.0116475625, -0.010445656, -0.008240249, -0....  \n",
       "193  [-0.01801527, -0.009214208, 0.00016266719, -0....  \n",
       "42   [-0.026761461, 0.019656219, -0.00022959975, -0...  \n",
       "127  [-0.009260124, 0.01992812, 0.009780536, -0.058...  \n",
       "343  [-0.0016530727, 0.0044874516, -0.0070126606, -...  \n",
       "169  [-0.0012154158, -0.010159548, 0.010861144, -0....  \n",
       "276  [0.011783604, 0.007787306, 0.008415056, -0.080...  \n",
       "287  [0.018854156, 0.0033274922, -0.0072523863, -0....  \n",
       "30   [-0.016532253, -0.018671215, 0.0024112132, -0....  \n",
       "245  [-0.013035271, 0.0017458068, -0.017289385, -0....  \n",
       "49   [0.0059057474, -0.034324665, 0.0036267077, -0....  \n",
       "185  [-0.010776043, -0.010502652, 0.0044182716, -0....  \n",
       "14   [-0.025927138, 0.0076092225, -0.028915087, -0....  \n",
       "258  [-0.0424127, 0.017318571, -0.019188805, -0.061...  \n",
       "143  [-0.008968516, -0.04955138, 0.0032091022, -0.0...  \n",
       "28   [-0.016306585, -0.025352607, 0.028456606, -0.0...  \n",
       "270  [-0.004990889, 0.011567411, -0.01829109, -0.07...  \n",
       "314  [0.0032898958, 0.030603174, 0.0022816553, -0.0...  \n",
       "11   [-0.020602157, 0.004117812, 0.006575624, -0.06...  \n",
       "342  [0.0018189758, 0.023590546, -0.0067852526, -0....  \n",
       "196  [-0.03421193, 0.017039796, 0.028741952, -0.085...  \n",
       "323  [0.00336918, -0.03743703, -0.012332446, -0.064...  \n",
       "109  [0.0048581217, -0.0056593698, -0.0023954825, -...  \n",
       "92   [-0.02349053, -0.000944749, -0.0057726167, -0....  \n",
       "152  [-0.0022556814, -0.012241578, 0.0050421893, -0...  \n",
       "128  [0.008659948, -0.0070254644, -0.0111895, -0.04...  \n",
       "23   [-0.037104376, -0.016576506, -0.019182565, -0....  \n",
       "130  [-0.014280062, 0.00909578, -0.020082366, -0.05...  \n",
       "221  [-0.004037361, -0.00066357036, 0.0022901418, -...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them to pickle files\n",
    "train_df_new.to_pickle(\"./data/train_df_sample_embeddings.pkl\") \n",
    "test_df_new.to_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load the pickle files\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_new.iloc[0][\"embeddings_values\"]) # Gemini embedding dimension is 3072 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"59dea144-cbc3-40ac-b68c-53792a729fa1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"59dea144-cbc3-40ac-b68c-53792a729fa1\")) {                    Plotly.newPlot(                        \"59dea144-cbc3-40ac-b68c-53792a729fa1\",                        [{\"customdata\":[[\" I can't guess if you holding a grudge against the best'\",0.425],[\"@healeyraine I'm offended, I actually am\",0.479],[\"#welfarereform should not be a 'model' for .\",0.417],[\"So #angry about my @WishShopping order. 6 #months ago I placed an order of over $500. Card billed. Never #received \\\\n#disappointing\",0.771],[\"@RealJeffsdomain Wolfpack theme and trons and sting wore the wolf shirt\",0.312],[\"@realDonaldTrump: No sense in taking out your wrath on innocent people because you think police shot an innocent man. #MakeAmericaSafeAgain\",0.479],[\"As your own lives in order to complete our amazing life journey successfully, it is there. #bitter\",0.417],[\"@lesyoung01 a rabid dog being ridden by the child who has eaten all the flesh off one fellow and the limbs of the other adults.\",0.583],[\"@nytopinion  The point of voting for Trump to push all the pieces off the board game like an angry toddler? Wreck everything for everybody?\",0.562],[\"Tasers immobilize, if you taser someone why the fuck do you need to shoot them one second later?! This is really sick!  #wtf #murder\",0.729],[\"Sorry to burst your bubble but it isn't that century anymore. Welcome to the 21st century.\",0.354],[\"Like hello? I am your first born you must always laugh at my jokes. \",0.324],[\"@RegalisAzura \\\\ngrasp the cobalt woman's own; which they did fairly easily. Fair cheeks would ignite into a fiery hue. Warm.. was the only\",0.438],[\"I have 1000 rabid grizzly bears I'm going to scatter in neighborhoods all over America.\\\\n\\\\nThey're poor refugees!\\\\n\\\\n#InYourNeighborhoodNotDC\",0.646],[\"@DeltaDomain @SawDraze @qurions dis dat nigga from fume right?\",0.417],[\"straight people are canoodling on the quad and I'm #offended\",0.648],[\"never #make a decision when you are .. #angry &gt;_&lt; .... and never make a #promis when you are #happy :) :*\",0.521],[\"Seeing #RIPShawtyLo got me thinking bout other rappers then I thought about @LilTunechi dying, and burst into tears... Smh\",0.417],[\"@LisaAsquithtobe @craig8710 @WayneHaselden @june65wigan everyone is against wigan because we are the biggest club \",0.354],[\"@BosNaud so scared to ruffle feathers, he resorted to writing in cryptic code. #UncleCamsCabin\",0.5],[\"Have wee pop socks on and they KEEP FALLING OFF INSIDE MY SHOES \",0.562],[\"The most important thing to #bestrong is to hold your  #thoughts\",0.147],[\"@JuliaHB1 Bloody right \",0.562],[\"Thatmoment you're watching #worstcelebritycooks and your bubble is burst by finding out KyleXY is gay and married😭 #nochance #KindaDontMind😉\",0.479],[\"My mind is raging and i just want to end it all\",0.75],[\"“He who is slow to anger is better than the mighty, And he who rules his spirit than he who takes a city.”\\\\nP16:32 #bibleverse #pride #anger\",0.314],[\"@IrishTimesPol @IrishTimes Irish citizens boiling drinking water in 2016 leaves one foot firmly in the bog!\",0.542],[\"Holding a #grudge doesn't make you #strong; it makes you #bitter. #Forgiving doesn't make you #weak; it sets you #free.\",0.312],[\"Kik me I want to swap pics I will post on my account anonymously if you wish Kik: vsvplou #Kik #kikme #snap #nudes #tits #snapchat\",0.292],[\"I wish the next madden has a story mode too. Just like Fifa 17 #madden\",0.312],[\"@clarechampion @Westclarepage and peter your radio piece on off the ball was pure class , no digs , no revenge , a total balanced pro ! 👏👏👏\",0.438],[\"@cc_yandian @HillaryClinton her team must draw from a hat for daily personality #drugged  #yeller #quiet #screamer #😂😂\",0.521],[\"A wise man told me that holdin' a grudge is like\\\\nLetting somebody just live inside of your head rent free\",0.354],[\"@johnaugust @clmazin I was so looking forward to @ABCDesignated. Then it opened with a #stuartspecial. I literally yelled at my tv. #umbrage\",0.521],[\"I wish the next madden has a story mode too. Just like Fifa 17 \",0.292],[\"“He who is slow to anger is better than the mighty, And he who rules his spirit than he who takes a city.”\\\\nP16:32 #bibleverse #pride \",0.354],[\"@PatVPeters @FreeBeacon Quite the response of retaliation from Weiner in getting revenge on Huma &amp; Hillary 'clam digging'.\\\\n#AllScumbags\",0.5],[\"Y'all really insult coz of soccer???  Lmao, wow!!!!!!\",0.396],[\"i live and die for mchanzo honeymoon crashing and burning the second they move in together\",0.479],[\"@DxfyingGrxvity - frustration, looking up at Elphaba in a frown of aggravation. Her high pitched voice was growing more and more --\",0.604],[\"@FluDino Event started! everyone is getting ready to travel to the lake of rage, where everything glows\",0.521],[\"Kik to trade, have fun or a conversation  (kik: youraffair) #kik #kikme #messageme #textme #pics #trade #tradepics #dm  #bored\",0.241],[\"Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake\",0.417],[\"Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 #fuming\",0.708],[\"Sorry guys I have absolutely no idea what time i'll be on cam tomorrow but will keep you posted. \",0.202],[\"I wouldn't have #anger issues.....if she didn't have #lying issues.....think about that one. #pow #lies #confusion\",0.5],[\"@DailyMirror i love how theres no outrage that it's a white man but if it was a black man them BLM would be all over it regardless of reason\",0.726],[\"@TrueAggieFan oh so that's where Brian was! Where was my invite? #offended\",0.417]],\"hovertemplate\":\"emotion=anger\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"anger\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"anger\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.6278706,3.164672,4.347459,3.4792974,2.6070805,5.2877307,2.7523735,4.0333643,5.076159,5.5682583,1.812951,3.6611776,2.6981661,4.6446176,2.4740138,3.1146228,2.4145968,1.1261052,4.154565,3.6948304,1.2326375,2.2195673,4.2768383,2.8643734,1.200625,2.52031,4.4050303,2.388898,3.087828,0.6287434,4.236456,4.840107,2.2977445,3.1160882,0.5738048,2.4695547,5.0553155,4.2203474,2.297775,2.7829976,2.9763186,2.8775332,3.3387482,3.260941,1.6593852,2.3253431,5.681725,3.3681908],\"xaxis\":\"x\",\"y\":[5.175123,6.333195,4.7729626,7.468549,4.7295775,5.679193,4.6877046,5.531925,5.814062,5.978289,4.1637044,4.2040753,3.7772121,5.6605988,4.1393533,6.3371544,5.8556523,4.639351,5.9957104,5.2094765,5.059217,5.606602,4.8628836,6.221222,5.482362,5.7817764,4.499592,5.5397353,2.208681,4.1120143,4.0519114,5.833811,5.346242,6.7783003,4.085166,5.7409997,5.972074,6.214074,4.9364986,5.2807975,3.7096128,2.3299997,5.4111614,7.1624956,3.8773699,5.9485183,5.5407205,6.428379],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"GUY was such a video I'm shaking @ladygaga\",0.375],[\"anxiety level- 100\",0.905],[\"Have to say that third City kit is fucking awful. Someone at Nike wants shooting.\",0.521],[\"jesus ok an alarming percentage of my teachers ths year dont have a  s ingle thoughtful bone in their bodies . its gonna b an interesting yr\",0.565],[\"Saga: When all of your devices and teles fail just in time for bake off  #gbbo\",0.583],[\"Wishing i was rich so i didnt have to get up this morning #poor #sleepy  #sad #needsmoresleep\",0.562],[\"Fear blocks blessings, faith unlocks them. #ManUp #fear #faith\",0.388],[\"@TheDuranSite Russian mistrust of the U.S is well justified &amp; the precaution they've taken are very prudent.\",0.375],[\"@Zen1dfabflake You are all our angelic comrades! #flutter\",0.125],[\"@JogglingDroid @BrancoCarmine @Otto_English yeah, #UK was quite the \",0.25],[\"I really wanna go to fright fest 😩\",0.333],[\"a panic attack AND CALL YOURSELF A REAL FAN makes me so mad like i dont even have the words to explain. this is why some people give no +\",0.646],[\"@GMModular @goldmedalindia  horrible experience with a company like this #goldmedal #horrible sales person #wrong commitments#wrongproduct\",0.542],[\"Gonna get some acupuncture today for all my damn anxiety 🙃🤕\",0.854],[\"mmmm i'm kinda sad i hope i can shake this before school\",0.616],[\"@Fly_Norwegian quite simply the #worst #airline #worstairline I've ever used! #shocking #appauling #dire #dismal #beyondajoke #useless\",0.62],[\"@SalmonDelicious @bigdickkishibae I lost it at 18. Like, really not a big deal. Don't worry about trivial shit like that.\",0.292],[\"The radio just told me Lady GaGa is going country, which is like if the Beatles decided to do opera singing for their final albums #awful\",0.375],[\"#NawazSharif confesses that #Pakistan  supports #terror at #unga\\\\n#BurhanWani\",0.625],[\"@SportsTraderIT Madrid is playing awful and no modric but 90 minutes in Bernabéu stadium are so so long. Viallreal never won there\",0.292],[\"@ManUtd it was a terrible Freekick...\",0.347],[\"@ksmitely @CitizenMeh I feel strongly that we need to work together to right this dreadful wrong.\",0.479],[\"This is a terrific university-a unique university..Athabasca University has become a part of my head &amp; a part of my heart' Peter MacKinnon\",0.157],[\"Starting not to give a fuck and stopped fearing the consequence\",0.396],[\"How I Murdered Your Mother #SpookyTv #horror\",0.625],[\"@BBs_Coffee somebody needs tell staff at Reading cappuccino is supposed to have a thick layer of foam and coffee should be hot #awful again\",0.458],[\"@smb_ryan @Kamper10 I couldn't care less about #GOTHAM. I haven't watched it since the mid point of season 1. \",0.292],[\"3 #tmobile #stores, #original #note7 #customer and zero #results... What's going on guys?  #customerservice #2hour #waittime\",0.5],[\"Man Utd are shambles that was horrific 😭😭😭\",0.521],[\"@mackenzian yes! That was my one qualm. These are deeply theological issues we're engaging theologically.\",0.229],[\"Idk if it's hella hot in here or I'm nervous\",0.68],[\"3 #tmobile #stores, #original #note7 #customer and zero #results... What's going on guys? #terrible #customerservice #2hour #waittime\",0.5],[\"#goksfillyourhouseforfree should be retitled fill your house with old trash repainted ... #shocking #junk #trash\",0.417],[\"I can never find the exact #emoji that I'm after at the exact moment that I need it \",0.417],[\"@megynkelly We should be ignoring these rioters like the current administration ignores #terrorism. This will obviously make it stop.\",0.708],[\"Don't wanna really go out but I can't say no. Deffo have a fear of missing out\",0.708],[\"This is the scariest American Horror Story out of all of them... I'm gonna have to watch in the daytime. \",0.742],[\"How can America be so openly embracing racism. #dismayed\",0.604],[\"It's a good day at work when you get to shake Jim Lehrer's hand. Thanks, @keratx! Still kicking myself for being to shy to hug @mcuban.\",0.208],[\"#rocklandcounty get to ravis in suffern, ny. Great food, new #chef, terrific atmosphere. Say 'twitter' to server and get free #appetizer\",0.125],[\"@Relaqss I know she did horrible shit, but it wouldn't make anything better in the end, but your choice\",0.542],[\"I hate when people say 'I need to talk to you or we need to talk.' My anxiety immediately goes up...\",0.875],[\"If Monday had a face I would punch it #monday #horrible #face #punch #fight #joke #like #firstworldproblems #need #coffee #asap #follow\",0.5],[\"@MikeGrunwald Anything is better than a Trump ramble. He is awful. Truly truly awful.\",0.625],[\"Americans as a whole are, for the most part, feeling borderline despair at the very least. Looking at a situation out of control.\",0.562],[\"@NRA @HillaryClinton  She never said anything about taking away guns but I would now bc of your stupid scare tactics for gun sales.Sickening\",0.583],[\"Crossword puzzle is oat meals solitary respecting the flat out portentous nutrient rootstock re scruple failur...\",0.375],[\"How is that in 2016, a 757 airplane does not have WiFi...ridiculous. #AmericanAirlines #americanairlinessucks #AATeam \",0.292],[\"Angelino's been horrific\",0.583],[\"my mom recorded nightmare before Christmas for me 😍😍😍 I LOVE IT 💕\",0.14],[\"Wish I was a kid again. The only stressful part was whether Gabriella and Troy would get back together or not. #hsm2 \",0.458],[\"This is #horrible: Lewis Dunk has begun networking #a Neo-Geo with a his holiday home in Mexico.\",0.479],[\"An adviser to the #European #Union’s top #court said #Hamas and the #Tamil #Tigers should be taken off the EU’s #terror list.#lka\",0.5],[\"There goes the butterflies in my stomach.  #anxietyproblems\",0.702],[\"So about 18mths ago i signed up to @Lumo_Energy for their @VirginAustralia \\u002f Velocity FF deal. 18 months in still no FF points \",0.271],[\"Watching It Follows.  This is a super freaky movie.  #scary\",0.708],[\"@mikefreemanNFL \\\\nIsn't OBrien supposed to be some sort of offensive genius #awful\",0.479],[\"@CesarSampao @thisisbolton don't get me started on town centre. Used to go every week.... not been for 18 months #horrible\",0.479],[\"Dunno y am going to the Yorkshire scare grounds when I only lasted a minute in the Alton towers one before running out a fire exit crying\",0.812],[\"@TheDappaMc also £2.50 for a chocolate Feast ice lolly.. proper shocking 😩\",0.438],[\"If my concerns &amp; anxiety don't matter to you then I shall return the favor. #EyeMatter\",0.729],[\"When you're scared to press send #bgoodthepoet #PrayForMe #ThisIsAGodDream #career #help #fear #heart #HeartRacing\",0.842],[\"They'll be yo friend, shake your hand, then kick in yo door thas the way the game go🤖🤐.\",0.417],[\"Came in to work today 1.5 hours late.1st thing I hear: 'Ma'am,the big boss has been waiting for you in his office.' #panic #hateBeingLate 😩😪\",0.896]],\"hovertemplate\":\"emotion=fear\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"fear\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"fear\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[2.3212767,0.7415788,4.8151474,1.3772465,3.2466276,0.6168634,1.1208785,5.033716,3.123898,4.5401196,0.24969918,1.2844716,4.360867,0.6639882,1.1254139,4.1354847,1.9033204,4.372025,4.748553,4.5037036,4.485638,4.133814,3.9707122,1.5191269,1.6222414,4.0434904,1.6927603,3.5700903,4.575033,3.3773665,0.43826178,3.6503747,4.376612,0.79533803,5.2092786,0.3634802,1.3955231,5.629727,4.106713,4.247602,2.1140623,0.88194233,0.5755713,4.904869,5.3213916,5.17661,3.0651855,3.8140013,4.817851,1.4853363,0.6409954,4.854845,4.807436,0.85890377,3.6124337,1.3394848,4.7841964,4.1567316,0.35110724,3.8760264,1.4637418,0.68838114,2.6194155,0.7315043],\"xaxis\":\"x\",\"y\":[6.722179,6.2752357,7.074271,4.93299,5.9236445,4.657286,6.3185744,5.0192466,3.443303,3.6780012,5.8512254,5.9904227,7.512188,6.2950015,4.623273,7.626241,4.734953,6.896527,5.1705956,7.0881124,7.1888833,4.6406236,3.7479796,5.531124,7.1766305,7.2576184,6.458198,7.6745367,7.1325717,4.449347,6.138658,7.6072564,7.4914465,4.980061,5.58653,6.0141487,7.018714,5.634237,2.8371303,2.6195111,4.4412413,6.1751347,4.8881555,6.480893,5.1911073,6.2034435,4.8904476,7.6594076,7.102403,6.9781523,4.372563,6.9899087,5.089139,6.3147163,7.6874514,7.020269,7.1462526,7.209985,6.1291904,6.993523,6.163422,6.475133,5.185658,5.9692054],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Three days off a month with two ex wives and no home could be worse. I don't know how, but it could #oilandgas #optimism\",0.25],[\"it was both lively &amp; lovely @crumblepie15 @buryprofs @DittoBistro #BuffnPolish\",0.48],[\"Watch this amazing live.ly broadcast by @brooks_swaggysquad #lively #musically\",0.479],[\"i'm doing laundry and watching that 70's show with a bunch of strangers. #happy #birthday #to #me\",0.438],[\"Watch this amazing live.ly broadcast by @huntermcaseyy  #musically\",0.558],[\"My siblings look all gangster &amp; I look all cheery 😅😂\",0.667],[\"@AphoticSanguine —but be a little playful. \\\\n\\\\nHe hesitantly pulls away, just enough so he could get words out, lips brushing against—\",0.46],[\"@BattleSmitten \\\\n\\\\nother begin telling a 'story' he realized that she was making an attempt at cheering him up. It was sweet of her and so ➤\",0.521],[\"Fee otherwise tricks: palm oil delegation mt jaunty resident: TZxCHLdAQ\",0.269],[\"@BrightPigSEO @BrightPigSEO we provide dignified and professional funerals at prices families can afford #satisfied clients #bright pig\",0.345],[\"@ArtyBagger With or without cake seeing your wee cheery face is always a joy xx\",0.729],[\"Do not truck the delight; delight the truck.\",0.34],[\"Watch this amazing live.ly broadcast by @hannah..mccloud #lively #musically\",0.562],[\"Rec'd call 2day from Haitian church we started in Florida some 15yrs ago. Preparing to acquire their own bldg. Wanted me to know. #rejoicing\",0.56],[\"It's not that the man did not know how to juggle, he just didn't have the balls to do it. \\\\n #funny #pun #punny #lol \",0.604],[\"@grahnort wonderful experience watching you yesterday at. @BBCLetItShine thankyou for the \",0.708],[\"@RealKyper @NHL watching the jubilant scrum at the end of the day and remembering they're all still kids! #priceless\",0.625],[\"Watch this amazing live.ly broadcast by @thebrandonrobert #lively #musically\",0.458],[\"Just popped a half bottle of 2014 @Bellawines #sparkling #gamaynoir from Westbank. Evenin', folks! \\\\n#bcwinechat\",0.62],[\"My friend just messaged me 'ugh I'm so hungry I can't wait for breakfast' #socialmedia #WineWednesday  #funny #laughing \",0.479],[\"A #smile brightens your day and the day of everyone around you, so remember to #smile, it's #free. :-)\",0.792],[\"Update: I have yet to hang out with @MisElizaJane, but I'm still hopeful! \",0.396],[\"Apparently all the money in the world can't buy a single person to tell you not give your own waist a hearty two-handed pinch while onstage.\",0.16],[\"@doubtcaspar babe :(( remember I'm ALWAYS here if u need a little cheering up or talk, ily lots💘\",0.417],[\"@lawson__lynch my kinda girl pleasing the dick right😍😏\",0.542],[\"@TheNotoriousMMA looking like @MIckeyRourkeFP in his heyday\",0.4],[\"I take a strange delight from seeing mark Hughes struggle\",0.333],[\"#OneSimpleChange: Drink sparkling water instead of soft drinks to steer clear of fructose while still getting a refreshing carbonation kick.\",0.227],[\"Day 3 of #harvest16 - listening to the sound of the chopper working it's way closer to home at @mountaindairy makes me . #farm365\",0.417],[\"@JoshNoneYaBiz I love parody accounts! Well done. Vote for #Trump. #lol \",0.708],[\"Being a veteran just totally got me out of a ticket. I'm elated right now, close call.\",0.604],[\"@biggerthanyuu He's flushed upon hearing the feeling is reciprocated. He's elated to shove himself right into his arms and hug him tightly.+\",0.5],[\"Feelings got cheated when I mistook the sparkling ribena to be the normal ribena......\",0.14],[\"Had a coworker look at her phone and say, cheerfully, 'oh look, Kap's getting death threats now.' 🙄. Then she goes to say the 49ers are\",0.385],[\"Happy birthday @iRidhiDogra keep smiling always.Wishing you a wonderful year ahead mam\",0.74],[\"@u4uzoma Boss I see you as someone that is jovial and funny. Tho av not met u in person.\",0.5],[\"This tweet is dedicated to my back pain, which I do not understand because I am youthful and spry. Full of life. Vivacious.\",0.229],[\"Sioux Valley wins home competitive #cheer invite with a score of 158. ...Dell Rapids second at 138\",0.583],[\"@Casper10666 I assure you there is no laughter, but increasing anger at the costs, and arrogance of Westminster.\",0.167],[\"@kwelbyroberts they will come and you will rejoice at their arrival.\",0.458],[\"@harrietemmett great minds think alike. #rejoice\",0.519],[\"[Moment of levity on the B41] Baby: I want ISIS! Give me ISIS!\\\\nMom: Shh!\\\\nBaby: I want ISIS!\\\\nWest Indian woman: She wants what?\\\\nMom: *Ices*.\",0.521],[\"@GigaFag @pipertownsend_ snapchat new would beg to differ #optimism\",0.396],[\"Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day.  #challenge #kashmir #baloch\",0.58],[\"Imagine how sad LA fans are gona be when they get eliminated...Man that's gonna be Nirvana, a religious experience rejoicing in their misery\",0.333]],\"hovertemplate\":\"emotion=joy\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"joy\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"joy\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.86869556,4.3673334,3.612019,3.2963967,3.4613574,3.457441,2.643125,2.6387663,3.2031114,4.317295,3.4838693,3.3828516,3.3749933,3.6279116,3.8909676,4.505349,4.0736794,3.5818484,4.093792,3.867029,3.6171827,1.5853422,2.352586,2.754683,3.3765688,3.640285,4.349653,3.9534872,3.8722107,4.7957883,3.5329852,2.7085028,1.5315732,3.922479,3.6452641,3.4514287,2.9963396,4.0834336,4.5270786,3.116509,3.4901223,3.906332,1.4530579,4.536021,4.197749],\"xaxis\":\"x\",\"y\":[4.202681,2.9590926,1.9781048,3.9818213,2.1717155,4.0585084,3.6184301,3.5788038,4.8205094,3.286539,3.5183365,3.1391253,2.0460382,2.957438,4.955558,3.1964176,3.0190315,2.05697,3.233484,4.0532117,3.257345,3.6636288,4.9832783,3.2827277,2.2153654,4.7185445,6.636981,3.3421988,3.198517,5.944341,2.8742561,3.4250944,4.9263234,6.332705,3.4253163,3.7071042,4.4958386,2.5347176,4.799523,3.164119,3.0730898,5.5881696,3.5902543,4.913549,6.69084],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Already plotting next steps if I get cut off by the same minivan in tomorrow's drop-off line. #preschoolpolitics #momthings #serious\",0.417],[\"@JUSTICESLUT420 sadly this sort of poster died by the 90s afaik\",0.669],[\"@rickygervais my first time in Slough so checked out the new station floor  #LifeOnTheRoad\",0.292],[\"@realDonaldTrump negative campaign of doom and gloom don't win elections\",0.521],[\"@_Mrs_Peel @lp_lisa @PaulRGoulden @LisaLuscious Might be the pout of a star baker tho !\",0.312],[\"Don't let the behavior of others destroy ur inner peace.' -Dalai Lama @OWNTV #healing #depression #anxiety #intuition #meditation #book\",0.583],[\"Kinda wanna just book a vacation and go...anyone wanna tag along? #adventure #serious\",0.312],[\"@crimsonwulfe it's super sad!! Especially when you are talking to a real person and not a bot! Makes it feel real :(\",0.75],[\"Had to give up on The Blue Guitar, couldn't stand main character. Sort of skim-read to the end which got grim and unsettling . . . 1\\u002f2\",0.583],[\"@AMB4JC @drtonyevans It's our job, the job of people who r still sane,still ok in life, to help the lost to find themselves &amp; love eachother\",0.214],[\"Think Val might be going this week. I'll have to take the rest of the week off work to mourn. I'm sure they'll understand. #GBBO\",0.562],[\"@EmotionalLimine you're sadly mistaken if you think I'd make a tweet for an isolated comment by a random twitter user.\",0.469],[\"@el_tityboi bc it's a gloomy day Tony\",0.625],[\"My name is John Locke and you can't tell me what I can and can't do #lost #アニメ\",0.292],[\"@KurakkuSora he is.\\\\nSure his mind was clouded but...]\",0.333],[\"@patthemanager how could I work with @chancetherapper . ? #serious\",0.354],[\"@lee_family5 @USAneedsTRUMP @HillaryClinton @realDonaldTrump You can't be serious. This man practices no religion. Only in church campaignin\",0.396],[\"Depression sucks! #depression\",0.958],[\"Theyve substituted the hood for a badge and gun.' Public opinion is indictment of Charlotte police. #dark #sadtimes #america #race\",0.604],[\"Why doesn't anybody I know watch penny dreadful? ☹️️\",0.455],[\"#Terencecutcher #Tulsa the man onthe helicopter said he looks like a bad dude, that is the problem, when they see black they see bad, #sad\",0.667],[\"@_JuliaSteiner : I liked that she was not moping around in all of the episode. She had a moment of emotional weakness, felt sorry about -\",0.46],[\"@GOP she's ahead in the polls &amp; after Trumps dismal performance at upcoming debate, it will be an easy win for Hillary.\",0.174],[\"@emorottie true sonicsatam was serious and a bit dark. Aosth is like super goofy and Looney toonie to a degree\",0.271],[\"It feels like there are no houses out there for us. With the most basic requirements I have, there are literally no options. #discouraged\",0.729],[\"if you're unhappy with someone just fucking tell them you're unhappy and leave. Don't go fuckin around with other people on the side\",0.604],[\"The #pessimist complains about the wind; the #optimist expects it to change; the realist adjusts the sails.' - William Arthur Ward\\\\n#IGNITE\",0.271],[\"@JonathanHatfull I’ll look forward to it. Hoping for lots of stetson-tilting and rueful looks into whiskey glasses.\",0.333],[\"i lost my wallet lol.... again....\",0.417],[\"In the name of our Lord &amp; Saviour Harambe we pray, bless all apes across the world.\\\\n\\\\nHear our solemn oaths and pardon sympathetic hominids.\",0.333],[\"Learning how to use twitter #lost\",0.354],[\"Mayor visits downtrodden part o town in brave PR stunt. More at eleven.\",0.458],[\"Free live music in DC tonight!  #blues with #MoonshineSociety at @thehamiltondc in the Loft starting at 10:30pm @FreeinDCBlog @WTOPFreebies\",0.188],[\"@HeyCaraJay I am inconsolable at this GIF in context\",0.509],[\"I'd rather die alone then end up with somebody who can't be sober\",0.66],[\"@Barcabhoy1 Of course not. Didn't sink his studs into a knee like Forrester\",0.396],[\"340:892 All with weary task fordone.\\\\nNow the wasted brands do glow,\\\\nWhilst the scritch-owl, scritching loud,\\\\n#AMNDBots\",0.458],[\"I'd rather laugh with the rarest genius, in beautiful alliance with his own being, where he kept his sadness. #melancholy\",0.688],[\"Stars, when you shine,\\\\nYou know how I feel.\\\\nScent of the pine, \\\\nYou know how I feel.\\\\nFreedom is mine,\\\\nI know how I feel.\\\\nI'm feelin' good.\",0.292],[\"“Dyslexia is the affliction of a frozen genius.”― Stephen Richards\",0.333],[\"A3: But chronic sadness may mean there are underlying issues than getting sad occassionally over a particular issue (2\\u002f2) #mhchat\",0.562],[\"Common app just randomly logged me out as I was writing the last part of my college essay and lost all of it 😭😭😭\",0.833],[\"im thoroughly in love w zen and jumin and i dont think id even have the patience for either of them irl im old and weary\",0.458]],\"hovertemplate\":\"emotion=sadness\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"sadness\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"sadness\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[3.5207853,2.026918,4.6642876,5.092479,3.3334165,1.7748091,1.0384595,1.5870333,1.0330997,3.9442961,3.3939536,2.3816788,2.0182238,2.991402,2.4424057,1.0582323,5.048346,0.8327028,5.713346,1.4033638,5.7559395,2.3113742,5.046248,2.1702735,0.66520333,2.0812526,1.3917567,2.3089917,1.3398861,4.2585073,2.918346,4.360173,4.048746,2.6087782,1.9685701,4.2204385,2.850609,1.6507256,3.287486,1.8495903,1.438034,1.017801,2.1788232],\"xaxis\":\"x\",\"y\":[5.6708803,4.1358123,3.6448598,5.8686156,5.448094,5.9177294,4.021303,4.301748,4.8020773,4.6284432,5.7980585,4.440035,3.4380739,4.236551,4.0426207,4.0494905,5.917261,5.0551543,5.5148687,6.864255,5.4932027,3.8507597,6.0265636,3.6869571,4.9227843,5.8658414,3.5924387,3.480316,5.001125,5.286945,4.371965,5.442742,2.2835422,6.4852824,5.410273,5.8402405,3.9527256,4.8443193,3.0206773,5.0440965,4.4008574,5.2777796,4.850896],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"UMAP1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"UMAP2\"}},\"legend\":{\"title\":{\"text\":\"emotion\"},\"tracegroupgap\":0},\"title\":{\"text\":\"2D UMAP Projection of Text Embeddings\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('59dea144-cbc3-40ac-b68c-53792a729fa1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Concatenate the training and test data\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# Prepare the embeddings for UMAP\n",
    "# Convert the list of embeddings into a 2D numpy array\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_components=2, metric='cosine', random_state=28) \n",
    "embedding_2d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# Visualize the embeddings with Plotly\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='emotion',  # Color points by the 'emotion' column\n",
    "    hover_data=['text', 'intensity'],  # Show text and intensity on hover\n",
    "    title='2D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with Gemini's embeddings there doesn't seem to be a clear 2D separation of clusters with our data classes. It could be because emotions are often not discrete. Texts can contain mixed feelings (e.g., \"bittersweet\") or use similar language to express different emotions, causing their embeddings to be naturally close in semantic space. And also the process of projecting high-dimensional embeddings down to a 2D visualization inevitably loses some information, which can make distinct clusters appear to overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
    "\n",
    "Apply UMAP to the same embeddings to reduce the dimensionality to 3D vectors and plot the 3D graph, discuss the differences and similarities with the 2D graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"67ecd208-2cd6-4f86-8d50-5decca04c962\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"67ecd208-2cd6-4f86-8d50-5decca04c962\")) {                    Plotly.newPlot(                        \"67ecd208-2cd6-4f86-8d50-5decca04c962\",                        [{\"customdata\":[[\" I can't guess if you holding a grudge against the best'\",0.425],[\"@healeyraine I'm offended, I actually am\",0.479],[\"#welfarereform should not be a 'model' for .\",0.417],[\"So #angry about my @WishShopping order. 6 #months ago I placed an order of over $500. Card billed. Never #received \\\\n#disappointing\",0.771],[\"@RealJeffsdomain Wolfpack theme and trons and sting wore the wolf shirt\",0.312],[\"@realDonaldTrump: No sense in taking out your wrath on innocent people because you think police shot an innocent man. #MakeAmericaSafeAgain\",0.479],[\"As your own lives in order to complete our amazing life journey successfully, it is there. #bitter\",0.417],[\"@lesyoung01 a rabid dog being ridden by the child who has eaten all the flesh off one fellow and the limbs of the other adults.\",0.583],[\"@nytopinion  The point of voting for Trump to push all the pieces off the board game like an angry toddler? Wreck everything for everybody?\",0.562],[\"Tasers immobilize, if you taser someone why the fuck do you need to shoot them one second later?! This is really sick!  #wtf #murder\",0.729],[\"Sorry to burst your bubble but it isn't that century anymore. Welcome to the 21st century.\",0.354],[\"Like hello? I am your first born you must always laugh at my jokes. \",0.324],[\"@RegalisAzura \\\\ngrasp the cobalt woman's own; which they did fairly easily. Fair cheeks would ignite into a fiery hue. Warm.. was the only\",0.438],[\"I have 1000 rabid grizzly bears I'm going to scatter in neighborhoods all over America.\\\\n\\\\nThey're poor refugees!\\\\n\\\\n#InYourNeighborhoodNotDC\",0.646],[\"@DeltaDomain @SawDraze @qurions dis dat nigga from fume right?\",0.417],[\"straight people are canoodling on the quad and I'm #offended\",0.648],[\"never #make a decision when you are .. #angry &gt;_&lt; .... and never make a #promis when you are #happy :) :*\",0.521],[\"Seeing #RIPShawtyLo got me thinking bout other rappers then I thought about @LilTunechi dying, and burst into tears... Smh\",0.417],[\"@LisaAsquithtobe @craig8710 @WayneHaselden @june65wigan everyone is against wigan because we are the biggest club \",0.354],[\"@BosNaud so scared to ruffle feathers, he resorted to writing in cryptic code. #UncleCamsCabin\",0.5],[\"Have wee pop socks on and they KEEP FALLING OFF INSIDE MY SHOES \",0.562],[\"The most important thing to #bestrong is to hold your  #thoughts\",0.147],[\"@JuliaHB1 Bloody right \",0.562],[\"Thatmoment you're watching #worstcelebritycooks and your bubble is burst by finding out KyleXY is gay and married😭 #nochance #KindaDontMind😉\",0.479],[\"My mind is raging and i just want to end it all\",0.75],[\"“He who is slow to anger is better than the mighty, And he who rules his spirit than he who takes a city.”\\\\nP16:32 #bibleverse #pride #anger\",0.314],[\"@IrishTimesPol @IrishTimes Irish citizens boiling drinking water in 2016 leaves one foot firmly in the bog!\",0.542],[\"Holding a #grudge doesn't make you #strong; it makes you #bitter. #Forgiving doesn't make you #weak; it sets you #free.\",0.312],[\"Kik me I want to swap pics I will post on my account anonymously if you wish Kik: vsvplou #Kik #kikme #snap #nudes #tits #snapchat\",0.292],[\"I wish the next madden has a story mode too. Just like Fifa 17 #madden\",0.312],[\"@clarechampion @Westclarepage and peter your radio piece on off the ball was pure class , no digs , no revenge , a total balanced pro ! 👏👏👏\",0.438],[\"@cc_yandian @HillaryClinton her team must draw from a hat for daily personality #drugged  #yeller #quiet #screamer #😂😂\",0.521],[\"A wise man told me that holdin' a grudge is like\\\\nLetting somebody just live inside of your head rent free\",0.354],[\"@johnaugust @clmazin I was so looking forward to @ABCDesignated. Then it opened with a #stuartspecial. I literally yelled at my tv. #umbrage\",0.521],[\"I wish the next madden has a story mode too. Just like Fifa 17 \",0.292],[\"“He who is slow to anger is better than the mighty, And he who rules his spirit than he who takes a city.”\\\\nP16:32 #bibleverse #pride \",0.354],[\"@PatVPeters @FreeBeacon Quite the response of retaliation from Weiner in getting revenge on Huma &amp; Hillary 'clam digging'.\\\\n#AllScumbags\",0.5],[\"Y'all really insult coz of soccer???  Lmao, wow!!!!!!\",0.396],[\"i live and die for mchanzo honeymoon crashing and burning the second they move in together\",0.479],[\"@DxfyingGrxvity - frustration, looking up at Elphaba in a frown of aggravation. Her high pitched voice was growing more and more --\",0.604],[\"@FluDino Event started! everyone is getting ready to travel to the lake of rage, where everything glows\",0.521],[\"Kik to trade, have fun or a conversation  (kik: youraffair) #kik #kikme #messageme #textme #pics #trade #tradepics #dm  #bored\",0.241],[\"Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake\",0.417],[\"Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 #fuming\",0.708],[\"Sorry guys I have absolutely no idea what time i'll be on cam tomorrow but will keep you posted. \",0.202],[\"I wouldn't have #anger issues.....if she didn't have #lying issues.....think about that one. #pow #lies #confusion\",0.5],[\"@DailyMirror i love how theres no outrage that it's a white man but if it was a black man them BLM would be all over it regardless of reason\",0.726],[\"@TrueAggieFan oh so that's where Brian was! Where was my invite? #offended\",0.417]],\"hovertemplate\":\"emotion=anger\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003eUMAP3=%{z}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"anger\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"anger\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[2.3122714,1.1966703,0.9809724,0.94517624,1.5989643,1.9783627,2.1257029,1.9389019,2.2068386,1.6016237,1.443445,0.9419516,1.3633436,2.114645,1.5595787,1.2291619,3.0086768,1.8671068,0.28888658,2.849686,1.6606761,2.7902784,0.8080303,1.0555315,2.5814593,2.9395418,0.41550076,2.5979168,-0.0726816,1.8704208,-0.022003433,2.3291342,2.5905678,1.1426945,1.8077502,3.0223467,2.0489678,0.8496842,1.6246333,2.1171956,1.4578718,0.12170719,2.1840215,1.0509977,1.4199762,2.9657745,1.2010983,0.89893144],\"y\":[1.4111555,2.5631473,1.4480908,3.8943172,1.6725992,2.0492182,1.1616096,1.722832,2.133072,2.4401867,2.3845878,2.1190777,0.7648324,1.9146577,1.4788465,2.8171508,1.3194613,2.8589504,2.2541845,2.283428,2.8224652,1.0994503,1.5965688,3.1887934,2.167173,1.1822773,1.509099,1.1633545,1.6258508,3.3050404,1.539069,2.3291318,1.2653346,3.3006268,3.4179976,1.0812886,2.5127907,2.5686553,1.59957,1.5255584,0.9083435,1.796212,2.3352237,3.7252266,2.4597554,1.4440798,2.0907965,2.7928748],\"z\":[7.868756,8.562671,9.054393,9.177678,8.063947,10.06314,7.61563,9.076256,9.915581,10.10134,7.407962,8.308673,7.3587694,9.511304,7.603959,8.488227,7.855638,7.3283806,9.101459,8.867354,7.9429626,7.660203,8.814874,8.031958,7.629755,7.9113364,8.849837,7.5583,6.380249,6.958708,8.542349,9.647582,7.622326,8.621263,7.0142293,7.870939,9.65686,9.101202,6.829317,8.099248,7.6766376,6.3327036,8.863976,8.882991,7.1331396,8.0095,9.877024,8.658562],\"type\":\"scatter3d\"},{\"customdata\":[[\"GUY was such a video I'm shaking @ladygaga\",0.375],[\"anxiety level- 100\",0.905],[\"Have to say that third City kit is fucking awful. Someone at Nike wants shooting.\",0.521],[\"jesus ok an alarming percentage of my teachers ths year dont have a  s ingle thoughtful bone in their bodies . its gonna b an interesting yr\",0.565],[\"Saga: When all of your devices and teles fail just in time for bake off  #gbbo\",0.583],[\"Wishing i was rich so i didnt have to get up this morning #poor #sleepy  #sad #needsmoresleep\",0.562],[\"Fear blocks blessings, faith unlocks them. #ManUp #fear #faith\",0.388],[\"@TheDuranSite Russian mistrust of the U.S is well justified &amp; the precaution they've taken are very prudent.\",0.375],[\"@Zen1dfabflake You are all our angelic comrades! #flutter\",0.125],[\"@JogglingDroid @BrancoCarmine @Otto_English yeah, #UK was quite the \",0.25],[\"I really wanna go to fright fest 😩\",0.333],[\"a panic attack AND CALL YOURSELF A REAL FAN makes me so mad like i dont even have the words to explain. this is why some people give no +\",0.646],[\"@GMModular @goldmedalindia  horrible experience with a company like this #goldmedal #horrible sales person #wrong commitments#wrongproduct\",0.542],[\"Gonna get some acupuncture today for all my damn anxiety 🙃🤕\",0.854],[\"mmmm i'm kinda sad i hope i can shake this before school\",0.616],[\"@Fly_Norwegian quite simply the #worst #airline #worstairline I've ever used! #shocking #appauling #dire #dismal #beyondajoke #useless\",0.62],[\"@SalmonDelicious @bigdickkishibae I lost it at 18. Like, really not a big deal. Don't worry about trivial shit like that.\",0.292],[\"The radio just told me Lady GaGa is going country, which is like if the Beatles decided to do opera singing for their final albums #awful\",0.375],[\"#NawazSharif confesses that #Pakistan  supports #terror at #unga\\\\n#BurhanWani\",0.625],[\"@SportsTraderIT Madrid is playing awful and no modric but 90 minutes in Bernabéu stadium are so so long. Viallreal never won there\",0.292],[\"@ManUtd it was a terrible Freekick...\",0.347],[\"@ksmitely @CitizenMeh I feel strongly that we need to work together to right this dreadful wrong.\",0.479],[\"This is a terrific university-a unique university..Athabasca University has become a part of my head &amp; a part of my heart' Peter MacKinnon\",0.157],[\"Starting not to give a fuck and stopped fearing the consequence\",0.396],[\"How I Murdered Your Mother #SpookyTv #horror\",0.625],[\"@BBs_Coffee somebody needs tell staff at Reading cappuccino is supposed to have a thick layer of foam and coffee should be hot #awful again\",0.458],[\"@smb_ryan @Kamper10 I couldn't care less about #GOTHAM. I haven't watched it since the mid point of season 1. \",0.292],[\"3 #tmobile #stores, #original #note7 #customer and zero #results... What's going on guys?  #customerservice #2hour #waittime\",0.5],[\"Man Utd are shambles that was horrific 😭😭😭\",0.521],[\"@mackenzian yes! That was my one qualm. These are deeply theological issues we're engaging theologically.\",0.229],[\"Idk if it's hella hot in here or I'm nervous\",0.68],[\"3 #tmobile #stores, #original #note7 #customer and zero #results... What's going on guys? #terrible #customerservice #2hour #waittime\",0.5],[\"#goksfillyourhouseforfree should be retitled fill your house with old trash repainted ... #shocking #junk #trash\",0.417],[\"I can never find the exact #emoji that I'm after at the exact moment that I need it \",0.417],[\"@megynkelly We should be ignoring these rioters like the current administration ignores #terrorism. This will obviously make it stop.\",0.708],[\"Don't wanna really go out but I can't say no. Deffo have a fear of missing out\",0.708],[\"This is the scariest American Horror Story out of all of them... I'm gonna have to watch in the daytime. \",0.742],[\"How can America be so openly embracing racism. #dismayed\",0.604],[\"It's a good day at work when you get to shake Jim Lehrer's hand. Thanks, @keratx! Still kicking myself for being to shy to hug @mcuban.\",0.208],[\"#rocklandcounty get to ravis in suffern, ny. Great food, new #chef, terrific atmosphere. Say 'twitter' to server and get free #appetizer\",0.125],[\"@Relaqss I know she did horrible shit, but it wouldn't make anything better in the end, but your choice\",0.542],[\"I hate when people say 'I need to talk to you or we need to talk.' My anxiety immediately goes up...\",0.875],[\"If Monday had a face I would punch it #monday #horrible #face #punch #fight #joke #like #firstworldproblems #need #coffee #asap #follow\",0.5],[\"@MikeGrunwald Anything is better than a Trump ramble. He is awful. Truly truly awful.\",0.625],[\"Americans as a whole are, for the most part, feeling borderline despair at the very least. Looking at a situation out of control.\",0.562],[\"@NRA @HillaryClinton  She never said anything about taking away guns but I would now bc of your stupid scare tactics for gun sales.Sickening\",0.583],[\"Crossword puzzle is oat meals solitary respecting the flat out portentous nutrient rootstock re scruple failur...\",0.375],[\"How is that in 2016, a 757 airplane does not have WiFi...ridiculous. #AmericanAirlines #americanairlinessucks #AATeam \",0.292],[\"Angelino's been horrific\",0.583],[\"my mom recorded nightmare before Christmas for me 😍😍😍 I LOVE IT 💕\",0.14],[\"Wish I was a kid again. The only stressful part was whether Gabriella and Troy would get back together or not. #hsm2 \",0.458],[\"This is #horrible: Lewis Dunk has begun networking #a Neo-Geo with a his holiday home in Mexico.\",0.479],[\"An adviser to the #European #Union’s top #court said #Hamas and the #Tamil #Tigers should be taken off the EU’s #terror list.#lka\",0.5],[\"There goes the butterflies in my stomach.  #anxietyproblems\",0.702],[\"So about 18mths ago i signed up to @Lumo_Energy for their @VirginAustralia \\u002f Velocity FF deal. 18 months in still no FF points \",0.271],[\"Watching It Follows.  This is a super freaky movie.  #scary\",0.708],[\"@mikefreemanNFL \\\\nIsn't OBrien supposed to be some sort of offensive genius #awful\",0.479],[\"@CesarSampao @thisisbolton don't get me started on town centre. Used to go every week.... not been for 18 months #horrible\",0.479],[\"Dunno y am going to the Yorkshire scare grounds when I only lasted a minute in the Alton towers one before running out a fire exit crying\",0.812],[\"@TheDappaMc also £2.50 for a chocolate Feast ice lolly.. proper shocking 😩\",0.438],[\"If my concerns &amp; anxiety don't matter to you then I shall return the favor. #EyeMatter\",0.729],[\"When you're scared to press send #bgoodthepoet #PrayForMe #ThisIsAGodDream #career #help #fear #heart #HeartRacing\",0.842],[\"They'll be yo friend, shake your hand, then kick in yo door thas the way the game go🤖🤐.\",0.417],[\"Came in to work today 1.5 hours late.1st thing I hear: 'Ma'am,the big boss has been waiting for you in his office.' #panic #hateBeingLate 😩😪\",0.896]],\"hovertemplate\":\"emotion=fear\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003eUMAP3=%{z}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"fear\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"fear\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[2.5389924,3.233974,0.7579145,2.0406914,0.82416105,2.0357401,3.2939281,1.7298537,0.8704624,-0.051455155,2.9219904,2.7822218,0.8567642,3.4033272,2.1333034,0.7313235,2.171362,1.4827929,1.1403223,0.7962171,0.7334548,1.0128529,0.12154255,2.6637073,2.9552968,0.6117502,2.5702288,0.79078954,0.6442578,0.99693114,3.1993911,0.76082194,0.91127044,1.7313058,2.0336561,3.004356,3.0697527,1.3581907,-0.2582834,-0.5240957,2.1311927,3.3211303,1.4857658,1.6169562,1.6434358,1.9555615,2.0023143,0.7278344,0.70411503,2.8034413,1.9878808,0.93838775,1.0532682,3.5042455,0.81576705,3.0396037,1.1435865,0.3958633,3.0714133,0.44825956,3.2510223,3.4665065,2.5958083,3.1325746],\"y\":[3.2256863,2.8826487,3.1693506,2.7852535,3.1289458,2.902831,2.6350641,1.7379355,1.1025574,1.2298454,3.3932924,2.5733685,3.7691662,2.9200592,2.6804411,3.7983518,2.015618,3.19885,2.0052774,3.2546263,3.3225098,1.3886536,1.2970735,2.1450584,3.3599668,3.635357,3.0874217,3.9936054,3.1883156,1.1362631,3.0942237,3.9364564,3.621125,3.2416186,1.842891,3.3247294,3.3919766,2.209269,1.5089114,1.2952774,1.7055916,2.7495332,2.948001,2.8316965,1.8771232,2.5960448,0.9198211,3.8745668,3.252639,3.3412921,3.0193353,3.3162234,1.8254293,2.795807,4.0944653,3.3574817,3.1607342,3.4265387,3.433615,3.4763641,2.3241618,2.895424,1.2966291,3.0591142],\"z\":[8.668294,7.996766,9.989221,7.823631,8.039819,7.0948772,8.248432,9.69519,7.386332,8.306579,7.9016037,8.033863,9.714901,7.9964757,7.297797,9.562176,7.7998905,9.630839,9.406292,9.648275,9.691951,8.664797,8.085042,7.845197,8.749641,9.504325,8.417549,8.939399,9.724528,8.3704405,7.87253,9.18052,9.790692,7.688533,9.922506,7.828342,8.580862,9.8892,7.7813754,7.360697,7.5421004,7.811819,7.4510994,9.873134,9.719304,9.847246,8.053684,9.462373,9.853955,8.937368,6.8267307,9.982849,9.550146,7.8008695,9.042491,8.623818,9.694161,9.609528,8.075948,9.39519,7.902873,7.9577627,7.799691,7.5639877],\"type\":\"scatter3d\"},{\"customdata\":[[\"Three days off a month with two ex wives and no home could be worse. I don't know how, but it could #oilandgas #optimism\",0.25],[\"it was both lively &amp; lovely @crumblepie15 @buryprofs @DittoBistro #BuffnPolish\",0.48],[\"Watch this amazing live.ly broadcast by @brooks_swaggysquad #lively #musically\",0.479],[\"i'm doing laundry and watching that 70's show with a bunch of strangers. #happy #birthday #to #me\",0.438],[\"Watch this amazing live.ly broadcast by @huntermcaseyy  #musically\",0.558],[\"My siblings look all gangster &amp; I look all cheery 😅😂\",0.667],[\"@AphoticSanguine —but be a little playful. \\\\n\\\\nHe hesitantly pulls away, just enough so he could get words out, lips brushing against—\",0.46],[\"@BattleSmitten \\\\n\\\\nother begin telling a 'story' he realized that she was making an attempt at cheering him up. It was sweet of her and so ➤\",0.521],[\"Fee otherwise tricks: palm oil delegation mt jaunty resident: TZxCHLdAQ\",0.269],[\"@BrightPigSEO @BrightPigSEO we provide dignified and professional funerals at prices families can afford #satisfied clients #bright pig\",0.345],[\"@ArtyBagger With or without cake seeing your wee cheery face is always a joy xx\",0.729],[\"Do not truck the delight; delight the truck.\",0.34],[\"Watch this amazing live.ly broadcast by @hannah..mccloud #lively #musically\",0.562],[\"Rec'd call 2day from Haitian church we started in Florida some 15yrs ago. Preparing to acquire their own bldg. Wanted me to know. #rejoicing\",0.56],[\"It's not that the man did not know how to juggle, he just didn't have the balls to do it. \\\\n #funny #pun #punny #lol \",0.604],[\"@grahnort wonderful experience watching you yesterday at. @BBCLetItShine thankyou for the \",0.708],[\"@RealKyper @NHL watching the jubilant scrum at the end of the day and remembering they're all still kids! #priceless\",0.625],[\"Watch this amazing live.ly broadcast by @thebrandonrobert #lively #musically\",0.458],[\"Just popped a half bottle of 2014 @Bellawines #sparkling #gamaynoir from Westbank. Evenin', folks! \\\\n#bcwinechat\",0.62],[\"My friend just messaged me 'ugh I'm so hungry I can't wait for breakfast' #socialmedia #WineWednesday  #funny #laughing \",0.479],[\"A #smile brightens your day and the day of everyone around you, so remember to #smile, it's #free. :-)\",0.792],[\"Update: I have yet to hang out with @MisElizaJane, but I'm still hopeful! \",0.396],[\"Apparently all the money in the world can't buy a single person to tell you not give your own waist a hearty two-handed pinch while onstage.\",0.16],[\"@doubtcaspar babe :(( remember I'm ALWAYS here if u need a little cheering up or talk, ily lots💘\",0.417],[\"@lawson__lynch my kinda girl pleasing the dick right😍😏\",0.542],[\"@TheNotoriousMMA looking like @MIckeyRourkeFP in his heyday\",0.4],[\"I take a strange delight from seeing mark Hughes struggle\",0.333],[\"#OneSimpleChange: Drink sparkling water instead of soft drinks to steer clear of fructose while still getting a refreshing carbonation kick.\",0.227],[\"Day 3 of #harvest16 - listening to the sound of the chopper working it's way closer to home at @mountaindairy makes me . #farm365\",0.417],[\"@JoshNoneYaBiz I love parody accounts! Well done. Vote for #Trump. #lol \",0.708],[\"Being a veteran just totally got me out of a ticket. I'm elated right now, close call.\",0.604],[\"@biggerthanyuu He's flushed upon hearing the feeling is reciprocated. He's elated to shove himself right into his arms and hug him tightly.+\",0.5],[\"Feelings got cheated when I mistook the sparkling ribena to be the normal ribena......\",0.14],[\"Had a coworker look at her phone and say, cheerfully, 'oh look, Kap's getting death threats now.' 🙄. Then she goes to say the 49ers are\",0.385],[\"Happy birthday @iRidhiDogra keep smiling always.Wishing you a wonderful year ahead mam\",0.74],[\"@u4uzoma Boss I see you as someone that is jovial and funny. Tho av not met u in person.\",0.5],[\"This tweet is dedicated to my back pain, which I do not understand because I am youthful and spry. Full of life. Vivacious.\",0.229],[\"Sioux Valley wins home competitive #cheer invite with a score of 158. ...Dell Rapids second at 138\",0.583],[\"@Casper10666 I assure you there is no laughter, but increasing anger at the costs, and arrogance of Westminster.\",0.167],[\"@kwelbyroberts they will come and you will rejoice at their arrival.\",0.458],[\"@harrietemmett great minds think alike. #rejoice\",0.519],[\"[Moment of levity on the B41] Baby: I want ISIS! Give me ISIS!\\\\nMom: Shh!\\\\nBaby: I want ISIS!\\\\nWest Indian woman: She wants what?\\\\nMom: *Ices*.\",0.521],[\"@GigaFag @pipertownsend_ snapchat new would beg to differ #optimism\",0.396],[\"Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day.  #challenge #kashmir #baloch\",0.58],[\"Imagine how sad LA fans are gona be when they get eliminated...Man that's gonna be Nirvana, a religious experience rejoicing in their misery\",0.333]],\"hovertemplate\":\"emotion=joy\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003eUMAP3=%{z}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"joy\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"joy\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[1.5567338,-0.43012553,-0.46780893,0.6110823,-0.38609144,0.69283074,1.2034113,1.3121958,1.8767642,-0.22190599,0.41614595,0.27543035,-0.4625106,-0.0035816224,1.4941525,-0.37762606,-0.26943624,-0.5130912,-0.22438581,0.38003662,0.28281114,1.0653508,1.9425879,0.86620235,-0.21415369,0.24538167,0.5097975,0.1612833,-0.19588608,2.3156762,0.117214,1.1394284,1.3618637,1.152689,0.38452938,0.55689967,1.0741853,-0.47050777,0.82597,0.35624295,0.029814115,1.9872438,1.0952554,1.0075916,0.67803466],\"y\":[2.6453114,1.2088248,1.3261138,2.1934395,1.3908874,1.9040054,0.8902779,0.89375645,0.8923038,1.1035602,1.4836333,0.8612654,1.3224486,0.9379783,2.457901,1.2794372,1.5628227,1.261867,1.7903104,2.3894396,1.2724862,2.513466,2.1912699,1.398308,1.4607514,1.7554585,2.79526,1.837877,1.6503795,2.287032,0.90195775,0.8567464,3.1899955,2.6509085,1.5156993,1.4777535,2.172899,1.2994213,1.8954431,0.78301513,1.0561206,1.8438745,2.4399314,2.0427957,2.8558974],\"z\":[6.710128,7.835273,6.593618,7.4363585,6.713647,8.043821,7.289898,7.1881676,8.081467,7.910039,7.4374747,7.6054134,6.574672,7.403967,8.276715,8.007157,7.861724,6.653499,7.5431256,7.6324277,7.267481,7.0777793,8.121578,7.086558,6.507488,8.618742,9.474285,7.3682885,7.7858667,9.871771,7.358407,7.156212,7.8435807,9.094078,7.338081,7.5864234,7.7298436,7.4249687,8.939617,7.635924,7.55227,9.073529,6.7032666,9.111133,9.2823305],\"type\":\"scatter3d\"},{\"customdata\":[[\"Already plotting next steps if I get cut off by the same minivan in tomorrow's drop-off line. #preschoolpolitics #momthings #serious\",0.417],[\"@JUSTICESLUT420 sadly this sort of poster died by the 90s afaik\",0.669],[\"@rickygervais my first time in Slough so checked out the new station floor  #LifeOnTheRoad\",0.292],[\"@realDonaldTrump negative campaign of doom and gloom don't win elections\",0.521],[\"@_Mrs_Peel @lp_lisa @PaulRGoulden @LisaLuscious Might be the pout of a star baker tho !\",0.312],[\"Don't let the behavior of others destroy ur inner peace.' -Dalai Lama @OWNTV #healing #depression #anxiety #intuition #meditation #book\",0.583],[\"Kinda wanna just book a vacation and go...anyone wanna tag along? #adventure #serious\",0.312],[\"@crimsonwulfe it's super sad!! Especially when you are talking to a real person and not a bot! Makes it feel real :(\",0.75],[\"Had to give up on The Blue Guitar, couldn't stand main character. Sort of skim-read to the end which got grim and unsettling . . . 1\\u002f2\",0.583],[\"@AMB4JC @drtonyevans It's our job, the job of people who r still sane,still ok in life, to help the lost to find themselves &amp; love eachother\",0.214],[\"Think Val might be going this week. I'll have to take the rest of the week off work to mourn. I'm sure they'll understand. #GBBO\",0.562],[\"@EmotionalLimine you're sadly mistaken if you think I'd make a tweet for an isolated comment by a random twitter user.\",0.469],[\"@el_tityboi bc it's a gloomy day Tony\",0.625],[\"My name is John Locke and you can't tell me what I can and can't do #lost #アニメ\",0.292],[\"@KurakkuSora he is.\\\\nSure his mind was clouded but...]\",0.333],[\"@patthemanager how could I work with @chancetherapper . ? #serious\",0.354],[\"@lee_family5 @USAneedsTRUMP @HillaryClinton @realDonaldTrump You can't be serious. This man practices no religion. Only in church campaignin\",0.396],[\"Depression sucks! #depression\",0.958],[\"Theyve substituted the hood for a badge and gun.' Public opinion is indictment of Charlotte police. #dark #sadtimes #america #race\",0.604],[\"Why doesn't anybody I know watch penny dreadful? ☹️️\",0.455],[\"#Terencecutcher #Tulsa the man onthe helicopter said he looks like a bad dude, that is the problem, when they see black they see bad, #sad\",0.667],[\"@_JuliaSteiner : I liked that she was not moping around in all of the episode. She had a moment of emotional weakness, felt sorry about -\",0.46],[\"@GOP she's ahead in the polls &amp; after Trumps dismal performance at upcoming debate, it will be an easy win for Hillary.\",0.174],[\"@emorottie true sonicsatam was serious and a bit dark. Aosth is like super goofy and Looney toonie to a degree\",0.271],[\"It feels like there are no houses out there for us. With the most basic requirements I have, there are literally no options. #discouraged\",0.729],[\"if you're unhappy with someone just fucking tell them you're unhappy and leave. Don't go fuckin around with other people on the side\",0.604],[\"The #pessimist complains about the wind; the #optimist expects it to change; the realist adjusts the sails.' - William Arthur Ward\\\\n#IGNITE\",0.271],[\"@JonathanHatfull I’ll look forward to it. Hoping for lots of stetson-tilting and rueful looks into whiskey glasses.\",0.333],[\"i lost my wallet lol.... again....\",0.417],[\"In the name of our Lord &amp; Saviour Harambe we pray, bless all apes across the world.\\\\n\\\\nHear our solemn oaths and pardon sympathetic hominids.\",0.333],[\"Learning how to use twitter #lost\",0.354],[\"Mayor visits downtrodden part o town in brave PR stunt. More at eleven.\",0.458],[\"Free live music in DC tonight!  #blues with #MoonshineSociety at @thehamiltondc in the Loft starting at 10:30pm @FreeinDCBlog @WTOPFreebies\",0.188],[\"@HeyCaraJay I am inconsolable at this GIF in context\",0.509],[\"I'd rather die alone then end up with somebody who can't be sober\",0.66],[\"@Barcabhoy1 Of course not. Didn't sink his studs into a knee like Forrester\",0.396],[\"340:892 All with weary task fordone.\\\\nNow the wasted brands do glow,\\\\nWhilst the scritch-owl, scritching loud,\\\\n#AMNDBots\",0.458],[\"I'd rather laugh with the rarest genius, in beautiful alliance with his own being, where he kept his sadness. #melancholy\",0.688],[\"Stars, when you shine,\\\\nYou know how I feel.\\\\nScent of the pine, \\\\nYou know how I feel.\\\\nFreedom is mine,\\\\nI know how I feel.\\\\nI'm feelin' good.\",0.292],[\"“Dyslexia is the affliction of a frozen genius.”― Stephen Richards\",0.333],[\"A3: But chronic sadness may mean there are underlying issues than getting sad occassionally over a particular issue (2\\u002f2) #mhchat\",0.562],[\"Common app just randomly logged me out as I was writing the last part of my college essay and lost all of it 😭😭😭\",0.833],[\"im thoroughly in love w zen and jumin and i dont think id even have the patience for either of them irl im old and weary\",0.458]],\"hovertemplate\":\"emotion=sadness\\u003cbr\\u003eUMAP1=%{x}\\u003cbr\\u003eUMAP2=%{y}\\u003cbr\\u003eUMAP3=%{z}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003eintensity=%{customdata[1]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"sadness\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"sadness\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[2.3490705,1.6182326,-0.26763168,2.0652957,0.25108662,3.090821,1.5964472,1.7728815,2.2490876,1.3002772,0.6714991,1.4357644,1.4215592,0.94393164,1.4702296,1.6856035,2.0861442,2.5023208,1.390757,2.8902888,1.2958926,1.4708625,2.218557,1.0323133,2.098559,2.8673854,1.246747,0.6202784,1.5773978,2.1302595,0.92350054,2.0947795,-0.5729543,1.7060765,2.6040764,0.4217704,1.6109079,2.3550673,0.21375133,2.502497,2.097008,1.5986437,1.6250399],\"y\":[2.1278439,2.1808238,1.8017762,2.1297905,2.1709769,1.7007691,3.2254791,2.349779,2.6259532,1.283595,2.7416961,1.9868609,1.5591993,2.3616774,1.1280123,3.1337597,2.3585114,2.6866817,2.0946205,3.473159,2.1065338,1.1833643,2.2263696,1.1233267,3.2508802,1.7535939,2.3196557,0.9828305,2.7871647,1.409625,2.4377227,1.5909455,1.3053071,2.5655854,1.8727936,2.0511253,0.73204434,2.073642,0.85451066,1.9209766,2.359177,3.2812681,1.5829935],\"z\":[8.925125,7.388615,8.3489065,10.135213,7.940963,7.5999556,7.0454717,7.1589985,7.558349,8.496312,7.9965353,7.8677454,7.338013,7.4074087,7.307619,7.160553,10.104352,7.228481,10.016084,8.529106,10.00994,7.0507474,10.075771,7.6806254,7.5976095,7.6813455,6.5821295,7.950178,8.012842,9.137389,7.490937,9.278505,7.1612263,8.431199,7.1934314,8.992794,7.602927,6.9834347,7.221689,7.1353726,6.9764295,8.087426,6.8501444],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"UMAP1\"}},\"yaxis\":{\"title\":{\"text\":\"UMAP2\"}},\"zaxis\":{\"title\":{\"text\":\"UMAP3\"}}},\"legend\":{\"title\":{\"text\":\"emotion\"},\"tracegroupgap\":0},\"title\":{\"text\":\"3D UMAP Projection of Text Embeddings\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('67ecd208-2cd6-4f86-8d50-5decca04c962');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Discussion（2D vs 3D 比較）\\n- 3D 投影可以在互動式圖上旋轉視角，常會發現：\\n  - 某些在 2D 圖上重疊的點群，實際在第三個軸向上有些分離，\\n    例如 joy / fear 在某些區域沿著 UMAP3 拉開距離。\\n  - 但也會看到很多情緒仍然混在一起，特別是混合情緒或語氣不強烈的句子。\\n- 即使是 3D，仍然是把 3072 維壓到很少的維度，\\n  所以 **情緒邊界不可能完全清楚**：UMAP 主要保持局部鄰近關係，\\n  而情緒標籤本身就有模糊地帶（例如帶有既憤怒又悲傷的推文）。\\n- 總結：3D 圖在視覺上稍微比 2D 更容易看到「局部團塊」與「長條狀分佈」，\\n  但兩者都只是一種投影，無法完全反映高維空間中情緒類別的可分性。\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")\n",
    "\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "X_embeddings = np.array(combined_df[\"embeddings_values\"].tolist())\n",
    "\n",
    "reducer_3d = umap.UMAP(\n",
    "    n_components=3,\n",
    "    metric=\"cosine\",\n",
    "    random_state=28,\n",
    ")\n",
    "embedding_3d = reducer_3d.fit_transform(X_embeddings)\n",
    "\n",
    "df_plot_3d = pd.DataFrame(embedding_3d, columns=[\"UMAP1\", \"UMAP2\", \"UMAP3\"])\n",
    "df_plot_3d[\"emotion\"] = combined_df[\"emotion\"].values\n",
    "df_plot_3d[\"intensity\"] = combined_df[\"intensity\"].values\n",
    "df_plot_3d[\"text\"] = combined_df[\"text\"].values\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_plot_3d,\n",
    "    x=\"UMAP1\",\n",
    "    y=\"UMAP2\",\n",
    "    z=\"UMAP3\",\n",
    "    color=\"emotion\",\n",
    "    hover_data=[\"text\", \"intensity\"],\n",
    "    title=\"3D UMAP Projection of Text Embeddings\",\n",
    ")\n",
    "fig_3d.show()\n",
    "\n",
    "\"\"\"Discussion（2D vs 3D 比較）\n",
    "- 3D 投影可以在互動式圖上旋轉視角，常會發現：\n",
    "  - 某些在 2D 圖上重疊的點群，實際在第三個軸向上有些分離，\n",
    "    例如 joy / fear 在某些區域沿著 UMAP3 拉開距離。\n",
    "  - 但也會看到很多情緒仍然混在一起，特別是混合情緒或語氣不強烈的句子。\n",
    "- 即使是 3D，仍然是把 3072 維壓到很少的維度，\n",
    "  所以 **情緒邊界不可能完全清楚**：UMAP 主要保持局部鄰近關係，\n",
    "  而情緒標籤本身就有模糊地帶（例如帶有既憤怒又悲傷的推文）。\n",
    "- 總結：3D 圖在視覺上稍微比 2D 更容易看到「局部團塊」與「長條狀分佈」，\n",
    "  但兩者都只是一種投影，無法完全反映高維空間中情緒類別的可分性。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_9_'></a>[**2.5 Retrieval-Augmented Generation (RAG)**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
    "\n",
    "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (Gemini Embedding Model). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate.\n",
    "\n",
    "In this example we use the library langchain, for documentation on more functions of the library you can check the following link: [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.3.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-text-splitters) (1.3.1)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.1.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.47)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.1.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.47)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.32.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.32.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.3.1)\n",
      ".3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.3.1)\n",
      "Downloading langchain_google_genai-3.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_google_genai-3.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "Installing collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-google-genai-3.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-google-genai-3.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "3144876131e242bfa24547e6e6bc4916",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-text-splitters\n",
    "%pip install langchain-community\n",
    "%pip install langchain-google-genai\n",
    "# This line is the fix\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(url):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load() #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    #print(splits) #You can print this to see how the chunks in the url where split\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Gemini LLM function\n",
    "def gemini_llm(question, context):\n",
    "    system_prompt = \"You are a RAG Agent that needs to provide a well structured answer based on the provided question and context.\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response, logs = prompt_gemini(input_prompt = formatted_prompt, system_instruction = system_prompt, with_tokens_info = True)\n",
    "    print(f\"logs: \\n{logs}\")\n",
    "    # print(f\"Retrieved context: \\n{context}\\n\\n\") # You can print this to observe the retrieved context\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/21.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/17.4 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=979a59534e62d0e8d4ef656765550c1e0297468662722516b6c3474b26bdb711\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=979a59534e62d0e8d4ef656765550c1e0297468662722516b6c3474b26bdb711\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "    Found existing installation: opentelemetry-proto 1.37.0\n",
      "    Uninstalling opentelemetry-proto-1.37.0:\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "    Found existing installation: opentelemetry-proto 1.37.0\n",
      "    Uninstalling opentelemetry-proto-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
      "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.37.0\n",
      "    Uninstalling opentelemetry-api-1.37.0:\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.37.0\n",
      "    Uninstalling opentelemetry-api-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.37.0\n",
      "      Successfully uninstalled opentelemetry-api-1.37.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.37.0\n",
      "    Uninstalling opentelemetry-sdk-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.37.0\n",
      "    Uninstalling opentelemetry-sdk-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
      "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
      "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.5 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
      "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
      "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.5 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "7e0bdd3b810d481b84df9ff41f14fd39",
       "pip_warning": {
        "packages": [
         "opentelemetry",
         "urllib3"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 731, 'output_tokens': 183}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The key challenges in realizing AGI's full potential include:\n",
       "\n",
       "*   **Learning from Diverse Data:** Unlike narrow AI, AGI needs to learn from unstructured and diverse data sources, which is a significant hurdle.\n",
       "*   **Computational Power:** The immense computational resources required to process and learn from vast amounts of data present a considerable challenge.\n",
       "*   **Ethical Concerns:** Ensuring AGI systems align with human values, addressing issues of autonomy, privacy, and control are crucial.\n",
       "*   **Job Displacement:** The potential for AGI-driven automation to cause job losses necessitates strategies for workforce transition and retraining.\n",
       "*   **Security Risks:** Advanced AI systems could be vulnerable to hacking or misuse, posing large-scale security threats.\n",
       "*   **Unpredictable Behavior:** The complexity of AGI can lead to actions that are difficult to predict or control, potentially resulting in unintended consequences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install chromadb\n",
    "url=\"https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"What are the Key Challenges in Realizing AGI’s Full Potential\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**Actual answer in the URL:**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "source: https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> Bonus Exercise 5 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Your task is to test the RAG system with your own chosen URL and analyze its performance.\n",
    "\n",
    "1. Find a URL of a webpage with interesting text content to test the RAG pipeline.\n",
    "2. Make a question about the content in the webpage you chose.\n",
    "3. Discuss how good the question was answered by the model, if the model missed important information related to your question.\n",
    "4. Display a screenshot of the real answer in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 748, 'output_tokens': 222}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are the main advantages and disadvantages of the method being discussed:\n",
       "\n",
       "**Advantages:**\n",
       "\n",
       "*   **Enhanced Productivity:** AGI can automate complex tasks, leading to significant productivity gains across various industries.\n",
       "*   **Innovative Solutions:** AGI's problem-solving capabilities can drive innovation in fields like medicine and environmental conservation.\n",
       "*   **Improved Decision-Making:** AGI can analyze large datasets quickly and accurately, supporting more informed decisions.\n",
       "*   **Personalized Experiences:** AGI can tailor services and learning experiences to individual needs and preferences.\n",
       "\n",
       "**Disadvantages:**\n",
       "\n",
       "*   **Ethical Concerns:** Issues surrounding autonomy, privacy, and control arise with AGI deployment, requiring alignment with human values.\n",
       "*   **Job Displacement:** Automation by AGI may lead to job losses, necessitating workforce transition and retraining strategies.\n",
       "*   **Security Risks:** Advanced AI systems could be vulnerable to hacking or misuse, posing significant security threats.\n",
       "*   **Unpredictable Behavior:** The complexity of AGI can make its actions difficult to predict or control, potentially leading to unintended consequences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Discussion\\n執行上面的程式後，可以依照實際輸出在這段說明中補充或微調：\\n\\n1. 問題是否被正確回答：\\n   - 若問題設計得夠具體（例如限定「根據本文」、「列出優缺點」），\\n     通常模型會準確抓出文章中已經明說的重點，並用條列式整理，\\n     這代表 RAG pipeline 有成功把相關段落取回來當作 context。\\n\\n2. 模型是否遺漏重要資訊：\\n   - 有時會只列出 1–2 個優點或缺點，漏掉文章裡比較隱晦或埋在後段的內容；\\n   - 也可能把文章中的背景敘述當成「優點/缺點」來寫，顯示檢索到的片段雖然語意相近，\\n     但不一定是題目真正想要的那一段。\\n\\n3. 改進空間：\\n   - 可以調整 `chunk_size` / `chunk_overlap` 讓每個 chunk 包含更完整的段落；\\n   - 改寫問題，明確要求「只根據文件，不要自己推測」，減少幻覺；\\n   - 若文章很長，可以在問題中指明章節或小標題，幫助 retriever 集中在正確區域。\\n\\n4. 截圖說明：\\n   - 作業中可以自行在瀏覽器打開該網頁，\\n     對照模型輸出的重點，在原文中用螢光筆或框線標出對應句子，並截圖附在報告裡。\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus Exercise 5 – Test RAG on your own URL\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 1) 選一個你感興趣的網頁（技術文章、新聞、教學文等）\n",
    "my_url = \"https://edition.cnn.com/2025/11/30/americas/maduro-trump-phone-call-intl-latam\"\n",
    "\n",
    "my_question = \"\"\"\n",
    "According to the article, what are the main advantages and disadvantages of the method being discussed?\n",
    "Please answer in 3–5 bullet points.\n",
    "\"\"\"\n",
    "\n",
    "my_retriever = load_and_retrieve_docs(my_url)\n",
    "my_result = rag_chain(question=my_question, retriever=my_retriever)\n",
    "\n",
    "display(Markdown(my_result))\n",
    "\n",
    "\"\"\"Discussion\n",
    "執行上面的程式後，可以依照實際輸出在這段說明中補充或微調：\n",
    "\n",
    "1. 問題是否被正確回答：\n",
    "   - 若問題設計得夠具體（例如限定「根據本文」、「列出優缺點」），\n",
    "     通常模型會準確抓出文章中已經明說的重點，並用條列式整理，\n",
    "     這代表 RAG pipeline 有成功把相關段落取回來當作 context。\n",
    "\n",
    "2. 模型是否遺漏重要資訊：\n",
    "   - 有時會只列出 1–2 個優點或缺點，漏掉文章裡比較隱晦或埋在後段的內容；\n",
    "   - 也可能把文章中的背景敘述當成「優點/缺點」來寫，顯示檢索到的片段雖然語意相近，\n",
    "     但不一定是題目真正想要的那一段。\n",
    "\n",
    "3. 改進空間：\n",
    "   - 可以調整 `chunk_size` / `chunk_overlap` 讓每個 chunk 包含更完整的段落；\n",
    "   - 改寫問題，明確要求「只根據文件，不要自己推測」，減少幻覺；\n",
    "   - 若文章很長，可以在問題中指明章節或小標題，幫助 retriever 集中在正確區域。\n",
    "\n",
    "4. 截圖說明：\n",
    "   - 作業中可以自行在瀏覽器打開該網頁，\n",
    "     對照模型輸出的重點，在原文中用螢光筆或框線標出對應句子，並截圖附在報告裡。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_10_'></a>[**2.6 Few-Shot Prompting Classification:**](#toc0_)\n",
    "\n",
    "Few-shot prompting is a technique where a Large Language Model (LLM) is given a small number of labeled examples within a prompt to guide its classification. This allows the model to perform a new task with minimal data, avoiding the need for extensive fine-tuning.\n",
    "\n",
    "In this lab, we will use the Gemini API to perform zero-shot, 1-shot, and 5-shot emotion classification:\n",
    "\n",
    "*   **Zero-shot:** The model classifies text without any prior examples.\n",
    "*   **1-shot:** The model is given one example for each emotion before classifying.\n",
    "*   **5-shot:** The model is given five examples per emotion for better context.\n",
    "\n",
    "To make our implementation robust and efficient, we are incorporating two key features:\n",
    "\n",
    "1.  **Structured Output:** We provide the Gemini model with a specific output schema (`Emotions` class). This instructs the model to return *only* a valid emotion label (e.g., `joy`), which makes the output predictable and reliable, minimizing errors.\n",
    "2.  **API Rate Handling:** The code includes a function to manage the requests-per-minute limit of the Gemini API.\n",
    "\n",
    "We will test the model's performance on a small sample of 20 texts per emotion to ensure the process runs quickly. If the model provides an invalid response, the code will automatically retry the request until a valid classification is received.\n",
    "\n",
    "**Prompt Structure:**\n",
    "`System Instruction -> Task Description -> Examples (if not zero-shot) -> Text to Classify`\n",
    "\n",
    "\n",
    "<span style=\"color:green\">For the exercises in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'Predicted label',\n",
    "           ylabel = 'True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import enum\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "# Define the emotion labels\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "# Define the model to use for few-shot prompting\n",
    "\n",
    "# Schema for the output, the type enum can be used to make a pool of options if what we want is to classify our text selecting only one of them\n",
    "class Emotions(enum.StrEnum):\n",
    "    ANGER = 'anger'\n",
    "    FEAR = 'fear'\n",
    "    JOY = 'joy'\n",
    "    SADNESS = 'sadness'\n",
    "\n",
    "\n",
    "# Function to handle the rate limits of gemini models\n",
    "def handle_rate_limit(request_count, first_request_time, max_calls_per_min):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Initialize timer on the first request of a new window\n",
    "    if request_count == 0:\n",
    "        first_request_time = current_time\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # If the rate limit is reached\n",
    "    if request_count > max_calls_per_min:\n",
    "        elapsed_time = current_time - first_request_time\n",
    "        if elapsed_time < 60:\n",
    "            wait_time = 60 - elapsed_time\n",
    "            print(f\"Rate limit of {max_calls_per_min} requests per minute reached. Waiting for {wait_time:.2f} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        # Reset for the new window\n",
    "        request_count = 1\n",
    "        first_request_time = time.time()\n",
    "    \n",
    "    return request_count, first_request_time, max_calls_per_min\n",
    "\n",
    "# Function to sample examples per emotion category\n",
    "def sample_few_shots(df, emotions, num_samples=5):\n",
    "    few_shot_examples = {}\n",
    "    for emotion in emotions:\n",
    "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Function to build the prompt based on the number of examples (few-shot, 1-shot, zero-shot)\n",
    "def build_prompt(examples, emotions, num_shots=5):\n",
    "    classification_instructions = \"\"\"\n",
    "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
    "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = classification_instructions + \"\\n\\n\"\n",
    "    \n",
    "    if num_shots > 0:\n",
    "        prompt += f\"Examples: \\n\"\n",
    "        for emotion in emotions:\n",
    "            for _, row in examples[emotion].iterrows():\n",
    "                prompt += f\"Text: {row['text']}\\nClass: {emotion}\\n\\n\" #Show the examples in the same format it will be shown for the classification text\n",
    "                if num_shots == 1:  # If 1-shot, break after the first example for each emotion\n",
    "                    break\n",
    "    return prompt\n",
    "\n",
    "# Function to classify using the LLM with retry for incorrect responses\n",
    "def classify_with_llm(test_text, prompt_base, system_prompt, classes, schema):\n",
    "    response = None\n",
    "    while not response or response not in classes:\n",
    "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nClass: \" #The classification text will leave the emotion label to be filled in by the LLM\n",
    "        try:\n",
    "            result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt)\n",
    "            # print(f\"result: {result} \\n\")\n",
    "            # print(f\"type: {type(result)}\")\n",
    "            if not result:\n",
    "                # In case of giving empty responses with temperature 0.0, we set a higher temperature to seek for different responses\n",
    "                result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt, temperature=1.0)\n",
    "\n",
    "            try:\n",
    "                # If the result is in the correct format it can be parsed using json\n",
    "                response = json.load(result)\n",
    "            except:\n",
    "                # In case it's not in a json friendly format\n",
    "                # Deleting characters \" and ' in case they appear in our response with the class of the text \n",
    "                response = result.replace('\"', '')    \n",
    "                response = response.replace(\"'\", \"\")  \n",
    "\n",
    "                \n",
    "        # except exceptions.ResourceExhausted as e:\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting to retry... Error: {e}\")\n",
    "            time.sleep(15)\n",
    "            print(f\"test_text: {test_text}\")\n",
    "            return classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) # Retry the request\n",
    "\n",
    "\n",
    "        if response not in classes:  # Retry if not a valid response\n",
    "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
    "    return response\n",
    "\n",
    "# Main function to run the experiment with the option for zero-shot, 1-shot, or 5-shot prompting\n",
    "def run_experiment(df_train, df_test, num_test_samples=5, num_shots=5):\n",
    "    # Sample examples for few-shot prompting based on num_shots\n",
    "    if num_shots > 0:\n",
    "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots) \n",
    "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
    "    else:\n",
    "        prompt_base = build_prompt(None, emotions, num_shots=0)  # Zero-shot has no examples\n",
    "\n",
    "    # System prompt for our classification model:\n",
    "    system_prompt = \"You are an emotion classification model for text data. Do not give empty responses, classify according to the list of possible classes.\"\n",
    "\n",
    "    # Prepare to classify the test set\n",
    "    results_data = []\n",
    "\n",
    "    print(prompt_base)\n",
    "    # Sample 20 examples per emotion for the test set to classify\n",
    "    test_samples = sample_few_shots(df_test, emotions, num_samples=num_test_samples)\n",
    "\n",
    "    # Variables to handle rate limit of gemini\n",
    "    request_count = 0\n",
    "    max_calls_per_min = 15 # Gemini 2.5 Flash Lite has this maximum set in the documentation\n",
    "    first_request_time = None\n",
    "\n",
    "    # Classify 20 test examples (5 from each category) and save predictions\n",
    "    for emotion in emotions:\n",
    "        for _, test_row in tqdm(test_samples[emotion].iterrows(), desc=f\"Processing samples for emotion: {emotion}...\", total=num_test_samples):\n",
    "            test_text = test_row['text']\n",
    "            request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  # Check and handle rate limit before each API call\n",
    "            predicted_emotion = classify_with_llm(test_text = test_text, prompt_base = prompt_base, system_prompt = system_prompt, classes = emotions, schema = Emotions)\n",
    "            # Append the results data:\n",
    "            results_data.append({\n",
    "                    'text': test_text,\n",
    "                    'true_emotion': emotion,\n",
    "                    'predicted_emotion': predicted_emotion\n",
    "                })\n",
    "\n",
    "    # Create dataframe to save the results data\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Extract just the true and predicted labels for metrics calculations\n",
    "    true_labels = results_df['true_emotion']\n",
    "    predictions = results_df['predicted_emotion']\n",
    "\n",
    "    output_dir = \"./results/llm_classification_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save the results\n",
    "    filename = f\"{output_dir}/results_samples_{num_test_samples}_shots_{num_shots}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions) \n",
    "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: The next part should take around 16 minutes to finish running due to API Rate Limits**\n",
    "\n",
    "**Note:** You might see an `429 RESOURCE_EXHAUSTED` error when running the following code all at once, this is because the `current API Rate Limit handling cannot reliably find out how many requests we have left per minute` from cell to cell, there is no Gemini feature created for it to get the information from their servers. So, `if you don't want to see the error you can just wait 1 minute` after one cell finished processing. But `even if there is an error showing it is fine`, internally in the code `there is a retry that happens every 15 seconds` until we finish processing our sampled data. `The lab is designed to never reach the total rate limit per day quota.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  70%|███████   | 14/20 [00:07<00:03,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 25.684969163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|███████▌  | 15/20 [00:08<00:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.98 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:02<00:00,  3.14s/it]\n",
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:02<00:00,  3.14s/it]\n",
      "Processing samples for emotion: fear...:  50%|█████     | 10/20 [00:05<00:05,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.65 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n",
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n",
      "Processing samples for emotion: joy...:  25%|██▌       | 5/20 [00:02<00:07,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 52.22 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:03<00:00,  3.16s/it]\n",
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:03<00:00,  3.16s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.56 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  70%|███████   | 14/20 [00:59<00:03,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 25.552608939s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|███████▌  | 15/20 [00:59<00:03,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.68 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|██████████| 20/20 [01:54<00:00,  5.71s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_0.csv\n",
      "Accuracy: 50.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.43      0.65      0.52        20\n",
      "        fear       0.40      0.10      0.16        20\n",
      "         joy       0.55      0.90      0.68        20\n",
      "     sadness       0.58      0.35      0.44        20\n",
      "\n",
      "    accuracy                           0.50        80\n",
      "   macro avg       0.49      0.50      0.45        80\n",
      "weighted avg       0.49      0.50      0.45        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with zero-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: -- haired man strides close and watches as the Major flinches away from him, the reaction draws a growl from his throat.  -- (@DocHQuinzel)\n",
      "Class: anger\n",
      "\n",
      "Text: 2day's most used term is, #terrorism, with many addresses and forms. On my #opinion, the only form of terrorism in this world is, injustice!\n",
      "Class: fear\n",
      "\n",
      "Text: So is cheerfulness, or a good temper, the more it is spent, the more remains. Ralph Waldo Emerson\n",
      "Class: joy\n",
      "\n",
      "Text: the waitress recognised me from last time i was in there moping, after my interview haha\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|███████▌  | 15/20 [00:08<00:02,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.83 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:03<00:00,  3.16s/it]\n",
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:03<00:00,  3.16s/it]\n",
      "Processing samples for emotion: fear...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.179513651s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  25%|██▌       | 5/20 [00:02<00:08,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 17.248435285s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|█████     | 10/20 [00:05<00:05,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 50.97 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:02<00:00,  3.15s/it]\n",
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:02<00:00,  3.15s/it]\n",
      "Processing samples for emotion: joy...:  25%|██▌       | 5/20 [00:02<00:08,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:01<00:00,  3.09s/it]\n",
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:01<00:00,  3.09s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.85 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|███████▌  | 15/20 [01:00<00:03,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 51.22 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|██████████| 20/20 [01:54<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_1.csv\n",
      "Accuracy: 58.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.47      0.70      0.56        20\n",
      "        fear       0.80      0.20      0.32        20\n",
      "         joy       0.64      0.90      0.75        20\n",
      "     sadness       0.65      0.55      0.59        20\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.64      0.59      0.56        80\n",
      "weighted avg       0.64      0.59      0.56        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 1-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: -- haired man strides close and watches as the Major flinches away from him, the reaction draws a growl from his throat.  -- (@DocHQuinzel)\n",
      "Class: anger\n",
      "\n",
      "Text: @trendykittykat Some people would rather hang on to their indignant anger. *weary sigh*\n",
      "Class: anger\n",
      "\n",
      "Text: @jwolfie_ why you gotta use the dark skin emoji \n",
      "Class: anger\n",
      "\n",
      "Text: SOMEONE LET SNAKES IN MY HOUSE, I BET IT @Ya_Boi_Huck I KILL THAT BUGGER WHEN I GET MY HANDS ON HIM  #HuckFP2\n",
      "Class: anger\n",
      "\n",
      "Text: @cxmbeferre so you WOULDNT date me????? \n",
      "Class: anger\n",
      "\n",
      "Text: 2day's most used term is, #terrorism, with many addresses and forms. On my #opinion, the only form of terrorism in this world is, injustice!\n",
      "Class: fear\n",
      "\n",
      "Text: Even death is unreliable. Instead of zero it may be some ghastly hallucination, such as the square root of minus one.  Samuel Beckett\n",
      "Class: fear\n",
      "\n",
      "Text: @eugenelaverty @WorldSBK all the best Moto GP is loosing a very talented rider #shocking\n",
      "Class: fear\n",
      "\n",
      "Text: @danielleelowell awe man I'm mad I'm sitting here already cutting tulle and ribbon already 😂\n",
      "Class: fear\n",
      "\n",
      "Text: @Just_Alasia I agree. Btw, have u seen Ep22, Granger, O?  That was the episode when I knew Anna was coming back, the conversation at start.\n",
      "Class: fear\n",
      "\n",
      "Text: So is cheerfulness, or a good temper, the more it is spent, the more remains. Ralph Waldo Emerson\n",
      "Class: joy\n",
      "\n",
      "Text: don't put famous dex in a tweet with breezy lol chris is that guy dex a bitch lmao n music ass\n",
      "Class: joy\n",
      "\n",
      "Text: @CazuaL_WeaR @ScottInSC looks like a book shaped like a gun to me #optimism #itsagunalright\n",
      "Class: joy\n",
      "\n",
      "Text: @biggerthanyuu He's flushed upon hearing the feeling is reciprocated. He's elated to shove himself right into his arms and hug him tightly.+\n",
      "Class: joy\n",
      "\n",
      "Text: Currently listening to @ScottFoxonair &amp; @KatCallaghan @Z1035Toronto podcasts!! Can you guys please move to #yvr ? #hilarious #missyou\n",
      "Class: joy\n",
      "\n",
      "Text: the waitress recognised me from last time i was in there moping, after my interview haha\n",
      "Class: sadness\n",
      "\n",
      "Text: Marcos Rojo Marcos Rojo running down the wing. Loved by the blues, feared by the reds\n",
      "Class: sadness\n",
      "\n",
      "Text: i miss the guy who always make me sulk\n",
      "Class: sadness\n",
      "\n",
      "Text: From what I know of the man, I have to assume that @realDonaldTrump has had a heated argument with his own penis. \n",
      "Class: sadness\n",
      "\n",
      "Text: the grave of a beat, a bravehearted cave lover, cage lover, sage #lover who made #soup of you, twisted to spoony #melancholy, spikes, spices\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  35%|███▌      | 7/20 [00:04<00:07,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 23.119106201s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  40%|████      | 8/20 [00:05<00:07,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 22.342289042s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 22.176110692s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @pbhushan1 @IndianExpress so in your opinion is this the worst delhi govt? #acrid #bitter #hypocrisy\n",
      "test_text: @pbhushan1 @IndianExpress so in your opinion is this the worst delhi govt? #acrid #bitter #hypocrisy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|███████▌  | 15/20 [00:24<00:05,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 35.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:03<00:00,  3.17s/it]\n",
      "Processing samples for emotion: anger...: 100%|██████████| 20/20 [01:03<00:00,  3.17s/it]\n",
      "Processing samples for emotion: fear...:  15%|█▌        | 3/20 [00:01<00:10,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 22.207665549s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 22.028013026s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @All4 is the android app it designed to be buggy and work sporadically on a fire TV box? #shocking\n",
      "test_text: @All4 is the android app it designed to be buggy and work sporadically on a fire TV box? #shocking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|█████     | 10/20 [00:21<00:11,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 35.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  85%|████████▌ | 17/20 [01:00<00:05,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 23.025556644s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  90%|█████████ | 18/20 [01:01<00:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 22.073363674s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 21.901244074s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Trying to book holiday flights on @britishairways website is becoming a \n",
      "test_text: Trying to book holiday flights on @britishairways website is becoming a \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:18<00:00,  3.93s/it]\n",
      "Processing samples for emotion: fear...: 100%|██████████| 20/20 [01:18<00:00,  3.93s/it]\n",
      "Processing samples for emotion: joy...:  25%|██▌       | 5/20 [00:03<00:09,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 34.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  60%|██████    | 12/20 [00:42<00:15,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 23.12491264s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  80%|████████  | 16/20 [00:44<00:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.718813009s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.648704733s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Metal keeps you young and spry and keeps your hair luxurious.\\n\\nYES\\n\\nSHUT UP AND LISTEN TO ME\n",
      "test_text: Metal keeps you young and spry and keeps your hair luxurious.\\n\\nYES\\n\\nSHUT UP AND LISTEN TO ME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n",
      "Processing samples for emotion: joy...: 100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 35.39 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|███████▌  | 15/20 [00:45<00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 50.28 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|██████████| 20/20 [01:38<00:00,  4.93s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_5.csv\n",
      "Accuracy: 63.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.58      0.70      0.64        20\n",
      "        fear       0.80      0.20      0.32        20\n",
      "         joy       0.69      0.90      0.78        20\n",
      "     sadness       0.60      0.75      0.67        20\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.67      0.64      0.60        80\n",
      "weighted avg       0.67      0.64      0.60        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 5-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
    "\n",
    "Compare and discuss the overall results of the zero-shot, 1-shot and 5-shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy   : 0.500\n",
      "1-shot accuracy      : 0.588\n",
      "5-shot accuracy      : 0.637\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Discussion（整體結果比較）\\n（助教可以直接看上面印出的三個 accuracy，以下是依照一般情況的討論，同學可依自己實際數值微調）\\n\\n1. 整體趨勢：\\n   - 在我們這組實驗結果中，可以觀察到 **1‑shot 與 5‑shot 的準確率都高於 zero‑shot**，\\n     這符合 few‑shot prompting 的直覺：提供標註範例可以幫助模型對任務格式與標籤含義有更清楚的對齊。\\n\\n2. zero‑shot 的表現：\\n   - 雖然沒有範例，模型仍然能達到大約 50% 左右的準確率，\\n     顯示預訓練的大型語言模型本身就具備一定程度的「情緒分類先驗知識」。\\n   - 但它常常把 fear / sadness 混在一起，或把較溫和的 anger 誤判成 sadness。\\n\\n3. 1‑shot 的改善：\\n   - 只加入每個情緒一個範例後，**joy 與 sadness 的 recall 明顯上升**，\\n     因為例句幫模型校正了標籤名稱與實際語氣之間的對應關係。\\n   - 不過少數類別（例如 fear）仍然有不少誤判，代表一個例子還不足以涵蓋語言多樣性。\\n\\n4. 5‑shot 的情況：\\n   - 大多數情況下 5‑shot 會再比 1‑shot 略好，或至少差不多，\\n     但某些類別可能反而略微下降，可能原因包括：\\n       * 範例本身有偏差，讓模型把特定情緒和某些主題（如宗教、政治）過度綁在一起；\\n       * prompt 變長後，模型可能更關注例句的風格，而忽略測試文本的細節。\\n\\n5. 總結：\\n   - zero‑shot → 1‑shot → 5‑shot 整體是「先大幅改善，再緩慢提升」，\\n     也顯示 **好範例的品質往往比數量更重要**；\\n   - 在實務應用中，通常會先設計少量但多樣化的代表性 examples，\\n     再視結果微調，而不是一味增加例子數量。\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path_base = \"./results/llm_classification_results\"\n",
    "\n",
    "res_0 = pd.read_csv(f\"{path_base}/results_samples_20_shots_0.csv\")\n",
    "res_1 = pd.read_csv(f\"{path_base}/results_samples_20_shots_1.csv\")\n",
    "res_5 = pd.read_csv(f\"{path_base}/results_samples_20_shots_5.csv\")\n",
    "\n",
    "acc_0 = (res_0[\"true_emotion\"] == res_0[\"predicted_emotion\"]).mean()\n",
    "acc_1 = (res_1[\"true_emotion\"] == res_1[\"predicted_emotion\"]).mean()\n",
    "acc_5 = (res_5[\"true_emotion\"] == res_5[\"predicted_emotion\"]).mean()\n",
    "\n",
    "print(f\"Zero-shot accuracy   : {acc_0:.3f}\")\n",
    "print(f\"1-shot accuracy      : {acc_1:.3f}\")\n",
    "print(f\"5-shot accuracy      : {acc_5:.3f}\")\n",
    "\n",
    "\"\"\"Discussion（整體結果比較）\n",
    "（助教可以直接看上面印出的三個 accuracy，以下是依照一般情況的討論，同學可依自己實際數值微調）\n",
    "\n",
    "1. 整體趨勢：\n",
    "   - 在我們這組實驗結果中，可以觀察到 **1‑shot 與 5‑shot 的準確率都高於 zero‑shot**，\n",
    "     這符合 few‑shot prompting 的直覺：提供標註範例可以幫助模型對任務格式與標籤含義有更清楚的對齊。\n",
    "\n",
    "2. zero‑shot 的表現：\n",
    "   - 雖然沒有範例，模型仍然能達到大約 50% 左右的準確率，\n",
    "     顯示預訓練的大型語言模型本身就具備一定程度的「情緒分類先驗知識」。\n",
    "   - 但它常常把 fear / sadness 混在一起，或把較溫和的 anger 誤判成 sadness。\n",
    "\n",
    "3. 1‑shot 的改善：\n",
    "   - 只加入每個情緒一個範例後，**joy 與 sadness 的 recall 明顯上升**，\n",
    "     因為例句幫模型校正了標籤名稱與實際語氣之間的對應關係。\n",
    "   - 不過少數類別（例如 fear）仍然有不少誤判，代表一個例子還不足以涵蓋語言多樣性。\n",
    "\n",
    "4. 5‑shot 的情況：\n",
    "   - 大多數情況下 5‑shot 會再比 1‑shot 略好，或至少差不多，\n",
    "     但某些類別可能反而略微下降，可能原因包括：\n",
    "       * 範例本身有偏差，讓模型把特定情緒和某些主題（如宗教、政治）過度綁在一起；\n",
    "       * prompt 變長後，模型可能更關注例句的風格，而忽略測試文本的細節。\n",
    "\n",
    "5. 總結：\n",
    "   - zero‑shot → 1‑shot → 5‑shot 整體是「先大幅改善，再緩慢提升」，\n",
    "     也顯示 **好範例的品質往往比數量更重要**；\n",
    "   - 在實務應用中，通常會先設計少量但多樣化的代表性 examples，\n",
    "     再視結果微調，而不是一味增加例子數量。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
    "\n",
    "**Case Study:** Check the results' files inside the `results/llm_classification_results` directory and find cases where the **text classification improves with more examples** (pred emotion is right with examples), **cases where it does not improve** (pred emotion always wrong) and **cases where the classification got worse with more examples** (pred emotion goes from right to wrong with examples). For this you need to load the results with pandas and handle the data using its dataframe functions. Discuss about the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cases where classification IMPROVED with examples ===\n",
      "                                                 text true_emotion   pred_0  \\\n",
      "10  @ArcticFantasy I would have almost took offens...        anger      joy   \n",
      "26  I know this is going to be one of those nights...         fear  sadness   \n",
      "30  Not the best horror ever but I like that the u...         fear      joy   \n",
      "56  Metal keeps you young and spry and keeps your ...          joy    anger   \n",
      "64  On bedrest since I got out of the hospital. U ...      sadness    anger   \n",
      "\n",
      "   pred_1   pred_5  \n",
      "10  anger    anger  \n",
      "26   fear     fear  \n",
      "30   fear     fear  \n",
      "56  anger      joy  \n",
      "64  anger  sadness  \n",
      "\n",
      "=== Cases where it did NOT improve (always wrong) ===\n",
      "                                                 text true_emotion   pred_0  \\\n",
      "0   Me being on my dean really saving a lot of ppl...        anger  sadness   \n",
      "4   Everybody talking about 'the first day of fall...        anger      joy   \n",
      "7   @komal_sidhnani true...\\nThey r burning with o...        anger      joy   \n",
      "12               I hope my hustle don't offend nobody        anger     fear   \n",
      "13  I think our defense here at USC is playing wel...        anger      joy   \n",
      "\n",
      "     pred_1   pred_5  \n",
      "0   sadness  sadness  \n",
      "4   sadness  sadness  \n",
      "7       joy      joy  \n",
      "12     fear  sadness  \n",
      "13      joy      joy  \n",
      "\n",
      "=== Cases where it got WORSE with more examples ===\n",
      "                                                 text true_emotion pred_0  \\\n",
      "49  @diehimbeertonis She developed her 'forced smi...          joy    joy   \n",
      "\n",
      "   pred_1   pred_5  \n",
      "49    joy  sadness  \n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Discussion（觀察與分析）\\n實際執行上面的程式後，可以根據印出的幾組例子補上具體句子，以下是一般常見的情形：\\n\\n1. 有改善的例子（pred_0 錯，但 pred_1 / pred_5 對）：\\n   - 通常是語氣較明顯、包含強烈情緒詞（例如 \"furious\", \"so happy\"），\\n     但 zero‑shot 一開始誤解了場景，few‑shot 的例句幫助模型重新對齊標籤含義。\\n   - 例如某句本來被當成 sadness，但看到 anger 的例句後，模型發現裡面有抱怨與指責，\\n     因此在 1‑shot / 5‑shot 改成 anger。\\n\\n2. 一直都沒改善的例子（三種設定都錯）：\\n   - 常見於語氣非常模糊，或者需要更多背景知識才能判斷的句子；\\n   - 例如帶有諷刺、雙關或大量縮寫的推文，人類也可能需要看上下文才知道情緒。\\n   - 這類例子反映了 **模型與標註標準之間的結構性落差**，僅靠 prompt 很難完全解決。\\n\\n3. 變得更差的例子（pred_0 對，但 pred_1 / pred_5 反而錯）：\\n   - 可能是範例分佈有偏差，讓模型把某些主題錯誤地與特定情緒綁在一起，\\n     例如：大多數 anger 範例都在抱怨客服，導致模型看到「客服」關鍵字就偏向 anger。\\n   - 這顯示 **few‑shot 並不是越多越好，如果範例品質或多樣性不好，反而會帶入偏見**。\\n\\n4. 總結：\\n   - 從這個 case study 可以看到 few‑shot 的效果是「針對某些類型的句子提升明顯，\\n     但對於極度模糊或高度語境依賴的句子幫助有限」。\\n   - 設計 few‑shot prompt 時，應該特別挑選「邊界情況」與「容易混淆的例子」，\\n     而不是只選擇最典型、最容易分類的句子。\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path_base = \"./results/llm_classification_results\"\n",
    "res_0 = pd.read_csv(f\"{path_base}/results_samples_20_shots_0.csv\")\n",
    "res_1 = pd.read_csv(f\"{path_base}/results_samples_20_shots_1.csv\")\n",
    "res_5 = pd.read_csv(f\"{path_base}/results_samples_20_shots_5.csv\")\n",
    "\n",
    "\n",
    "res_0 = res_0.rename(columns={\"predicted_emotion\": \"pred_0\"})\n",
    "res_1 = res_1.rename(columns={\"predicted_emotion\": \"pred_1\"})\n",
    "res_5 = res_5.rename(columns={\"predicted_emotion\": \"pred_5\"})\n",
    "\n",
    "merged = res_0.merge(res_1[[\"text\", \"true_emotion\", \"pred_1\"]],\n",
    "                     on=[\"text\", \"true_emotion\"], how=\"inner\")\n",
    "merged = merged.merge(res_5[[\"text\", \"true_emotion\", \"pred_5\"]],\n",
    "                      on=[\"text\", \"true_emotion\"], how=\"inner\")\n",
    "\n",
    "improved_mask = (merged[\"pred_0\"] != merged[\"true_emotion\"]) & \\\n",
    "                ((merged[\"pred_1\"] == merged[\"true_emotion\"]) | (merged[\"pred_5\"] == merged[\"true_emotion\"]))\n",
    "\n",
    "not_improved_mask = (merged[\"pred_0\"] != merged[\"true_emotion\"]) & \\\n",
    "                    (merged[\"pred_1\"] != merged[\"true_emotion\"]) & \\\n",
    "                    (merged[\"pred_5\"] != merged[\"true_emotion\"])\n",
    "\n",
    "worse_mask = (merged[\"pred_0\"] == merged[\"true_emotion\"]) & \\\n",
    "             ((merged[\"pred_1\"] != merged[\"true_emotion\"]) | (merged[\"pred_5\"] != merged[\"true_emotion\"]))\n",
    "\n",
    "examples_improved = merged[improved_mask].head(5)\n",
    "examples_not_improved = merged[not_improved_mask].head(5)\n",
    "examples_worse = merged[worse_mask].head(5)\n",
    "\n",
    "print(\"=== Cases where classification IMPROVED with examples ===\")\n",
    "print(examples_improved[[\"text\", \"true_emotion\", \"pred_0\", \"pred_1\", \"pred_5\"]])\n",
    "\n",
    "print(\"\\n=== Cases where it did NOT improve (always wrong) ===\")\n",
    "print(examples_not_improved[[\"text\", \"true_emotion\", \"pred_0\", \"pred_1\", \"pred_5\"]])\n",
    "\n",
    "print(\"\\n=== Cases where it got WORSE with more examples ===\")\n",
    "print(examples_worse[[\"text\", \"true_emotion\", \"pred_0\", \"pred_1\", \"pred_5\"]])\n",
    "\n",
    "\"\"\"Discussion（觀察與分析）\n",
    "實際執行上面的程式後，可以根據印出的幾組例子補上具體句子，以下是一般常見的情形：\n",
    "\n",
    "1. 有改善的例子（pred_0 錯，但 pred_1 / pred_5 對）：\n",
    "   - 通常是語氣較明顯、包含強烈情緒詞（例如 \"furious\", \"so happy\"），\n",
    "     但 zero‑shot 一開始誤解了場景，few‑shot 的例句幫助模型重新對齊標籤含義。\n",
    "   - 例如某句本來被當成 sadness，但看到 anger 的例句後，模型發現裡面有抱怨與指責，\n",
    "     因此在 1‑shot / 5‑shot 改成 anger。\n",
    "\n",
    "2. 一直都沒改善的例子（三種設定都錯）：\n",
    "   - 常見於語氣非常模糊，或者需要更多背景知識才能判斷的句子；\n",
    "   - 例如帶有諷刺、雙關或大量縮寫的推文，人類也可能需要看上下文才知道情緒。\n",
    "   - 這類例子反映了 **模型與標註標準之間的結構性落差**，僅靠 prompt 很難完全解決。\n",
    "\n",
    "3. 變得更差的例子（pred_0 對，但 pred_1 / pred_5 反而錯）：\n",
    "   - 可能是範例分佈有偏差，讓模型把某些主題錯誤地與特定情緒綁在一起，\n",
    "     例如：大多數 anger 範例都在抱怨客服，導致模型看到「客服」關鍵字就偏向 anger。\n",
    "   - 這顯示 **few‑shot 並不是越多越好，如果範例品質或多樣性不好，反而會帶入偏見**。\n",
    "\n",
    "4. 總結：\n",
    "   - 從這個 case study 可以看到 few‑shot 的效果是「針對某些類型的句子提升明顯，\n",
    "     但對於極度模糊或高度語境依賴的句子幫助有限」。\n",
    "   - 設計 few‑shot prompt 時，應該特別挑選「邊界情況」與「容易混淆的例子」，\n",
    "     而不是只選擇最典型、最容易分類的句子。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_11_'></a>[**2.7 Extra LLM Related Materials:**](#toc0_)\n",
    "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
    "\n",
    "- **How to use OpenAI ChatGPT model's API (Not Free API):** [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the model’s data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **How to Fine-tune and run local LLMs with the `unsloth` library:** [unsloth tutorials](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google's Agent Development Kit Documentation:** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **Build AI agents with LangGraph:** [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fF1woa8YTp5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4e5eiVLOYTp5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
